[{"category":"General","contents":"","date":"2000-01-01T00:00:00Z","description":"Atishay Jain home page","image":"/image/favicon.min.svg","meta":[{"file":"home/about/index.yaml"},{"file":"home/experience/index.yaml"},{"file":"home/internships/index.yaml"},{"file":"home/education/index.yaml"},{"file":"home/patents/index.yaml"},{"file":"home/speaking/index.yaml"},{"file":"home/awards/index.yaml"},{"file":"home/projects/index.yaml"},{"file":"home/publications/index.yaml"},{"file":"home/blog/index.yaml"},{"file":"home/proficiency/index.yaml"},{"file":"home/testimonial/index.yaml"},{"file":"home/contact/index.yaml"}],"permalink":"https://atishay.me/","readingTime":0,"series":null,"tags":null,"title":"Atishay Jain - Home Page"},{"category":"","contents":"Hello everyone. My name is Atishay and I am a JavaScript developer. A few years back, if I said this, someone would have thought - what\u0026rsquo;s this guy doing in a Cisco conference. Will he be going to a lawyer\u0026rsquo;s conference next to preach them to convert from legalese. The web developer community has changed a lot from the cult of people copying and pasting scripts from google. We have matured to a package manager. Jokes apart, the modern JavaScript looks nothing like the one from the 90s and the programming paradigm built from ground up to be asynchronous has a lot to offer. With node.js having a serious footprint on the server, especially in the serverless world, no one needs to defend the language. I\u0026rsquo;m not here today to sell you JS. I am here to talk about a unique style of designing cloud native applications getting popular in the JavaScript world. The entire programming community needs to take a note of this.\nToday I will talk about my journey into application architectures. I will talk about two definitions of cloud native and how they can be brought together. We will see how the cloud native revolutions fits historically in computing. We will then go into the role of JavaScript and node.js. I will try to justify my title by giving reasons and caveats of running node.js on customer machines and leave you with the knowledge of a new computing paradigm which may be best fit for your use case. Success it not always what it seems to be. With computing paradigms shifting fundamentally every decade, we need to be open to possibilities and inspiration from the unlikeliest of sources. The frontend community is one of them.\nAs a developer I have worked on most major computing platforms prevalent. I have worked on industry defining desktop applications, distributed full stack web applications both on premise and on the cloud as well as award winning mobile applications. With this variety of product experiences I have been able to witness the transformations that one area has had on the other. While developers and designers continue to club these experiences together, these three platforms remain unique. The users expect power on the desktop, cross-device synchronization on the web and ease of use on the mobile. The development of applications that targets all these platforms requires a fine balancing act between features that the users expect and those that ease in the development and maintenance.\nOne major development in the cloud has been the migration to the cloud native architectures. Raise your hand if you understand cloud native as a developer. Raise your hand if you find the cloud native as a simplification over the traditional approach to service development. Cloud native has turned into such a big thing for development teams. Here is a diagram describing cloud native for developers who are still uninitiated. Cloud Native has four pillars. When developing an application in the cloud, we should not be writing it like we do for a on-premise system where provisioning resources is so difficult. 5 layers of approvals to get a hard drive. In the cloud we can acquire a new server by the click of a button. The bigger servers are not necessarily better any more. We lose the advantages of an multi-region, multi-az and multi-cloud by having huge services that are difficult to setup and scale. Micro-services are easier to manage and maintain. In the cloud provisioning can be done by code. Why do it manually each time. DevOps is the second pillar of a developer\u0026rsquo;s cloud native. Containers provide an opportunity to have an exact replica of the production environment locally. That way we can restrict production server access. I love to SSH into production as much as you do. But I fear someone putting whisky on the delete key of my keyboard. You should too. The final pillar is continuous delivery. That brings the fun into development. I deployed for the first time to production two months after joining my job. Your intern could do it on his first day.\nWe all know what Cloud Native means for the developer. The question is - what does it mean to the customer. Gimme it a few seconds. \u0026ldquo;Seriously?\u0026rdquo;. Whatever that comes next may be cloud but is surely not native. That is a big problem with our approach towards moving the solution to the cloud. People know that the web is slow. If web pages show loading indicators, customers are able to accept it. But they don\u0026rsquo;t call them native. For the customer cloud and native are different. Cloud offers synchronization, collaboration and instant updates. They expect native apps to have near real-time performance, ability to handle flaky networks and full offline support. We cannot call it native if it doesn\u0026rsquo;t work in a moving vehicle or if it reminds us with every click that it has to go to the server. Even these web \u0026ldquo;apps\u0026rdquo; with 100 gigabytes of javascript make us wait. Mobile apps that authenticate with my face or my finger need to talk to the server to let me in. Native desktop apps, never had this problem until now.\nHow do we solve this problem? Can we make the cloud truly native for both the user and the developer? Here is a combined list of requirements. This is a lot. We want developer flexibility. The users want cloud features and native performance. This is like the heisenberg uncertainty principle. You cannot have all three. We are fighting with the laws of physics. Light moves too slow. We need to reduce the distance to speed it up. We start moving to a multi-cloud architecture where the full processing moves closer to the user. Then we get to CDNs where some resources come even closer. And then we added edge computing so that we could do some basic processing at the edges. This speeds things up making a faster cloud but it is still not native. What do we next? Go to the PM and say, this cannot be done. Or do what engineers do best - hack through it. Programmers have this interesting concept called Duck Typing. And we can make anything a duck by relaxing the definition of a duck to be just quacking or laying eggs. We need to relax all of these constraints to get what we want. The answer to the users version of cloud native lies in developer\u0026rsquo;s cloud native. This is microservices in cloud native. We have the main region, the multi-cloud sub-regions and the edges. All have microservices that perform tasks that can prevent unneeded trips for the light. What if we could get a microservice inside of the customer\u0026rsquo;s machine.\nOn the surface, this seems like a bad idea. We have lots of questions. How about security, updates, or supporting offline. But if we are shooting for the customer\u0026rsquo;s cloud native definition, we have to be clever about it. We need to relax our definition of cloud native to achieve all this. Lets answer the big questions. Security - the browser where the customer reads the data is already on the customer\u0026rsquo;s machine. If the machine gets compromised, there are much bigger problems than our data like the passwords in the browser\u0026rsquo;s storage. We can have our data encrypted at rest. We can updates on launch. Should the software stop working if it has not been updates and the user is offline? When it gets online, it can auto-update. The challenge of truth on the cloud is a bigger one. On a flaky or non-existant network, the cloud data may be stale. We already deal with this challenge in multi-cloud. Hard but not impossible. And the person on the other side of the screen is no chimpanzee punting on the keys. If we explain the status of the cloud sync properly, they do understand. Nothing changes in continuous delivery apart from the need to support updates from older versions for users that come back after months. The offline support we add can actually be a lot. It would be surprising to know how little data, a user needs on day to day basis. A simple LRU cache and a temporary cache storage for entered data that gets synced to the cloud will make the app feel native for majority of the use cases. Look again at the requirements. We can see how all of them can be met not to fullest but to an acceptable state. When online, you get almost 100% cloud native but when offline, the app is still functional.\nBefore going further and giving a homage to the history of computers lets put this change in perspective. In the early days, computing was difficult and we used to have machines like the Cray-1 upstairs that did magic and people used to time share it. Then machines became more powerful and the people got their own personal computers. Then we found use cases where we need data together and with browsers and mobile we had weak clients which were not good enough. From here we look into the future to see where the paradigm goes. If you look carefully, we are actually moving in circles. First the technology is expensive and we need a centralized server and then it gets cheap enough to provide flexibility to use is where you like. The cloud has shifted the pendulum away from flexibility and it has to shift back. And we do have a lot of power. Your wrist watch has more computing power than Cray-1. The phone that you would get for free with your data connection is more powerful than the entire cluster used to render the original Toy Story. It may be a difficult technical thing to do but so was provisioning a server from a single HTTP call. Until it wasn\u0026rsquo;t any more.\nI said at the start that I am a JavaScript developer. Why am I the messenger for this major change? Because JavaScript is a cloud first programming language. Cloud is natural to its asynchronous core. The challenge for JS has been native and the browser vendors have been working hard to meet the user\u0026rsquo;s definition of cloud native. What do they have to make this possible? Service workers. Service workers are those shared micro services within the browser that the servers control. They follow to most extent the definition of cloud native. They are microservices, deployed via code, sandboxed in a container setup by the browser which get updated by the latest version automatically. The experience works offline, they can LRU cache the pages, as well as the store the content in index dbs which can sync to the server when the user comes online.\nWas that it? All this talk just to introduce service workers. No, there is a lot more. Service workers show the concept but we can do a lot more if we do a proper daemon. You can do cross app communication. You can upload data hours after the user has clicked the save button, update when the user is not using the app. They don\u0026rsquo;t even have to think about it. It just works. We use node.js to create a service worker like daemon at my team. It is a true microservice acting as a server endpoint to the apps that you might have on your machine. It does some processing locally, provides data when the user is offline as well as collects user data to sync when the internet is available. Most of the time, the app does not even need to know or care about the fact that it is offline. The cases where the daemon does not have data requested are the only ones where the absence of the cloud impacts the user. The user can know that saves and syncs are happening but there is no wait if the data is present in the local cache.\nThese are the reasons for choosing node. Server technology is optimized to run 24x7. It is a single binary with a lot of text files and provide a good platform for the I/O intensive workload that the microservice does. And we can meet most definitions of cloud native. We don\u0026rsquo;t have the ability to ssh into prod and have a proper ops cycle and a release management team. It is a microservice by definition. What about continuous delivery. Things like puppet and chef are not meant for customer machines and for that piece we had to rely on our general desktop release infrastructure. There is auto-update in electron but nothing in node. Lucky for us, we already had the desktop update infrastructure at Adobe that we could piggyback on. And containers, well we could never get to containers because they are not built for a workflow like ours. The technology is maturing and I am confident future containers will be a lot stabler on windows and MacOS, with a minimal overhead and they can be packaged and shipped as daemons on the desktop.\nThat leaves me to talk about the ugly side of the picture. Apart from the fact that it a lot of hard work to setup a microservice on a customer machine, there are issues with server technology on desktop. The defaults are all made for the server where a gig of RAM is a lot on the client. Node has no support for features like proxies that servers don\u0026rsquo;t face. Node does not look like a traditional desktop service that is an exe with a few dlls. These are costs associated with doing something outside of the standard development track. As more and more of the develop community realizes the need for this approach, these costs would go down. The server technology is versatile and these one time costs provide a substantial benefit.\nAll technical approaches are bad ones if applied to the wrong problem. It all depends on the use case. The thing that we should remember as cloud native developers is that cloud and native are two different demands from the end user meeting which is fighting with the laws of physics. Once solution is duck typing by provisioning a microservice in the customer\u0026rsquo;s own hardware. Server technology like node.js is best suited for this job even though it will need work.\n","date":"2019-05-12T00:00:00+00:00","description":"Cloud Native for the user is native performance and cloud features - Presented at Cisco DevNet create 2019.","image":"/blog/2019/05/12/running-node.js-on-customer-machines./cover_hud129e95937d07529efdc43b4bac0cea5_318049_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/05/12/running-node.js-on-customer-machines./","readingTime":12,"series":null,"tags":["cloud-native","performance","cloud","native"],"title":"Running node.js on customer machines."},{"category":"Hugo","contents":"Unless you can hire an army of highly paid experts to support your trillion dollar business empire (cough Chrome), performance is one feature that cannot built as a feature. Performance is a mindset, a way of living, a choice that needs a decision very early in a product life cycle. Once the foundation is ready, and a palace built on those foundations, you cannot dig them out and live in the palace at the same time.\nWe see this day in and day out in software. In a zeal to get first to the market, validation of ideas and a product market fit wrong tools get chosen. There is no denying the fact that building the wrong thing will not get any success but a success built with the right tools is fleeting. Better implementation with a same level of everything else can provide the last mover\u0026rsquo;s advantage in ripping out an incumbent. While we always cite facebook as the insurmountable incumbent built with network effects, most products are easy to switch from and better performance is a can advantage that can live forever. We also forget that facebook has a half a billion dollar business with an army of developers to rewrite the programming language, the rendering engine and even the hardware for their hacked up software to run on.\nAn interesting study is the success of Hugo over an incumbent like Jekyll in the static site market share. This site migrated to Hugo from Jekyll and I found it so much fun that I decided to write a book about Hugo(which should be out in 2020). Jekyll had everything going right - first to the market by almost half a decade, built by the CEO of Github and exclusively supported by the most popular code hosting repository on the planet. Jekyll had a humongous lead over all the other systems and generators and its plugin ecosystem was strong, the over all market was growing. Hugo did not bring anything new to the table - a similar template system, built with a more arcane language, not supported by anyone natively, no big and proud sponsors when launched and an unpaid team of open source developers. Yet it stood strong and attracted developers from all around, getting a huge chunk of users from the Jekyll ecosystem and has continued to grow. The reason behind this is performance - the constant focus on the performance of Hugo over all the systems that are present. Once you start branding performance as a feature, everything you do, you think performance first and the result is a 50 times difference. Hugo has been low on features from all others as the plugin ecosystem is weak to non-existant and the developers have taken their time to build new features. But the community has waited and built tools around the core that they are willing move off from when the core adds the extended feature set. This is the thing about all software. In the end they mature. The most important use cases are the ones built in the first set and as much as we want to move the users to a new shiny thing, the core product after the churn remains the same.\nAt some point the new users are not from growth of the ecosystem any more and they are either students maturing or people you pull from the other competing products. At that point, your new features may not be as important as those that are already in the product and polishing them to be perfect makes more sense. Unfortunately that is the hardest thing to do. The organizations award new features, developers don\u0026rsquo;t like to look at old code and the programming paradigms evolve. And a product with a weak foundation never gets a chance to be fast.\nSuccessful products need a constant focus on performance. The prototype should not go to production. You have to pay for users that do free testing for you by incentives to keep them in the ecosystem as they would love to move out. It is important to have a long term performance plan and to move towards it with every release. It is even better to brand performance like uptime so that we can have incentives for improving it.\nSlow performance is the silent killer of products and if you have something that is slow as hell, it is time to build some competition.\n","date":"2019-05-09T08:06:22-07:00","description":"Performance is not something that can built as a feature later. Segue into Hugo's performance","image":"/blog/2019/05/09/performance-the-one-feature-that-you-need-to-do-early./cover_hue35c9ac59c30953d323d49d32cf63f8b_756962_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/05/09/performance-the-one-feature-that-you-need-to-do-early./","readingTime":4,"series":null,"tags":["hugo","performance"],"title":"Performance - the one feature that you need to do early."},{"category":"Toastmasters","contents":"Fellow members. Raise your hand if you have gone through the experience of getting custom tailor made dresses or have seen an arranged marriage. What do you think is common in these experiences with toastmasters. The awkward state of being measured constantly. It is difficult to be the center of attention. You get a feeling that your flaws are getting exaggerated and they will get reported at the end. The thing about custom tailor made clothing and arranged marriages is that, you do it because you need support. Those suites fit better. You rely on the experience of others for some level of advice. Similar are the objectives of toastmasters. You can get an audience amongst a group of friends or at a family event but at toastmasters speakers don\u0026rsquo;t just get any audience, there is an entire team with a defined set of objectives to help you succeed. The successful club series at toastmasters helps to improve the club conduct by talking about the responsibilities of the various roles in the club so that we can help the speakers and they in turn can help us.\nHere are the standard meeting roles that you would find in any toastmasters club. The toastmaster is the meeting manager whose role is to setup the agenda and to get it to flow. The toastmaster fills us the roles and introduces speakers. It is the responsibility of the toastmaster to warm the stage for the speaker and if the speaker is nervous to get on the stage, help him/her feel more comfortable. Topicsmaster has the responsibility of making the meeting more inclusive. Everyone has taken the misstep to come up to the meeting and they need to be punished with stage time. The topicsmaster has to figure out who has the least amount of stage time and needs to balance the usage. The most difficult part of a topicsmaster role is to keep the stage warm and exciting for guests to have the confidence to come up. They already took a major step forward and if the club needs to support them.\nThen we have the speakers who should have planned and prepared their speeches. They hold the heart of the meeting and their energy makes the meeting fly. The General evaluator introduces the evaluators, gets the report from the functionaries and evaluates the meeting. The general evaluator has the responsibility of completing the feedback loop and should be well versed in the meeting conduct at toastmasters. Next are the speech evaluators who provide oral and written evaluations. The timer emphasizes on the importance of time while the grammarian checks the formal usage of language. The ah counter measures the interruptions in the speech.\nThen we have the extended roles that we fill at Fair Oaks. This includes the Humorist who starts the day with a joke, the ballot counter who measures the votes and the word master which is a spin off from the grammarian role who counts the usage of the word of the day.\nAdditional roles present in other clubs or in the manuals which we curently don\u0026rsquo;t do at Fair Oaks include these. The Hear Master prepares 3 questions from the first half of the meeting and awards the most attentive listener. The Invocator starts the meeting with a prayer. The parliamentarian is a spin off from the general evaluator who understands the toastmasters bylaws and policies to help members. The Ha counter is someone we employ once in a while at Fair Oaks who counts the number of jokes where at least person laughed.\nApart from these there are club officers who help conduct the meeting. The Sergeant at arms sets up the meeting location and also returns it to the normal state after the meeting. The president helps the toastmaster ensure a functional meeting. As a leader, the president sets the mood of the meeting and does the opening and closing of the meeting and makes all announcements. The VP of Education charts the course of learning for everyone, helps us complete our assignments. This also includes the guests who don\u0026rsquo;t understand how toastmasters work. VP of PR makes the club known and maintains the website. VP of Membership performs the membership building in the club, conducts inductions and helps guests. The secretary maps the meeting minutes and is the archive of information about the officer and regular meetings. The treasurer takes care of all financial matters, the membership dues, the tax forms and the club solvency.\nA lot goes on in a Toastmasters meeting. Coming together every Sunday is the beginning, continuing to be here is progress and conducting such wonderful meetings as a team is success at Toastmasters. Thank you.\n","date":"2019-04-21T00:00:00+00:00","description":"Successful club series: Team involved in successfully running a meeting.","image":"/blog/2019/04/21/meeting-roles-and-responsibilities/cover_hu55a0e47d756fc1440d302a4d431ba79b_385011_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/04/21/meeting-roles-and-responsibilities/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Meeting Roles and Responsibilities"},{"category":"Toastmasters","contents":"Evaluation is a major part of a members toastmasters experience. It is a great honor to be an evaluator. Being an evaluator is a responsibility and doing it right is essential for the club to be successful. Evaluations improve our listening and impromptu skills and provide learning opportunities for everyone in the meeting. Raise your hand if you have had evaluations that have had a major impact on your speaking? Raise a hand if you have had underwhelming evaluations where you would desired more feedback. The successful club series at toastmasters wants to reduce the instances of underwhelming evaluations by providing tips for evaluators to be successful. This talk is not about how to win the evaluation contest. This talk is about ensuring that the speaker wins from the evaluation offered.\nLets talk about what the speaker is looking for an in evaluation. One - Immediate feedback. The speech is still fresh. Reinforce what the speaker did well and assist in finding areas of improvement. Two, offer methods of improvement. The speaker is looking for a new perspective, a fresh take on the topic. If you have seen or had round robin evaluations at our club, you would know would have seen how much alternative options can help improving the speech. Three - confidence. It takes a lot to come up here and speech. Don\u0026rsquo;t scare the speaker away. If the evaluator can pick up improvements from the previous speech it would do wonders.\nNext, let talk about style. Toastmasters recommends the tell and sell approach. A to and fro conversation can go off topic or can land into an argument. The one way feedback is the best way to pack maximum feedback in limited time. Toastmasters also recommends new members to have had some experience of being evaluated before they take the role.\nLets get into the meat of the matter. There are three parts to an evaluation. Before the speech. Talk to the speaker to get the objectives, what he or she is looking wants feedback on, and the concerns about the speech if any. During the speech be genuine. The speakers hate evaluators who are lost and not listening. Best evaluators I have had looking at me and not their phones. Their notes were phrases and not sentences. Another important thing to do is to put yourself in speakers shoes. If the speaker is finding it difficult to stay poised, don\u0026rsquo;t suggest hand gestures or stage movement. Being comfortable on stage comes first. Hiding behind the lectern is OK. Take short notes more like flash cards as you will forget everything by the evaluation session otherwise.\nDuring the evaluation session, the most important thing is to not cause a fight. The blame game does not belong in toastmasters. Words like \u0026ldquo;you did this and did not do this hurt\u0026rdquo;. Better to say \u0026ldquo;I think, believe or felt\u0026rdquo;. The toastmasters mantra is to focus on three senses - what I saw, heard and felt during the speech. The speaker has specific goals for the speech and our focus should be those. We need to make sure to measure the calm and confidence of the speaker on the stage and then give feedback based on the speaker\u0026rsquo;s comfort level. We need to make sure the speaker books for the next speech. The appreciation needs to be honest and insightful. There should be positive reinforcement and the closing remarks should always be upbeat and positive.\nA feedback that is all praise is useless. While it is important to be positive and encouraging, the evaluators who cover up flaws are doing the member and club a disservice. I know I\u0026rsquo;m bad at vocal variety. Give me one specific example from my speech where I could have spoken differently rather than not mentioning that it needs to improve or not talking about vocal variety at all.\nThe closing of an evaluation should tie to the opening. Evaluations are for motivation as well as for feedback. It should summarize the key points. Know the objectives before the speech, be sincere during the presentation and be honest and motivating during the evaluation session. Avoid pumping boilerplate text. An instance from the current speech or your personal experience is helpful. An evaluation is for everyone. The next time we have a evaluation based talk, I hope to see less number of people rasing their hands at underwhelming evaluations. Thank you.\n","date":"2019-04-14T00:00:00+00:00","description":"Successful club series: Evaluations should help not hamper progress.","image":"/blog/2019/04/14/evaluate-to-motivate/cover_hucecb568670d995ff8725383a886ec9cf_2148725_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/04/14/evaluate-to-motivate/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Evaluate to motivate"},{"category":"Toastmasters","contents":"Let me introduce you to this gentlemen. Anyone here could guess his name? He has been amongst the top role models on this planet for two decades, the nineties and the two thousands. What was his profession?\n Sachin Tendulkar   Cricket. It is a game where you would take a break if it rains to continue the next day. A game where after playing for a while, the players would take a tea break. Truly a gentleman\u0026rsquo;s game. And this guy is an epitome of a gentleman. Despite all his wealth, fame and success, he was always humble, controversy free, untarnished even when he did a short stint in politics and never boasting of his achievements, the little master - the greatest of his time. Unfortunately, as his ilk retired, the game changed into a 4 four hour money and entertainment festival and so did this world. The days when your work could speak of you are over. The idea of being humble and down to the earth may have been good earlier but are not any more. In the modern world you need to speak out - to broadcast yourself.\nIn the industrial age the access to information was limited and therefore everyone took time to assess the brilliance of an individual. Not so much any more. Restaurants die by yelp reviews. So do law practices, tax consultancies and other individual businesses. We had a massive uptick for Fair Oaks Toastmasters by fixing the online presence. Most job applicants get their linkedin screened. Developers are expected to have a github profile. In sales, they count your facebook connections and even print journalists are rated by twitter followers. These proxies have become replacements for actual tests of brilliance. It is a problem, but as individuals fighting this game might not lead to the best rewards and playing it is not difficult. I request you all to go home today and think this about this. Search yourself on google. Unless you are a Michael fighting with Michael Jackson and Michael Jordan, or a Donald competing with our president and also with a disney cartoon, there is a high chance you will be able to easily find yourself. Internet has an image of you, you like it or not. You cannot hide yourself. All you can do is direct it properly - shape it correctly, show your better side to the world, brand yourself, broadcast yourself.\nThe same goes in day to day life. The era of hire and retire in the same company has been over for a long time. The chances are if your boss retires, the company might find someone from the outside rather than to promote you. You may be brilliant but if you are not known for it, you might be forgotten. Being forgotten is amongst the number one reason for not getting what we deserve to get. In today\u0026rsquo;s world we need to be known. Here are three things to remember in day to day life. Keep a checklist of things that you worked on. You need to send that before the annual evaluation. If someone praises or thanks you for something, request them to direct this to your manager. If you get an award, display it on your desk, put it on your resume, inform your team about it by taking some champagne to work. Make yourself known. Broadcast yourself.\nI used to believe in internet anonymity, extreme humility and keeping a low profile. Singing your own praises felt like arrogance and I preferred that my work did the talking. Today I believe, it\u0026rsquo;s a loser\u0026rsquo;s play to be that silent. People around me knew what I was. But outside, associates etched their names on my hard work. Genuine innovation went out without being noticed while we have frivolous patents everywhere. I realized I need to speak up, to be heard and to be known. The last few years where I have worked on my image have done me wonders. That is a lesson I want to share with all introverts around me. Like it or not, you are leaving money on the table by not speaking when it matters. Open your eyes. Broadcast yourself.\nToastmasters is a great platform for bringing confidence. You are on the stage fighting your fears. You get real feedback on the articulation of your thoughts. What you say here won\u0026rsquo;t bring you down. Internet has made it so easy to let your work out and to be recognized and known. It will help you in your next job search, in promotions and day to day life. You do not need be anyone or have anything major to broadcast on Youtube. You can truly broadcast your content yourself. Your best content is your own personal brand. So literally. Broadcast yourself.\n","date":"2019-03-30T00:00:00+00:00","description":"Urging everyone to promote their own brand.","image":"/blog/2019/03/30/broadcast-yourself/cover_hucf0a8ad2e1f24b7c111d37cb75f7205d_1950348_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/30/broadcast-yourself/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Broadcast yourself"},{"category":"Javascript","contents":" In the previous post we discussed the shared data problem and the needs for locks in JS code if we are dealing with APIs that have state in them and we do not have the ability to get general purpose high-level stateless APIs.\nReader-Writer Problem One extension to this problem with is more complicated and also requires a more complicated solution is the reader writer problem. To understand it, lets look at the scene from the movie Despicable Me.\n  Despicable Me - Resume Scene   In this scene, the protagonist Gru is applying to adopt three girls and shows up to this lady who is inspecting his profile to figure out if he is a worthwhile candidate for that responsibility. While she reads his resume, two minions are writing it in parallel. They end up in a fight and garbage gets thrown out. We know the solution to this would be to have a shared lock that would allow only one minion to write at a time. Should we share the lock with the reader?\nThere could be a case where the minion has a typo and then the reader would get to see that. That presents a major problem. Maybe we should share the lock with the reader as well, so that when the reader is reading no one can write. This solution works but is extremely inefficient. What about instead of adopting 3 girls via one lady, Gru decided to spam every adoption agency on the plant. Should they all be in contention for the lock? Since the readers are not modifying data, the readers should be allowed to access in parallel.\nPreferred solution The preferred solution to the reader writer problem is to have a concept of a separate read and a separate write lock. The reader should not be allowed to write but in return we could have parallel access to the data.\n  Reader-Writer Problem   If there are readers already attached to the data store, other readers should be allowed but writers will need to wait for all other readers and writers to finish and will get exclusive access. Users of the reader writer would expect the following APIs for these locks:\n1 2 3 4 5 6 7 8 9  const x = await lock.read(async ()=\u0026gt; { // Do reading  return \u0026#34;Something\u0026#34;; }); const y = await lock.write(async () =\u0026gt; { // Do writing  return \u0026#34;Something else\u0026#34; });    All the logic behind the reader-writer problem should be hidden from the end user. We cannot achieve such a system with just living in the world of async-await. By definition, when the last read lock is released, we need to acquire the write lock as well as release the lock.read from being waiting on the function. Therefore we need to go down into the world of callbacks that make up the promises which are wrapped into async-await.\nThe library Here is the implementation of the boilerplate code to prepare the library:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class Lock { pendingReads = [] pendingWrites = [] async read(func) { // Cannot use await here  return new Promise(resolve =\u0026gt; { pendingReads.push({func, cb:resolve}); this.perform(); }); } async write(func) { // Cannot use await here  return new Promise(resolve =\u0026gt; { pendingWrites.push({func, cb: resolve}); this.perform(); } } perform() { ... } }    All the magic is performed by the perform method. In the code above, we create a list of pending reads and pending writes converting the async functions into callbacks. The perform method does all the locking using callback based code. Here is the perform method described above:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  class Lock{ ... perform() { // Perform the writes at a higher priority  if (this.state === \u0026#39;None\u0026#39; \u0026amp;\u0026amp; this.pendingWrites.length \u0026gt; 0) { this.state = \u0026#39;Write\u0026#39;; const {func, cb} = this.pendingWrites.shift(); func().finally(() =\u0026gt; { cb(); this.state = \u0026#39;None\u0026#39;; this.perform(); } } // Reads are lower priority.  if (this.state !== \u0026#39;Write\u0026#39; \u0026amp;\u0026amp; this.pendingReads.length \u0026gt; 0) { this.pendingReads.forEach(({func, cb})=\u0026gt; { this.state = \u0026#39;Read\u0026#39;; this.readInProgess++; func().finally(() =\u0026gt; { cb(); this.readInProgess--; if (this.readInProgess === 0) { this.state === \u0026#39;None\u0026#39;; this.perform(); } }) }); } } // Declare the private variables within the class  readInProgess = 0 state = \u0026#39;None\u0026#39; }    The method above is all that it takes to enable the perform method. All the magic is in those 25 lines of code that too repeated twice. The state variables contains the current state of the Lock. It can have three values, None, Read and Write. Note that this object should be read-only for anything outside of this class. At line 5, we check if there is no lock acquired and we have writes pending. If so, thew write lock is acquired and the write task is given an opportunity. The shift method on pendingWrites ensures the First In First Out(FIFO) queuing of the locks. We use the finally from promises so that we don\u0026rsquo;t have to care about the return or rejected values and they can be passed on to the caller transparently. As soon as the write is complete, the lock si freed and we call perform again.\nIf there is nothing to write and there is either a read lock or no lock in progress, then reads can continue. Since all reads can be run in parallel, we need to track the number of reads in progress. Once all reads are done, we can call the perform again to run pending writes.\nNote that it is a good idea to have the reads below the writes. If there is no lock and both read and writes are pending (happens after a write is complete), it is preferable to get through a write because a write lock is more likely to be starved because of new readers joining than a read one.\nWe could extend this further with features like like maximum read locks as well as timouts. These can be implemented easily by extending this method with racing for timeouts and basic bound checking.\nRead-Write locks are extremely powerful. We could use them for locking access to anything. The shared data and the reader-writer problems are everyday problems in back-end code which deals with a huge number of users accessing resources in parallel. We have been saved by database transactions doing this internally but as soon as we reach a complex codebase like multi-region configuration, locking will be involved. Javascript with async await is a first class citizen in programming languages and it is ready to take on complicated programming tasks normally reserved for the lower level brethren.\n","date":"2019-03-21T00:00:00+00:00","description":"Reader-Writer problem in Javascript with async await","image":"/blog/2019/03/21/shared-data-with-async-await-part-ii/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_3294336_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/21/shared-data-with-async-await-part-ii/","readingTime":6,"series":["Async Await"],"tags":["javascript","async-await"],"title":"Shared data with Async Await - Part II"},{"category":"Javascript","contents":" While JavaScript has strong support for asynchronous code, we rarely encounter issues related to asynchronous code as frontend developers. As soon we move to doing some back-end, we realize the inherent complexities of asynchronous programming.\nThe shared data problem One of the most important problems in asynchronous programming is the shared data or the critical region problem. To understand this problem have a look at the following figure:\n  Shared Data Problem   In this figure we have stateful APIs from the data store with the basic access to read and write but no in-built transaction support. This type of thing does not happen with modern databases because they have transactions but we could be using raw filesystem for storage where such a thing can take place. In this example the data store has a 100 dollars in the account with two functions one that pays $20 to the account and the other than takes $20 from it.\nThe basic structure of both the functions is the same:\n1 2 3 4 5 6 7 8 9  async function pay(amt) { const currentAmount = await readData(); await writeData(currentAmount + amt); } async function take(amt) { const currentAmount = await readData(); await writeData(currentAmount - amt); }    If both the functions are called in parallel there could be problem. Both can read and write at the same time thereby overwriting the value written by the other. In this example the readData returned $100 for both the function but the write of $80 was overwritten and the actions of the take method are lost.\nUsing locks as a solution The shared data problem is very similar to the problem of having two people trying to drink coffee from the same tumbler with one straw. If there is not understanding between them, it would be chaos. A solution to this problem is to protect the tumbler or the data store in case of the banking example with a lock. Only one method is allowed to use the data store at a time. This way the functions pay and take will be executed sequentially rather than concurrently and we will not face the shared data problem. In languages that are multi-threaded, locks are complicated as they need to be atomic CPU operations. Not so much in JavaScript. The single threaded task based approach of Javascript over the event driven model ensures that we can just have a regular JS variable in the main thread that instructs the disk pooler or the network card is good enough. Here is the implementation of a basic mutex lock in Javascript.\n1 2 3 4 5 6 7 8 9 10 11  let mutex = false; async function lock() { // Timeout is a wrapper over set timeout that makes it async.  while(mutex) { await timeout(100);} mutex = true; } function unlock() { mutex = false; }    The usage of this is very simple as well:\n1 2 3 4 5 6 7 8 9 10 11 12 13  async function pay(amt) { await lock(); const currentAmount = await readData(); await writeData(currentAmount + amt); unlock() } async function take(amt) { await lock() const currentAmount = await readData(); await writeData(currentAmount - amt); unlock(); }    This solves the shared data problem by ensuring that only instance even of take or pay could access the data at a time. While logically this solution has no issues, there is a subtle problem that this introduces which is not in the code but in the structure. In case of an exception or rejection, the unlock would never happen. While we are writing this code as a single function, no one prevents a programmer from refactoring it and making mistakes. The big rule of programming is to be safe by default and allow going to the unsafe versio only if it is essential for a certain use case. Here is a mistake that could happen:\n1 2 3 4  async function work() { await lock(); doSomething(); }    The lock call could be anywhere. The problem with allowing separate lock and unlock is that, it introduces the possibility of being called individually. A forgotten unlock would cause a leak. The lock would not be available any more and the program will come to a halt waiting. The forgotten lock is more dangerous as something would happen without a lock and some method could unlock a lock acquired by someone else. These issues are extremely difficult to debug. a better solution is to disallow this two step process and provide a one step method:\n1 2 3 4  async function transaction(cb) { await lock(); return await cb().finally(unlock); }    The transaction manages the lock and unlock both for resolve and reject cases. This ensures there is no leaks or accidental unlocks sprayed around in code. This solution is saner and less error prone than the individual lock and unlock call.\nDeadlock Deadlock is a concept when there is cyclic waits. Method A acquires a lock and then waits for method B while method B needs the same lock to continue execution and is waiting on A to release the lock. There is no standard way in code to prevent a deadlock. While writing code, we need to be careful to not have such a situation, by putting the minimal amount of code in a transaction and making sure we acquire all locks needed in the same order everywhere.\nIn the next post, we will go an advanced version of the shared data problem - the reader writer problem.\n","date":"2019-03-20T10:00:00+00:00","description":"Handling stateful APIs with shared data in async await based node.js with locks","image":"/blog/2019/03/20/shared-data-with-async-await-part-i/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_703798_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/20/shared-data-with-async-await-part-i/","readingTime":5,"series":["Async Await"],"tags":["javascript","async-await"],"title":"Shared data with Async Await - Part I"},{"category":"Javascript","contents":" In the previous post  we used memoize to prevent the parallel calls to a function. In this post we will be extending the memoize implementation to handle more of the situations that may arise with asynchronous functions and extending memoize to handle those additional cases.\nHere is the memoize function from lodash.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  function memoize(func, resolver) { const memoized = function(...args) { const key = resolver ? resolver.apply(this, args) : args[0]; const cache = memoized.cache; if (cache.has(key)) { return cache.get(key); } const result = func.apply(this, args); memoized.cache = cache.set(key, result) || cache; return result; } memoized.cache = new Map(); return memoized }    Adding State The first extension an asynchronous function needs to be able to determine the state of the promise. A promise can be resolved, rejected or pending. In Javascript the promise state is not available on the promise object. We need to extend it to provide the state information.\n1 2 3 4 5 6 7 8 9 10 11 12  function appendState(promise) { if (promise instanceof Promise) { promise.state = \u0026#39;pending\u0026#39;; promise.then(x =\u0026gt; { promise.state = \u0026#39;resolved\u0026#39;; }); promise.catch(e =\u0026gt; { promise.state = \u0026#39;rejected\u0026#39;; }); } return promise; }    Note that we are attaching the state to the original promise object and not returning a new promise object. This makes it unnecessary to have the rejection re-thrown or the resolution returned. This method should be called before line 9, in case the return value is a promise. We are not checking that the function called is async and therefore would not want to crash the function by adding a .then to a non-promise.\nGeneric rejection method The second extension we would like to do to the memoize method is to have a rejection method on the return value. We could do it via adding code to memoize like I mentioned in my byteconf talk, it is easier to add a selection method so as to make it generic. After adding the rejection method this is what memoize looks like:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  function memoize(func, resolver, rejector) { const memoized = function(...args) { const key = resolver ? resolver.apply(this, args) : args[0] const cache = memoized.cache if (cache.has(key) \u0026amp;\u0026amp; (!rejector || !rejector(args, cache.get(key)))) { return cache.get(key); } const result = func.apply(this, args); appendState(result); // Append state from above  memoized.cache = cache.set(key, result) || cache; return result; } memoized.cache = new Map(); return memoized; }    Memoize takes an optional parameter rejector which can reject a cached value. This way we could reject certain cached data based on conditions.\nHere is a sample rejector:\n1 2 3  function dontCacheRejections(args, promise) { return (promise instanceof Promise) \u0026amp;\u0026amp; (promise.state === \u0026#39;rejected\u0026#39;); }    This way of the original server request fails, we do not cache and continue using the failure results.\nThe save problem One very common problem in programming is the save problem. Say you have some document being edited and you want to trigger a save on it. If a save is in progress, you should not start saving in parallel but should wait for the save to complete. Saving should happen if the save is not in progress.\nExtending memoize to perform this task is relatively simple. Here is the rejection method to implement the solution to the save problem.\n1 2 3  function dontCallInParallel(args, promise) { return (promise instanceof Promise) \u0026amp;\u0026amp; (promise.state !== \u0026#39;pending\u0026#39;); }    In this case only if the promise is pending execution, save will not be executed. Otherwise save will go through. You might want to extend it further to delay the save call (something similar to debounce in concept). Here if the save is in progress, you want to call save again after the save is complete but if it is not running, you can call it right now.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  let saveWaiting = false; function delaySaveIfRunning(args, promise) { if ((promise instanceof Promise) ) { if (promise.state === \u0026#39;pending\u0026#39;) { if (!saveWaiting) { saveWaiting = true; promise.then(() =\u0026gt; { saveWaiting = false; object.save.apply(object, args); }); } return true; } return false; } return false; }    The above rejector also has a side-effect of delaying the save call to be applied if the save is in progress.\nIn these posts, we saw how powerful it can be to share functionality across async methods via creating wrappers that can solve many of our day to day problems in a generic way that could be abstracted out into a library.\n","date":"2019-03-20T00:00:00+00:00","description":"Extending memoize for async wrappers to solve the multiple save problem","image":"/blog/2019/03/20/method-wrappers-in-async-await-part-iii/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_5505055_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/20/method-wrappers-in-async-await-part-iii/","readingTime":4,"series":["Async Await"],"tags":["javascript","async-await"],"title":"Method wrappers in Async Await - Part III"},{"category":"Javascript","contents":" In the previous post we discussed about creating wrappers over asynchronous methods to provide some extra functionality. In this post we will be discussing creating a more complicated wrapper that uses the promises that the async function returns to solve a very common parallel calls problem.\nParallel calls problem The parallel calls problem is a very common problem in software development. Suppose you have an asynchronous method get that gets the data from the server. This data is not always needed and therefore one would want to delay the call for this data until the need arises. The data can be used at multiple places and they do not have a common ancestor or flow that you could call from. The desired behavior that we would like to achieve is that this method is called from multiple places but should only fetch from the server once. If a fetch is pending the new call should also wait for the same fetch and if the fetch is complete, the data should be returned as is. Unless new parameters are required to be sent to the server in which case this should be refreshed. Here is an attempt at creating the code with a simplified problem where there are no arguments:\n1 2 3 4 5 6 7 8 9 10 11 12 13  let data = null; function get(cb) { if (data) { cb(data); } else { callbacks.push(cb); } if (callbacks.length === 1) { ... data = response; callbacks.forEach(cb =\u0026gt; cb(data)); } }    Implementing such a system in callbacks is so complicated that the JavaScript developers gave up on using this behavior at all. We got into the worlds of state stores in frontend development which are not really storing the program state but the data that we get from the server. Here we have support for updating all the watchers/user interface when the data changes. Then we have one call that calls the server and populates the data. That call is where we check if a call is needed.\nSolution with async await With the async guarantees, the parallel calls problem becomes a lot simpler to solve and we can build a wrapper that can work in all cases. That wrapper will perform all the tracking and will be a lot less code than we need to write to get a basic version up and running. The code to perform this task is not something we need to write from scratch. We have been using this for years. The code that we need is the memoize function. Here is the implementation of memoize from Lodash.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  function memoize(func, resolver) { const memoized = function(...args) { const key = resolver ? resolver.apply(this, args) : args[0] const cache = memoized.cache if (cache.has(key)) { return cache.get(key) } const result = func.apply(this, args) memoized.cache = cache.set(key, result) || cache return result } memoized.cache = new Map(); return memoized } // Usage let get = memoize(async (...args) =\u0026gt; { ... return data; }); const A = async () =\u0026gt; await get(\u0026#39;x\u0026#39;); const B = async () =\u0026gt; await get(\u0026#39;x\u0026#39;); const C = async () =\u0026gt; await get(\u0026#39;y\u0026#39;); const D = async () =\u0026gt; await get(\u0026#39;x\u0026#39;); // A and B in parallel await Promise.all([A(), B(), C()]); // Get is finished already. await D();    Lets see how this works for an asynchronous function. When we get a method call, we resolve the parameters to ensure we can re-use the server data only if we are passing the same parameters to the server. In line 5 we check if this code has been called before and return the previous synchronous return value in case it has been called before. With the async guarantees, we know that the passed function returns a promise. Whether the method has completed execution or it is still in progress, the promise object does not change. Multiple functions can await on the same promise.\nWhen A calls await get() and it is first call with these parameters, the code reaches line 9, where the original method is called and A begins to wait on the returned promise which is also cached by the memoize cache. Next, when B calls await get(), the memoize returns the cached promise but the underlying method is not called again. B waits on the same promise. When the promise gets resolved or rejected, both A and B can continue from the await statement. Meanwhile when C calls the same method, it passes different arguments and therefore the if check at line 5 fails and we get a fresh call to the internal function.\nAfter the promises are resolved, when D calls the get method, the resolved promise is returned. This resolved promise is ready to be used and D can continue after the next tick. Async-await guarantees the methods are executed as asynchronous.\nWrap Up With the help of the async guarantees the regular memoize method that we have been using for so many years becomes very powerful and for asynchronous code, it can do proper memoization for them. There is no code change needed between synchronous and asynchronous code to achieve memoization.\nIn the next post, we will extend the memoize method to do a better job with rejections and also solve a little more complicated save problem in our wrapper.\n","date":"2019-03-19T00:00:00+00:00","description":"Using async wrappers with memoize to solve the parallel calls problem","image":"/blog/2019/03/19/method-wrappers-in-async-await-part-ii/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_3005652_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/19/method-wrappers-in-async-await-part-ii/","readingTime":5,"series":["Async Await"],"tags":["javascript","async-await"],"title":"Method wrappers in Async Await - Part II"},{"category":"Javascript","contents":" Wrapping methods is not very common in day to day programming but it is a very useful concept. We could abstract out shared functionality over methods with a defined signature in a wrapper and not have to repeat the same tasks again and again. The semantics of methods having return values that need to be returned sometime makes regular use cases of calling methods without wrappers cumbersome. In the world of JavaScript, methods like debounce and throttle have been popular since the very beginning of the programming language. These utility methods provide code that can take an existing method and provide additional functionality without interfering with the functionality. Async-await provides more avenues where this abstraction can be used to add more functionality to methods which otherwise takes a lot more effort to add. In this post we will discuss some advantages of async that makes wrapping easier as well as some common methods that make sense wrapped.\nAsync guarantees Async if used in the codebase provides certain guarantees that makes writing wrapper using async await much easier. some of those guarantees are built into the JavaScript runtime, others come from the expected use of async with await. Since async is meant to be used with await, methods that are created using async provide features that makes the lives of library developers a lot easier. They can point to cases that the code does not handle as bugs in the code of the library users rather than special cases that need to handled by the wrapper methods.\n It always returns once The biggest problem with wrapping callbacks is that there are valid cases where the callback can be called multiple times and also when it is not not called at all. Tracking these cases makes a wrapper very complicated. Also, we are not able to determine if the missing callback or the duplicate callback is a human mistake or as designed. This makes bugs difficult to track and wrappers have to deal with a lot more complexity than should be required in most use cases. This problem does not exist for async. It is meant to be used with await and it can assumed that it will always return once and if it implemented internally through some other mechanism that does something different, it likely a problem with the implementation than a special case that the library has to handle.\n There is always a single return value Extending functions that take callback as the last parameter is complicated. Should you add a parameter after callback to maintain backwards compatibility? Similar is the case with return values. Since callbacks can take multiple return values, the complexity for handling multiples becomes a responsibility of the wrapper. Even though modern JavaScript provides easy to use object destructing syntax, {x, y} = foo(), most callbacks take multiple arguments (more than the err, data that is standard in nodejs), in many cases as the refactor to return an object is lot more work than just ading a parameter. The complexity to handle those additional return values lies on the wrapper.\n It is always a promise Promises have well defined error semantics, more than that, with promises we are always sure about the nature of code is always async and the caller will get the response after some time. There are methods where the callback come back immediately in a non-blocking manner (eg [].forEach()). This makes wrappers hard to write as we cannot do something async with a guarantee. That can potentially break programs that assume that the function is synchronous. Some functions are asynchronous only in a certain cases and those cases are never hit by certain programs. All that complexity can be avoided in async thanks to the assumed usage with await and its general structure.\n  Measuring time The global console object comes with two methods time and timeEnd. They are meant to be used as points to mark time to measure in the console. For each console.time, it is meaningful to have only one console.timeEnd. Without the timeEnd call, the time call is not useful. These methods were implemented before async and therefore such a situation arises. A better option would be to have a wrapper that would take a async function and time it.\n1 2 3 4 5 6 7 8 9 10 11  async function time(name, method) { console.time(name); return await method().finally(() =\u0026gt; console.timeEnd(name)); } // Usage async function x(...args) { return await time(\u0026#39;x\u0026#39;, async () =\u0026gt; { // My code using args  }) }    The power of async is extremely clear in this case. We know the return value is a promise. The .finally takes care of being called both in error and return cases. the waiting and the wrapping can work perfectly.\nThe approach is extensible to add more features on need:\n1 2 3 4 5 6 7 8 9  async function time(name, method) { console.time(name); const start = Date.now(); return await method().finally(() =\u0026gt; { // Not waiting for fetch. Since there is no reason for performance monitoring to be waited upon,  fetch(`/performanceMonitoring?time=${Date.now() - start}\u0026amp;name=${name}`); console.timeEnd(name) }); }    This code adds calling to the server. We can also add checkpoint support easily.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class CheckpointBuilder { ... } async function time(name, method) { const builder = new CheckpointBuilder(name); await method(builder).finally(() =\u0026gt; { builder.post(); }) } // Usage async function x(...args) { await time(\u0026#39;x\u0026#39;, async (builder) =\u0026gt; { await doSomething(); builder.addCheckpoint(\u0026#39;Done something\u0026#39;); await doSomethingElse(); }) }    Here we created a class to handle all the communication with the server with support for more advanced features like a checkpoint. A good design pattern for implementing such a request builder is the Builder design pattern.\nWe could simplify some of these wrappers using decorators if you are using babel/typescript.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // Convert to decorators function Time(key) { return function (target, functionName, descriptor) { const x = target[functionName]; descriptor.value = async (...args) =\u0026gt; await time(key, async () =\u0026gt; await x.apply(target, args) ); }; } // Usage class { @Time(\u0026#34;key\u0026#34;) async function foo (...args) { ... } }    This way we have common 1-line code that can perform tasks that require a lot of functionality for async code that is properly abstracted.\nIn the next post we will discuss more complicated wrappers required to solve the parallel calls problem.\n","date":"2019-03-16T00:00:00+00:00","description":"Making cases for creating wrappers around asynchronous methods to perform additional tasks","image":"/blog/2019/03/16/method-wrappers-in-async-await-part-i/cover_hu9d46ba99487955b42970676b342cf1ce_3959900_100x100_fill_q75_box_top.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/16/method-wrappers-in-async-await-part-i/","readingTime":6,"series":["Async Await"],"tags":["javascript","async-await"],"title":"Method wrappers in Async Await - Part I"},{"category":"Toastmasters","contents":" Introduction Summer is a very important season. The sun is what provides the life on the planet. Now being the closest to it, in summer we get a lot more energy, sometimes too much that it drains us out. but there are a lot of things we can do in the sun.\nQuestions  Is Air conditioning a good this?\n Favorite memory of summer\n Which season is more romantic, summer or winter?\n Favorite movie set in the summer?\n If you could choose to be born any season, would you choose summer?\n If you could choose, would you choose to be married in summer?\n Which is your favorite destination in summer.\n Please share some childhood memories from the summer.\n Summer is marked with vacations and kids at home. Do you think it is better thay are school all summer?\n There is always winter in the one half of the world. Would you want to travel across the ocean to get back winters?\n Even though we get fruits all year - summer is supposed to be season of mangos and melons. What are your favorite foods for summer?\n In summer we can travel light. Is summer the best part of the year for travelling?\n Please share some trips that you\u0026rsquo;ve had during summer.\n  ","date":"2019-03-15T01:00:00+00:00","description":"A set of table topics questions themed on summer.","image":"/blog/2019/03/15/summer-table-topics-questions/cover_hu67c38fcaf01a003e0f43d1919b965f81_800588_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/15/summer-table-topics-questions/","readingTime":1,"series":null,"tags":["toastmasters","tabletopic"],"title":"Summer - Table Topics questions"},{"category":"Javascript","contents":" The async-await feature in modern JavaScript is very powerful and can provide a lot of functionality with very little code. The more we get into using async-await, the more we realize that it is not just syntactic sugar, it is a way of thinking. The more we use async await, the more we feel liberated and empowered. Here are some of the snippets in the order of increasing develop power and productivity and not necessarily the increase in code size.\n1. Waterfall execution Waterfall execution of async-await involves just adding await anywhere in the code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  async function foo() { ... // Always wait - like calling a callback.  x = await foo1(); ... // Same as above. The success value is used as a condition  if(await foo2()) { ... // Wait only if the condition is true.  // In callbacks, the code after the `if` statement needs to be called twice  await foo3() ... } for(...) { // Run `foo4` one after another waiting for it to complete in the for loop.  await foo4(...); } ... }    In cases like loops and callbacks, tracking function calls in callbacks is difficult and there are significant benefits of going to async.\nCaveat array.forEach cannot have await. Since it returns nothing, we cannot wait for anything. In modern JS, there is little reason to use array.forEach. A for..of loop is better in almost all cases where foreach has been used earlier.\n2. Fire and forget Is is not necesary to use await with async. We can just call and async method and not use await. This way the method would complete when it wants.\n1  fetch(\u0026#34;analytics/activity?userId=100\u0026#34;);    Note that this will also ignore all errors. A better implementation would be to write.\n1  fetch(\u0026#34;analytics/activity?userId=100\u0026#34;).catch(e =\u0026gt; console.log(\u0026#34;Error sending analytics\u0026#34;, e));    3. Catching one of errors You can use .catch to catch one of errors in the asynchronous code.\n1 2 3  await foo1(); await foo2().catch((e) =\u0026gt; console.log(`Got error ${e}but not throwing`)); await foo3();    You can also rethrow errors.\n1 2 3 4 5 6 7  await foo1(); await foo2().catch((e) =\u0026gt; { console.log(`Got error ${e}and rethrowing`); e.additionalData = \u0026#34;data from scope\u0026#34;; throw e; }); await foo3();    You can do cleanup using .finally\n1  await x.finally(() =\u0026gt; \u0026#34;Cleanup resources. will be called even in case of errors. No need to worry about the return value or the exception.\u0026#34;);    4. Delayed await The objective here is to do something in parallel to the synchronous call. This is a very common pattern in network requests. Since they take a lot of time, it is a good idea to trigger them as soon as possible and then do additional tasks like rendering the UI after the network request has been sent. If the response comes early, it can wait but in most cases, it won\u0026rsquo;t be ready early. But we will be able to save some extra time that was taken by additional code (like crunching the UI together) by sending over the requests early.\n1 2 3 4 5 6 7 8 9  async foo() { ... await fetch() ... } const promise = foo(); // Do some parallel tasks ... await p;    5. Parallel functions Waiting for multiple asynchronous functions running in parallel can be achieved by waiting on Promise.all. Very useful if we have multiple requests on the server that are independent but we need to wait for all of them. We can combine this with method #4 above.\n1 2 3 4 5 6  const tasks = [ fetch(p1), fetch(p2), fetch(p3) ]; responses = await Promise.all(tasks);    Note that this will not wait for all requests in case some request gives an error. For that we need Promise.allSettled currently on track for standardization in JavaScript.\n6. Async function for each array value Another common pattern is to have asynchronous processing of some data coming from an array. If we need to perform that one by one a for..of look is the solution. But if we want to run that in parallel the following code can be used.\n1 2 3 4 5  await Promise.all([...].map(async x =\u0026gt; { ... await foo(x); ... }));    7. Racing asynchronous functions It is difficult to appreciate exiting when the first of the two asynchronous methods completes. It feels wasteful to run two competing calls. But there are valid use cases for racing asynchronous functions. One of the best use cases is to have a timeout. We could race a method against set timeout and it will provide a one time timeout.\n1 2 3 4 5  // setTimeout async version const timeout = async (time) =\u0026gt; new Promise(resolve =\u0026gt; setTimeout(resolve, time)); // Adding a timeout to fetch await Promise.race([fetch(...), timeout(2000)]);    The first line is wrapper over setTimeout to make this async-await compatible. In the next line we race fetch and timeout. The one that completes first returns. If fetch returns first we get the response object. If fetch fails, it would reject immediately and we can catch the error in a try...catch or a .catch(() =\u0026gt; ...) block. If fetch succeeds under 2 seconds, its return value is present, otherwise timeout would win the race which would resolve to undefined. We could change this to an error or reject it in case of the timeout.\n8. Memoization and solving parallel calls In most cases when we call the server, we would like to use the value at multiple places but would not want to call the server multiple times. Traditionally this ahs been solved by keeping this output value in a variable (most likely in a store like mobx or redux) and calling a method once to fetch it. Such an approach is needlessly verbose and it prevents us from making the components independent as they depend on someone else to do server fetch. One solution to this is to use memoization - caching the return value from the function if it is called with the same parameterd. The challenge here is that the async functions can take a long time while the download is in progress, there is no data to cache. This problem is not there in async methods as we can cache and reuse promises easily.\n1 2 3 4 5 6 7 8 9 10 11  // Convert to ES6 Decorator function Memoize() { return function (target, functionName, descriptor) { descriptor.value = _.memoize(descriptor.value); }; } @Memoize async get() { ... return data; }    This method will only call the server once for any get call and all callers will get the response as quickly as possible. We are using an off the shelf memoize from lodash in this case and ECMA decorators making the code fun to read.\nWe can also create decorator wrappers for method like console.time, the scope of which discussion is beyond this post.\nHope you find these useful and are able to use these in everyday life.\n","date":"2019-03-14T00:00:00+00:00","description":"A set of code snippets showing various design patterns to be successful in the world of async await","image":"/blog/2019/03/14/snippets-for-success-with-async-await/cover_hu0c42532c9015fe6a920a6669d7997cd7_227181_100x100_fill_box_center_2.png","meta":null,"permalink":"https://atishay.me/blog/2019/03/14/snippets-for-success-with-async-await/","readingTime":6,"series":["Async Await"],"tags":["javascript","async-await"],"title":"Snippets for success with Async Await"},{"category":"Javascript","contents":" Fundamental Operators To understand at the fundamental level how the event driven mechanism in node.js works, lets start with the fundamental design of the computer and understand how the computer works. Still looking at the very high level and ignoring the magic that the OS provides, there is something called the instruction pointer in the CPU. This points to the next instruction in the assembly language that is executed. All programming languages eventually go down to assembly as that is what the hardware understands. The assembly language provides very basic bare-bones primitives which are used to build the entire feature set of all programming languages. So we have a special region in the memory where the executing code resides (in dynamic languages like JavaScript even this is very murky but still makes it easy to understand what\u0026rsquo;s going on) and the instruction pointer goes line by line through this code. You might have seen such a thing in the debugger when you debug your software application. The pointer jumps slightly in javascript because we have multiple executable statements in one line of code. In assembly it is not the case and we will find it running sequentially like shown in the Figure 1.\nOne basic operator fundamentally provided at the hardware layer is the conditional jump operator. This provides the basics of all the other functionality that traditional programming brings. What this provides is the ability to jump to a different line in code if a certain condition is true. We use it almost as is for the if-else conditional like shown in Figure 2.\n Sequential Execution    Conditional Execution    Loop Execution    Function Execution   \nWe also use it for the looping dispatch where we have a jump back to somewhere earlier in code. This is understood cleanest in the do..while loop in some programming languages, but functionally the for and the while loops are built over the same construct. This type of construct is shown in Figure 3.\nThe other constructs like functions are just two jump operators one goes into the special piece of code and the other comes back to the main executing code. But it still fundamentally is the same operator. The functional construct is shown in Figure 4.\nAsynchronous programming Asynchronous programming is fundamentally different from regular programming. In asynchronous programming, we have two things happening in parallel. These two things not necessarily mean two CPUs/threads running in parallel. There could be multiple things that happen together. The hard disk has a spooler that actually writes from the RAM to the disk. The CPU is available to do something else while the write is happening. Similar is the case with fetch being done via the network card or console being written to the screen. There are also multiple CPU threads or physical machines in certain APIs like crypto in node.js. the concept of two things done in parallel is not alien to node/javascript which is built primarily as the language around optimized network communication. Most machines are multi-core and therefore there are multiple CPUs running in parallel. We also have GPUs that can do processing(GPGPU) in parallel to the CPU working on something else.\nA piece of asynchronous code logically looks like what is shown in Figure 5. This is exactly how we do multi-threaded programming in most use cases. When the control reaches an asynchronous method, the second thread or hardware picks up the task and continue running in parallel. It could access the same resources and run at same or different speeds which the OS does not give the control over. It is very difficult to understand it across compiler optimizations and the assembly format of the hardware anyways. In traditional multi-threaded programming, at some point if we want to do some work in parallel we would fork a thread and then have the two threads running in parallel until we are done with the parallel operation. The join operation is what follows next where the faster thread waits for the slower thread to catch up and the resources are merged and the execution continues.\nIn most programming contexts, there is little we could do in parallel to the regular operations like filesystem access or even connection to a database. Therefore even though the CPU could potentially be used for something else, the program lets the OS make this decision as it does not have anything else to do. In most I/O bound use cases like those of doing CRUD operations on a database in response to network queries and we have to read from a file on disk or from the database connection over a high speed local network, the CPU wait is not too much of a problem. There is very little the CPU can do without the data and the Operating System is efficient in reallocating resources to another threads if a particular thread is waiting for the some I/O processing. The problem arises when we have hundreds of work items done in parallel like in the case of an application server responding to network requests. Having hundreds of threads is resource intensive and the OS is not able to do a good job with it. Javascript the language was built around extremely slow network requests and therefore instead of hiding the complexity of multiple hardware pieces doing multiple jobs, cherishes and exposes the concept in full flow. That is why most of the core methods in node are asynchronous and provide a promise or a callback.\nTo achieve the behavior that logically looks like the multi-threaded behavior in Figure 5 but can reuse the same flow of execution, the node runtime maintains a queue of tasks that the other pieces of hardware complete. So it never waits for the disk pooler or the network card. As soon as it reaches a statement that needs to send some work to the disk pooler, it takes the scope of the callback and ensures that it remains in the RAM by marking that used. Then the runtime continues. The other task is triggered and node does not wait for it. When the node reaches an end of the current task or things like an await statement, it looks at the queue of tasks that are completed by the other pieces of hardware that are waiting for further execution. It picks up the first task and attaches its scope to start execution. Therefore the main thread only halts if there is no work to do and in those cases if there is no timers or other hardware scheduled to do work, the node program quits. Figure 6 shows how this thing works. As programmers the act of picking up other task by the node process is something that may not impact us and therefore we remain oblivious to this event driven nature underneath. We can continue to believe that the current flow waits for the other hardware when we write await as logically that is correct. But instead of another thread modifying another variable, it is the same thread that performs this logic.\n Logical Async    Event Driven Async    If you have done lower level C++ application programming, you must feel this thing to be nothing new. The application run loop in all Operating systems works like this. They are all event driven. The uniqueness of node/javascript is not the event driven architecture but instead the adoption of this reality. Whereas languages hide this complication under synchronous read calls from the filesystem and try their best to make the programmer not worry about this detail, node/javascript embraces this. All methods are asynchronous and the runtime itself provides this queuing mechanism. In languages like C, we have the build it ourselves. Nginx is an example of great open source software that embraces this event driven architecture. The thing with JS is that this is forced upon every program by the standard library. The concept of scopes which all can reside in the heap memory, self contained objects that do not depend on any pointers to a class structure are designs to make the task of maintaining the queue easier. Therefore every program is fast, even though it may not be maintainable and may feel ugly. Early version of node software was ugly, error prone and confusing to use. Performance is the most difficult thing to patch on to any runtime. The other problems are solvable. Features like async await enable programming like Figure 5 without the overhead of making the thread wait. This concept has been so powerful that almost all languages have upended their standard libraries to add support for these features.\nNode\u0026rsquo;s event driven architecture is neither new nor unique. But node\u0026rsquo;s standard library was the first to embrace the event driven reality of working with multiple pieces of hardware at a large scale and forced all programmers to care about it. It has reaped the rewards to be hottest technology on the servers 10+ years and still running.\nThis post is accompanying my speech at Byteconf JS 2019.\n","date":"2019-03-13T00:00:00+00:00","description":"A figurative explanation for the event driven model that is present in node.js","image":"/blog/2019/03/13/understanding-the-event-driven-nature-of-node.js/cover_hu3dcd6f1f63b5cc45ac9a587952e9caf7_370383_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/13/understanding-the-event-driven-nature-of-node.js/","readingTime":8,"series":["Async Await"],"tags":["javascript","async-await"],"title":"Understanding the event driven nature of Node.js"},{"category":"Toastmasters","contents":" Introduction Daylight savings switch in March/November and major events where everyone has to change their clocks. Here are some questions on this theme:\nQuestions  When daylight saving change an hour is repeated or vanishes into thin air. I personally would like the hour that I get my salary repeated. Which hour would you like to repeat on daylight savings change?\n Similarly, an hour is lost when daylight switches. I would like to lose and hour of meetings from my calendar. What about you?\n Do you think we should get rid of daylight savings?\n What if we had two suns and 24 hour daylight. Would you enjoy living in such a world?\n Daylight savings mark the beginning of sunnier days - do you prefer the part of the year with extra sunlight or with extra sleep?\n Daylight savings are also marked with the spring cleanup. Can you think of some habits you would like to throw out of your life?\n By the time we reach March, our new year resolutions begin to fade in and we need a booster. Which resolution do you need a boost with?\n Daylight savings are important because we have clocks. Would you like to live in the world where we do not have clocks and the concept of measuring time?\n Instead of losing or gaining hours suppose we could freeze time. What would you like to do if you get infinite time in your life?\n With increase in daylight we definitely lose moonlight. Do you think we should call it moonlight savings when we lose daylight savings in November?\n Many celebrities and successful people are not able to get more than 6 hours of sleep. So daylight doesn\u0026rsquo;t mean much to them. Do you think you sleep too much or too little?\n Suppose humans hibernate for the winters and wake up when the daylight savings hit. What would be the thing you would like to do after 6 months of sleep?\n Imagine a situation when you were to give a speech for 6 minutes and the daylight savings are lost and it becomes a 1 hour 6 minute speech. Would you continue speaking or give up?\n Instead of the daylight suppose you could change the work day say 9 hours in summers and 7 hours in winters. Would you prefer the change?\n  ","date":"2019-03-10T00:00:00+00:00","description":"Table Topic Questions on Day Light Savings Time","image":"/blog/2019/03/10/table-topics-daylight-savings-time/cover_hu6ecaf0b05defb401bd7da521c5eb5bda_1114556_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/03/10/table-topics-daylight-savings-time/","readingTime":2,"series":null,"tags":["toastmasters","tabletopic"],"title":"Table Topics - Daylight Savings Time"},{"category":"Toastmasters","contents":" Introduction This is a collection of questions that can be used at Table Topics for toastmasters.\nQuestions  What makes humans different from others?\n What is the most important thing about you?\n What gives you hope?\n If God asked you why he should let you into the heaven, what would you say?\n What are the changes you want to see in the U.S.?\n If you had only 24 hours to live, what would you do?\n Whats your bucket list?\n Most difficult decision of your life.\n Should husbands be older than wives?\n Wisest decision of your life.\n If you were invisible for a day.\n Book that influenced you most.\n Benefits of toastmasters.\n Your retirement plans.\n Favorite activity outside of TV and internet\n Why should God let you in to the heaven?\n If you lost everything, who would you turn to?\n If you choose to retire at any age, at what age and what would you do?\n If there is a vacant lot in your neighborhood, how would you use it?\n If you are offered a free remodeling of your house but your house will be painted red, would you accept the offer?\n What would you like your company to offer?\n When you are 80 years old, what would mean to you most?\n Would you break a criminal law to save a loved one?\n Have you been the kind of friend you want as a friend?\n Would you rather lose all memories or never be able to?\n If you must evacuate your house, what would be the item you would take with you?\n What is something you pretend to understand but you really dont?\n What did you want to become when you were growing up?\n When in a conflict would you confront, compromise or flee?\n Would you rather live in a big city or out in the country?\n If you could own just three possessions what would you keep?\n What are the defining moments of your life?\n What is the most embarrassing moment of your life?\n If you had a chance to do something over again in your life what would that be?\n If you had to live without one of your senses, what would you choose?\n What is the scariest thing you have ever done?\n If you were to be given a chance to witness any event in the past, present or future what would that be?\n If you were made the president what would be the first thing you would do?\n What was the class that you found most useless in high school?\n What are the three things in nature that you find the most beautiful?\n Who do you admire most in life?\n What is your best childhood memory?\n Do you think crying is the sign of weakness or strength?\n Is it possible to lie without saying a word?\n Can there be happiness without sadness?\n Can there be peace without war?\n Do you own your things or do your things own you?\n What do you have that you cannot live without?\n  ","date":"2019-02-03T02:00:00+00:00","description":"Random table topics questions.","image":"/blog/2019/02/03/table-topics-a-random-collection-of-questions/cover_hude08613316fbd858e0cd7d076e4909bf_174120_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/02/03/table-topics-a-random-collection-of-questions/","readingTime":3,"series":null,"tags":["toastmasters","tabletopic"],"title":"Table Topics - A random collection of questions"},{"category":"Toastmasters","contents":" Introduction Today is award day. We are celebrating all the achievers for this year. And the table topics are also about receiving awards. All of the participants have to come on stage receive the award and say a few words.\nQuestions  Most devoted member\n Best table topics\n Best icebreaker\n Worst speech of the year\n Distinguished toastmaster\n World Champion of public speaking\n Oscar for the best director\n Golden boot at the soccer world cup\n Overachiever\n Friendlist member\n Most talkative member\n Underachiever\n Nobel Peace Prize\n  ","date":"2019-02-03T00:00:00+00:00","description":"Unique table topic theme around winning awards.","image":"/blog/2019/02/03/awards-table-topics/cover_hu3b3d983e9b4c9f235a538285a53adf9a_917068_100x100_fill_box_center_2.png","meta":null,"permalink":"https://atishay.me/blog/2019/02/03/awards-table-topics/","readingTime":1,"series":null,"tags":["toastmasters","tabletopic"],"title":"Awards - Table Topics"},{"category":"Toastmasters","contents":" Introduction With the start to 2019, we are here at a new tax season. This year with the prolonged shutdown and constant fears of delays from the IRS, tax season has enjoyed more media attention that usual. And many are rushing for them since we don\u0026rsquo;t know if the government will shutdown again. So today\u0026rsquo;s table topics is all about taxes. I will keep the questions simple and hopefully everyone gets to speak.\nQuestions  What would you do if you get a $10k tax refund?\n If all taxes were in the form of volunteer work, what would you like to work on?\n Do you think there should be taxes?\n If taxes were like tips what would you pay?\n You are the president of US and your first job is to declare to the public that you have to increase everyone\u0026rsquo;s taxes by 5%. How would you give this news?\n If you had an option to exempt one celebrity from taxes who would you chose and why? You can also chose none.\n If you were given a lifestyle choice which had you had to do more (say 1.5 times what you do right nows) to reduce your tax return which one would you chose - like walking, jogging, sleeping, watching TV, playing games. If you don\u0026rsquo;t do that your tax doubles.\n If instead of tax deduction at pay time, you had the option to pay all tax at the year end, you could earn interest on the tax money. Would you prefer that?\n If there was an option for having everyone\u0026rsquo;s tax returns public, would you take it?\n If you could chose which government agency to give your tax money to, what agency would you chose? Eg defence, national park, roads, libraries, USCIS.\n If you were forced to cut down tax money flow to certain government agency which one would you be willing to give up for 1 year.\n If you had all the lobbying power in the world and an option to create tax loopholes, would you create one - if yes which one?\n By as mistake IRS sends someone else\u0026rsquo;s tax refunds to your account which happen to be $100k and you hear in the news that IRS has made a big mistake and they have no way to recover the money, what would you do?\n If you had an option to pay taxes to your boss, the government, your kids or your spouse, which one would you chose and why?\n Tell us your experience when a gangster comes to you to help file his tax returns.\n  ","date":"2019-02-03T00:00:00+00:00","description":"Table topics questions used at a themed meeting around taxes.","image":"/blog/2019/02/03/tax-season-table-topics/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_492074_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/02/03/tax-season-table-topics/","readingTime":3,"series":null,"tags":["toastmasters","tabletopic"],"title":"Tax Season - Table Topics"},{"category":"Guitar","contents":" Another song that I have been practicing for a while.\nTujhe Dekha to yeh jana sanam - from DDLJ.\nIntro Created with Raphal 2.2.0TAB0007573587\nTujhe dekha toh yeh jana sanam\nCreated with Raphal 2.2.0TAB0007573532\nPyar hota hai divana sanam\nCreated with Raphal 2.2.0TAB023023032\nAbb yaha se kaha jaye ham\nCreated with Raphal 2.2.0TAB023023032\nTeree baho me mar jaye ham\nCreated with Raphal 2.2.0TAB0007573587\nTujhe dekha toh yeh jana sanam\nIntro Extended Ending Created with Raphal 2.2.0TAB781010877810710879 or\nCreated with Raphal 2.2.0TAB7810108778101210875 Teree baho me mar jaye ham\nVerse Created with Raphal 2.2.0TAB778121277812127\nAankhe meree sapne tere,\nCreated with Raphal 2.2.0TAB5787787\ndil mera yade teree\nO mera hai kya (la la la), sab kuchh tera (la la la)\nJan teree sanse teree\nCreated with Raphal 2.2.0TAB787875757235\nMeree aankho me aansu tere aa gaye\nCreated with Raphal 2.2.0TAB55510108108710879\nMuskurane lage sare gham\n","date":"2019-01-07T00:00:00+00:00","description":"Tujhe Dekha (DDLJ) - Guitar Tabs","image":"/blog/2019/01/07/tujhe-dekha/cover_hu9d50243e047e701fcc52ba64bc32ed39_892805_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/01/07/tujhe-dekha/","readingTime":1,"series":null,"tags":["guitar"],"title":"Tujhe Dekha"},{"category":"Toastmasters","contents":" I have some pamphlets distributed. No need to look at them right now.\nAccording to most studies, peoples number one fear is public speaking. Number two is death. Death is number two. Does that seem right? That means to the average person, if you have to go to a funeral, youre better off in the casket than doing the eulogy.\nThis was said by the comedian Jerry Seinfeld in 1993. 3 out of 4 Americans suffer from Glossophobia or the fear of public speaking. It leads to a 10% impairment of wages and 15% impairment in your promotion. This thing is very real. That is why we are all here right. Lets try and understand it. Glossophobia is a disease. It has its symptoms. As toastmasters all of us have given speeches. Lets discuss some symptoms of extreme stage freight out - raise your hand if you can state some.\nNow that we know these symptoms lets turn for some help from our friend Charles Darwin. Have a look at the bottom left of the pamphlet that I just gave you. You see this list. That\u0026rsquo;s exactly what we feel on the stage right. Increased heart rate - you can hear it pounding, bladder relaxation - happens to some, tunnel vision - you are stuck frozen on the stage, shaking, dilated pupils - see the stars in broad daylight, flushed sweaty faces, dry mouth, slowed digestion - butterflies and hearing loss.\nDarwin was not studying humans on the stage. He was studying animals in front of the predator. That is where this reaction comes from. We as humans are just slightly sophisticated, a little better mannered animals and our animal instincts still rule us. The cave man lived in small groups. At any time he was out in the open surrounded by others was when a pack of lions or wolves was after him. There is one thing scarier than death. That is death by a pack of lions tearing apart you and your legacy. And that is what feels on the stage. The audience feels like wolves. Fangs growing out on all your faces. Those teeth growing sharper. Your nails turning into claws ready to pounce. I am mortally afraid. Feel like running.\n Fight or Flight Response   Darwin talked extensively about the fight or flight response in animals what I call the freight response. When in danger the hypothalamus in the brain causes the pituitary gland to release adrenaline, the emergency hormone. And adrenaline can cause all these symptoms. We are in the adrenaline rush all the time on the stage. This heightens our senses and prepares us to run. We notice our mistakes more - did I just step on a twig and we want to run for our lives because when a pack of lions is after us, we rarely do recover.\nOur lives are not at stake on the stage, but studies have shown that humans overestimate them. The social animals are scared of their credibility, their position in society and their legacy. Being ousted from the community is worse for the cave man than being killed. Because not only him, but his family would also suffer. The odds are much bigger. There is something worse than death - death of all you care for.\nSo now we know that speaking on stage is like taking on an entire pride, lets talk about the three ways to be able to do that. 1 - Prepare. Prepare fighting animals. Start with a maimed lion, then a single lion and then promote yourself to the pack. Speak at small places, at toastmasters, at contests and then at conferences. 2 - Prepare. Come prepared with a armored coat, infinite ammunition and the best rifles you can get a hold of. Prepare your speech and the background material so that you are confident that your knowledge is with you. 3 - Prepare. Prepare the arena and your emotions for the battle. Try and practice on the real venue before the D-day. Bring a few friends to cheer you up. Take a deep breath before going on the stage. Once you are there, its a fight. Flight is not an option to the winners in life.\nGlossophobia is a natural reaction that happens to everyone. We need to prepare to condition ourselves to the adrenaline rush. Mark Twain wrote - There are two types of speakers in the world: the nervous and the liars. The science is against our success. We need to defeat those odds. Prepare, Prepare and Prepare. Thank you.\nReferences:  3 out of 4 Americans suffer from Glossophobia - Communicating for Results, a Guide for Business and the Professions (eighth edition). Belmont, CA: Thomson Wadsworth.\n Symptoms of Stage Freight - Treating social anxiety disorder https://www.academia.edu/2632777/ Garcia-Lopez (2013)\n Fight or Flight - The Expression of the Emotions in Man and Animals  Charles Darwin (1872)\n Fear of public speaking has 10% impairment on your wages \u0026amp; 15% impairment on your promotion - Peter Khoury (Magnetic Speaking)\n Image from Wikipedia\n A Racing Heart, Rattling Knees, and Ruminative Thoughts: Defining, Explaining, and Treating Public Speaking Anxiety  Graham Bodie(2009) - https://doi.org/10.1080/03634520903443849\n  ","date":"2019-01-05T00:00:00+00:00","description":"Understanding why we fear public speaking.","image":"/blog/2019/01/05/glossophobia/cover_hu46c75daf408c96acd3786cde3f9f5ad7_483807_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2019/01/05/glossophobia/","readingTime":5,"series":null,"tags":["toastmasters"],"title":"Science of Glossophobia"},{"category":"Web development","contents":" The browser engines as well as the hardware components in smart phones have dramatically improved in the last decade. The web platform has also standardized many APIs required for mobile development. Network bandwidths have had a major uptick. Just like electron in the last 5 years has become the standard way for developing desktop apps, the time is ripe for web technologies to put the strong foot forward in mobile app development.\nWeb Views are out of fashion WebViews were vogue in the early days of mobile development. The original iPhone had support for pinning websites on the home page and that was the only way to add applications to the device. There was no App Store and no native development. By 2009, every one was building a mobile version of their website optimized for smaller screen sizes. PhoneGap was a new and promising technology that could easy mobile development by helping us write once and use multiple times - the same software could run on the iPhone, Android and the upcoming Windows phones. Even in the App Store, many apps were wrappers over the website placed to get an entry in the search results.\nAll that ended once the music stopped. Most major applications moved off webviews during 2011-2012 because of a variety of reasons:\n The web platform was not mobile ready - Internet Explorer was the most used browser with over 70% market share in 2009. It was the peak era of JQuery where JavaScript was mostly used to patch up some animations on the rendered content. There were multiple issues with web development for mobile:\n Web was a document delivery platform and even things like vertical centering required extensive hacks.\n There was no web app and most websites were rendered on the server and the building blocks of web apps - JSON support, Flexbox, media queries were absent in the most browsers.\n  There were too many mobile platforms Blackberry, Symbian and Windows Mobile still existed. While the native app developers were happy to optimize for the specific platform, web apps were sold to the executive team as the solution that was cross platform. Therefore, they had to support the most incapable platforms in the website and the quality suffered.\n Mobile was rapidly evolving There were significant changes taking place with every passing year. From the release of the iPad to Retina displays, while the native developers got tools for each and every change, web developers who needed to support older devices were stuck with the minimum common set and the platform itself took time to catch up.\n Web carried a lot of baggage Most apps were fresh code bases written from scratch to support a new platform. Many web apps were patches over existing 5 year old projects written for IE6 support. The re-engineering and removal of defunct use cases made native apps thinner and lighter.\n Tooling was not there Remember Firebug. That was a huge luxury to have. Without it, developers resorted to alert based debugging where a modal dialog was launched just to print a string, especially on the Android Browser(no chrome on Android back then). Many web developers used notepad and did not have a compiler, linter or a code formatter. Selenium was in its infancy and mostly a hack injecting scripts to provide a testing environment on the desktop.\n The big churn The web community was going through the biggest churn in code and practices. Flash -\u0026gt; JQuery -\u0026gt; Backbone -\u0026gt; Angular -\u0026gt; React all in a span of a few years. Browser wars 2.0 was in full rage and there were new features out every month that made old web development practices defunct.\n Web got bad press Mobile surprised a lot of giant technology companies and they were unprepared. Facebook put the blame on web technology. That too just before their hugely anticipated IPO. It became extremely difficult to defend web once one of the biggest technology companies publicly shames the platform in general media.\n Design practices were evolving Mobile was new and the best practices on mobile were still evolving. Here is an image of New York times from the blackberry days. 50% of the screen space was the header and the footer. That too on a smaller screen that we had back then. Shrinking the desktop design on mobile we know now was not the best solution. Even though web might have been easier to experiment with new designs, native apps mostly got the new designs first simply because web was the last resort for the extreme edge cases - no one wanted to risk the users who expected the desktop functionality on mobile.\n  You might have realized almost all of those concerns are not there any more. The core features required for mobile development have been stable in the web browsers for years and even the oldest browsers in use support most of the essentials. There are just two mobile platforms left and even they have been converging. People are holding onto their phones longer and most apps do not need to support all of the new features. Supporting the iPhone X notch is not the retina level effort. Most apps are more than 5 years old and carry similar baggage as the web. With ES6, many web apps are getting a reboot. Tooling on the web has left native far behind. The web platform has stabilized. Array.includes is not a huge change in comparison to class statement and we still get the same buzz because there is not much new to cheer about. Native has had its own share of churns - ObjC to Swift, the removal of 32 bit apps, of OpenGL and the migration from eclipse to android studio. There has been radical unification of design. Most apps look the same on Android and iOS. The differences like menu placement are minor. Many apps have started building their own conventions that are cross platform and many developers instead of building platform only features have been busy ensuring the design remains consistent.\nWeb has quietly surpassed mobile For building a regular application on mobile the web platform provides better features today than native code ever did:\n Live Reload Web stack is much easier to develop due to live reload. Change something and see it live. Add it the fact that you can debug mostly on the desktop browser and things work fine on mobile. Native never had the luxury in the past and may never have it in the future.\n Layouting CSS Grid and Flexbox are much more expressive and powerful than auto layouting ever was. As an added advantage there is no interface builder where you cannot do diff across checkins or merge changes across commits.\n Hot patches Web as a platform has been built online first and adding offline capabilities have been added later. Adding online capabilities and network conditions is many times more difficult than adding offline caching. Minor fixes do not need a huge cycle of submitting an app again for review and watching it slowly being adopted. If built right the web based app can be updated almost instantly for most users.\n Testing and CI/CD Testing web based code is many times easier than testing native apps. Tests can run extremely fast with the command line and on the automation machines. That makes them extremely easy to use. Setting up a build machine for automating native apps is so much effort that many teams decide to skip it altogether.\n Features With WebGL we can build apps with full cross platform GPU support in the web platform. With WebAssembly and WebWorkers, CPU intensive computations are all safe and simple. With IndexDB we have a fully managed database. Cryptographic methods are available natively in all browsers. Even more arcane APIs like orientation, camera, proximity, accelerometer, gyroscope, page visibility, and Bluetooth are either built in or getting ready. There are little reasons for a WebView based application to have a single call that requires special native code. Even if we need one, we now have mature APIs to expose native objects asynchronously in JavaScript without resorting to hacks like URL redirections.\n Code sharing This is deliberately been put as the last item. Web based apps can share some code between multiple platforms and even with the server and the website. This can turn into a huge limitation if we developers go overboard with supporting everything.\n  Ideal apps for WebViews Web Views are not perfect for all app types. If you are building the Facebook app with 18000 classes even native might not be good enough. But there is a huge class of applications where Web based views are the best choices. If your app fits in these categories definitely go for web views:\n The app needs a network Interactions over the internet are the biggest strength of the web. Nothing is more optimized, and can provide a more robust set of network communication tools and APIs than a web view.\n There is no extensive need for cutting edge native APIs If your app needs AR Kit or CoreML then a web view might not be the best choice. You might be able to place the general browsing and settings pages in the web view but if you have a native renderer, putting a webview may not be worth the effort. One or two views being native is all right as Web Views will save tremendous effort in debugging the interactions outside of those views.\n Everything can be built in the website If your website is fully featured, you can build a web based app with all the features and it can be much better than the website by fine tuning for the device the app targets.\n The app is UI/Data based rather than CPU based If your app is not the one that needs to convert an iPhone into a room heater, the performance overhead of an interpreted language might be worth it. It makes UI development and experimentation with interactions and user interface easier. Web provides the best interaction\n  Tuning WebViews for native like performance Most of the developer knowledge as well as the best advice is tuned to web development where downloading the resource from the internet is the biggest bottleneck and every other consideration for performance is second fiddle. This changes in the world of WebViews where most of the HTML is bundled and there are very different things we need to cater to. Here are some things to consider to get native like performance in WebViews:\n Target a single user WebView based apps unlike websites target the same user, who logs in for the lifetime of the application. The cookies are not deleted. The requests are not blocked and multi-user considerations are simply not present. There are no cross-site security issues. Therefore, the key to great performance is caching. There is simply no need to download anything again. Stashing everything in the indexDB is the right idea. Just like native apps the focus should be on offline user experience and the server updates should be done whenever network is available and in the background. Progressive Web Apps with a service workers can be used if you need remote update capabilities. But starting with that may not be a great idea. Start with some bundled HTML to figure out what needs to be done to get the app perfect. Service worker should come later. Most apps update through the app store.\n Take note of the parse times Web apps are optimized to minimize the package size. This is not the most important thing in a native app. The source code is on the disk. Therefore there is a no point in bundling JavaScript into a single file, especially if it forces the browser to parse code that does not need to execute. The JS bloat is the only reason WebView apps appear slow. But it does not have to be that way. Having 1000 files optimally split is not even a problem on web any more. Most users are on HTTP/2. But on native, bundling them in a huge JS file will ruin everything. In a native app written in a different language, no CPU cycles are wasted on views that need not be shown. Same should be the case with web. Handsomely use prefetch, preload and prerender tags in a WebView app. We are not wasting bandwidth just opportunistically parsing some image, CSS and JS files. The costs on battery are very low and the experience benefits immense.\n Identify the strengths There are no browser plugins in a web view. No Javascript disabled mode. No worries about the web font not loading. All the extra effort needed to support these use cases and testing scenarios is not required. Instead all focus should be on the performance. Cache the rendered HTML on disk to prevent having to generate it again. Have a good state management library.\n Use the right tools HTML rendering is highly optimized and the browser takes extreme care not to waste cycles rendering stuff that is not needed. But still the DOM is extremely expensive. To get native like performance, we need to take some cues from the native code. Picking an virtual scroll library is essential if we need a scroll list. Animations in JavaScript until Web Animations becomes available is not a great idea. Images should be optimized to the view they will show up in. The need for the browser to relayout should be prevented with things like size attributes in images and preloading of the content.\n Do not go overboard While many native app teams are happy going with a simpler design, as soon as the web technology is brought into the picture more customizations are needed. Not many apps ship with custom fonts but almost all webviews based ones are forced to adopt one. Similarly developers want to share code as much as possible. These goals deter the focus from quality. As long as web based apps target the lowest common denominator, they will remain far behind native code. The webview app should not be sharing code with the website to begin with. First get the best app out and then focus on sharing. The app can act as a forerunner to the website meant to replace it when the lowest browser supports everything it needs. There will still be avenues to share code. And even if there is none shared, there was nothing shared in the native world as well so we are not worse off.\n Realize the limitations Some screens are not ideal to be WebViews. For example, if your applications core is something that depends on realtime updates from the Photo gallery, Phonebook or the camera, you can hook up Cordova or pass messages but it might be better to just use native code for those views. This does not mean the app cannot be a webview app. The photo view or the phonebook view can be a native view that calls back to the core webview when done. That way the core logic can still reside in the WebView and be cross platform while the platform specific performance sensitive pieces could reside in native code.\n Use the right defaults Almost all apps are on retina devices, wide gamut support is present by default almost everywhere. If building webview based apps start support the highest device feature set. Adding backwards compatibility is easy(especially with Babel and PostCSS) and we never know if we will support the older device by the time we get to a release. optimize for a feature that\u0026rsquo;s new in a new device. Users paid handsomely for the new handset and they expect the apps to appear much better on the new device. Developers need to respect those wishes with the web views just like they do with native code.\n  Just like native apps are engineered, web apps that are used natively need to be engineered. Web is extremely easy. Easy never means we dont need to learn. If the best practices are not followed no platform or programming language can save someone from making a horrible and extremely slow app.\nRaw WebViews vs Cordova vs React Native Raw WebViews are good for most of the workflows, especially if there is a team of native app developers who are building the hybrid part of the application. They allow native developers to feel at home while the web developers can fully implement most of the cross platform logic. The boilerplate has been reducing over time and with most requirements never requiring native code, the reasons not putting in a webview are diminishing at a great speed.\nCordova makes it faster but it comes with a lot of baggage of historical decisions that are not relevant in the modern world. Cordova is like JQuery, it makes job easier, works around platform specific bugs and significantly speeds up the process to get up and running. But in the modern OSes, it is not essential. If we are new to the platform we can use it to get started. But most of its functionality is natively available. At some point you can replace you entire framework dependency with a ployfill that is implemented over a web view. Cordova is perfect if you do not want to maintain a build system as Phonegap build can save you the cost of buying a Mac.\nReact Native is an interesting experiment. It started with the concept of using Native Controls directed by JavaScript but over time with things like React Navigation, the community has gravitated away from using true native controls to custom views. There are two big advantages of react native - out of box platform specific UI and the ability to write a custom native control surrounded by regular controls. Its API surface is very small in comparison to the web platform and new features like CSS Grids may not ever land up in the platform. WebViews also have native controls although things like switches have not yet been implemented. React native is a good idea if you are in terms with the limitations of the platform and need a custom control so tightly integrated with the JavaScript views that WebViews are prohibitive. Otherwise, WebViews with react would be easier to develop over and use with comparable performance for most use cases.\nConclusion There was an era when programmers using compiled languages over assembly were lesser beings. This was until the compiled languages took over the desktop. Then came a time when developers distinguished between compiled and interpreted languages. Interpreted and dynamic languages took over research and server side development. Then came an era when sand-boxed web development was marked as nothing in comparison to the real native stuff. Web applications are getting as powerful as native desktop applications and the difference will soon be indistinguishable. We still need to write assembly for really low level, extremely performance sensitive stuff but even those strong proponents of their real native skills never go down to assembly. We are entering the golden age of developing mobile apps using web technologies. Web Technologies are the present of application development. WebViews are a great way to make them go native.\n","date":"2018-12-15T00:00:00+00:00","description":"A case for extending the use of web views in applications. Web can be fast an easy.","image":"/blog/2018/12/15/getting-cozy-with-webviews/cover_hu3d03a01dcc18bc5be0e67db3d8d209a6_2038098_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/12/15/getting-cozy-with-webviews/","readingTime":16,"series":null,"tags":["web-development"],"title":"Getting cozy with WebViews"},{"category":"Toastmasters","contents":" The accompanying presentation is available here.\nFellow Toastmasters. Let talk about design. We are in the information age. Which means we are overloaded with information. And when too much information is there, it is presentation that matters. Bad design is dead design. While we are not designers, the art world has been democratized enough for us to leap from bad to above average just through a 5 minute toastmasters speech. So lets get started.\nI will be taking you through a journey where you will shake the feeling of not being a designer, learn some basics of design, the rules of being successful using the internet to design, and then I will demo some tools I use to make a poster and then we hopefully all be confident that we can design something.\nBefore going into making one - please raise your hand if you have ever designed something - What did you make? Lets broaden your horizon - did you ever design a facebook post - a birthday card - an invitation. Yes, these are all posters of some sort. Requiring the same skills.\nOk, so we all have been designing. But the problem is we don\u0026rsquo;t know anything for the design. We feel like an imposter in the world of design. That is not a tough challenge. We do need the basics but the truth is we don\u0026rsquo;t need the long design school to be better than an average facebook designer. We need that to be good. For being better than how bad we really are, we just need the basics. And the experts have put them up all there.\nOn the screen you should see the summary of the design that we amateurs need. On the left is the list of font styles an what emotion they represent while the right, it is the colors. While we don\u0026rsquo;t get the theory behind it but it is good enough in most cases that gray is for calm and brown for friendship.\nAnother thing to remember are the rules and the tools. First the rules, like not using copyrighted stuff. You can filter labelled for reuse images from google and also search them directly in sites like flickr, pixabay and unsplash. So lets talk about what I am going to demo today - today we will be making two posters, one for the open house in january and the other for the holiday party at the end of the year. From the looks of it, both of them are elegant and professional. How many hours do you think, I spent on them today? less than an hour to get them out. How - by using the right tools.\nHere is the first tool I am going to show - canva. In canva all you need to do is search. Searching for open house gives so many results, mostly brown for friendly but all clean and professional. The one here is what I selected for this poster. Adding text is easy - canva gives a lot of options - all perfectly tailored with the correct fonts and sizes. We just need to select and type. A few clicks and it is ready. One click download.\nThe next tool is spark. It is very close to canva but with a few differences. The template selection is not as vast but spark provides support for websites and videos. Spark also provides dynamic design update. So if we have the content in one posted and we want to try out another design, we just click. And sometimes like this one, it actually turns out well. You can play around with styles for individual elements like this text and images and this tool provides a lot of customization options to play with a specific design. And as I have been rotating the poster is ready.\nNow that you see how easy it is to design effective posts, I want you all to take this lesson back with you and try these tools. Waiting to see some great content.\nHere are the posters from this speech   Open House Poster    Christmas Poster 1    Christmas Poster 2   ","date":"2018-12-02T00:00:00+00:00","description":"A lesson on making posters for amateurs - getting to above average in 5 minutes","image":"/blog/2018/12/02/design/cover_hu21ef649dd5d2ec8749840699014d5bac_769702_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/12/02/design/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Democratized Design"},{"category":"Toastmasters","contents":"This speech is inspired by Jim McDonalds \u0026amp; others from Comedy Time.\nHow many of you would like to jump of the plane without a parachute?\nJust what I thought no one. [If someone raises their hand just call - we have 1/few suicidal person in the room]\nHow many people here have 5+ credit cards? You folks should buy a parachute.\nMadam Toastmaster, My capitalist friends and ever so beautiful judges.\nSee I come from India, where they still trade in cows.\nTaking a loan is a very dangerous business. You need a collateral. Anything from a cow to your unborn child. You dont have any of that, not to worry. Find an un suspecting friend, like {person1}, to sign a guarantee of your financial capability and to repay your loan, when you skip country. For those of who dont know {person1}, be sneaky - The neighbors home is a valid collateral too. Take the money and run.\nIn America things are so much better. All they do is to pull out your credit report. It may be a bit humiliating to see the list of things you havent paid for, buy hey, I have had my share of D grades at school.\nSo, the loan officer goes through this long list and he is like\n{Officer} Oh my god student loans.\n{Me} Ya, I know\n{Officer} Tell you what. We are gonna forget about those student loans.\n{Me} It is funny that you say that because I have done exactly the same thing.\n{Officer} 620 out of 800.\n{Me} I know. I dont need a million-dollar home loan.\n{Officer} Approved. And I\u0026rsquo;ll throw in another 1000 dollars off if you sign up for gambling \u0026hellip; I mean investment account.\n{Me} Why not. Will you also attach a personal loan and do a balance transfer? I really like that store card.\n{Officer} Why didn\u0026rsquo;t you tell me. Balance transfer can get you another 300 dollars.\n{Me} Wow.\nThe credit card is yours.\nAfter living in America for just 3 years here are some tips from a pro- credit card-holic.\nOne: You can use your credit cards for almost anything. It is important to remember - \u0026ldquo;almost anything\u0026rdquo;.\nIf you take your hot colleague to lunch - remember to pay cash even if it includes the 20% gratuity. Because if you use the card, your life will be ruined. I did not tell my wife when I bought my PS4. Wives may allow their husbands to go to the war front but a video game - no way. As soon as I swiped the card, Facebook sent me a push notification. Google decided that \u0026ldquo;I\u0026rsquo;m feeling lucky\u0026rdquo; and navigated me to IGN. Feeling is not the same as being lucky. My mailbox was full of discount coupons and my wife knew everything. My well-rehearsed 5 minute speech turned into table topics. I was never able to buy a game for the PS4.\nTwo : Banks love you\nIn America an average household has $9000 dollars in credit card debt. I am way above average. Even the banks think so. Every time they send me a statement, right next to my balance, they always write the word  Outstanding .\nLast month American Express called me up and said  Mr Jain your balance has been outstanding for the last two months.\nListen, I just got back from Vegas. Next month you are gonna be so proud!!!\nA few days they sent me a letter that said  Final Notice. Thank god. I thought those guys would never give up. I wrote them a thank you note. Amount I owed you 4000 dollars. Amount I paid you 20 dollars. You not sending any more letters  priceless. I hopped onto Bank of America.\nThree: Take huge loans\nNeighbours house are hacks around a much simpler concept. Pick up a house from the street. Preferably at zero down payment. Transfer your debt to it. Then wait. Wait for the prices to dip. Apart from the Silicon Valley they do eventually fall. A perfect time to flip. Your debt will be gone.\nThis is life. Now that you are all eager to run up the bank to start the swiping journey - married men one thing to remember. Keep your credit card under a lock and a key because if your wife ever finds it - there are not enough banks to hop onto. You have been warned.\nThank you.\n","date":"2018-09-28T00:00:00+00:00","description":"Humorous piece on Credit Cards - getting and using them","image":"/blog/2018/09/28/confession/cover_hu49c03114a9ce8ad2bc0bd62c0ddb3f2a_440708_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/09/28/confession/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Confessions of a Credit Card-o-holic"},{"category":"Toastmasters","contents":"Mostly impromptu speech on the updates on the new website and mailing lists for Fair Oaks Toastmasters. I don\u0026rsquo;t have this one written and am writing something after the fact that I wanted to speak on.\nThe presentation is present here\nIn this speech I introduce the new emails, the new mailing list and the website for Fair Oaks Toastmasters.\nThis is a follow up from my speech from last week talking about the changes that we did in the mailing lists. I talk about why we did this. It is not that some engineer decided to redo the wheel without thinking. We all know engineers love that. But this was not done for the reason. I also talk about the new mailing list the new email addresses, new website and new everything. I will also mention the posting policy - the same old posting policy which we want to reinforce because it is so important.\nLets start with the why. The club already had a website and a mailing list. I hope no body uses the phone I show in this slide. The world has moved from the dial phone to the iPhone. The old website did not even run on the iPhone. Now in the old system, if you have something you dial you had to rotate it full. Takes a lot of effort. Similar was the experience with our existing website. Updating it required multitude of forms, going to a variety of places that brought down the overall efficiency of the club.\nLets talk about the emails. There are official email addresses for all officers now. The doors of this room have been shut down and you will be forced into a sales presentation. All officers get their own photograph on the club home page. All of us have an excerpt by toastmasters, a link to your website for free SEO, free publicity as people of value. The officers work has greatly been reduced. You get a free archive of all your emails and as a bonus all new officers get an access to the email communication that took place before they joined the post. There is not a blank state to start any more. Just read through the communication that happened before you took over and you have most of the information you need.\nLets talk about the mailing lists. I sound like a google salesman but I am not. We had to chose a shoulder to stand upon as doing this work without the right tools is very time consuming. With google for non-profits, google actually picked us up upon its broad shoulders by providing the business suite for free. They say they don\u0026rsquo;t do any tracking (your wish whether you want to believe it) and even if they do the club is designed to be open and transparent and most of this information will lie int eh public domain anyways. Now we have four mailing lists. The membership list I have talked about in detail. All of us members have access to emails from this list. Only paid members can post here. The next are the contact and officers mailing list. We would love to have feedback for things that are and those that are not working. Anyone can post to the officers and the contact mailing list and even though we are a volunteer based organization we try to respond within 2-3 business days.\nAdding users to the new system is extremely easy in comparison to what we had. It is no more and obscure set of dialog boxes in an obscure website. The system is a lot easier. Goto admin.google.com and you will see something similar to the screen on your left in the slide. Click on Groups and you get the screen similar to the one I showed last. There you can click on the add user button to add users and paste the email address. As a great tip, keeping the list in sync is actually extremely easy. Remove all from the mailing list. Goto toastmasters.org and download the club roster. Paste it in the dialog box. Click submit. Done. Hope to find the next year\u0026rsquo;s VP PR ready.\nThe new website is also extremely easy to edit. Not trying to be a google publicist, it is hosted on google sites which gives a click and drag way to create a website. Click and type on a section. Good enough sample layouts, a pre-built theme is ready for use. Adding images gives you layout options. There is built in support for youtube and google maps. The website is already up to date with the content on the previous system.\nNow the most important part. Our posting policy is as simple and straightforward as it has always been. We provide free publicity to you and you own everything. We are happy to repost your content if you need it. Free SEO to your website and free branding to you. You already have a lot of speeches that you must be recording every meeting. We are happy to take icebreakers and speeches where the speaker freezes on the stage. An A Um on the stage is as useful as the eloquent expert as that shows that we are a variety club with speakers of every level. It also shows how much you have improved over the past year practicing the art of speaking. We are happy to take posts and spread them over the linkedin audience. We can have a better and much more professional reach that an individual - good like-minded people who would be happy to learn from you. So why wait - send us your content and see it all over. Thank you.\n","date":"2018-09-16T00:00:00+00:00","description":"New website and mailing lists for Fair Oaks Toastmasters.","image":"/blog/2018/09/16/web/cover_hu49c03114a9ce8ad2bc0bd62c0ddb3f2a_389407_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/09/16/web/","readingTime":5,"series":null,"tags":["toastmasters"],"title":"New Website and Mailing List"},{"category":"Toastmasters","contents":" New online identity for Fair Oaks Toastmasters Fair Oaks Toastmasters has had a gargantuan change in its online identity and the team wanted to share th updates with all its members. I have a speech that I gave impromptu to discuss these updates. I don\u0026rsquo;t have this one written but here it is for your enjoyment.\nThe presentation is present here\nThe content is mostly youtube\u0026rsquo;s automatic transcription.\nToastmasters is a non-profit. So everything we do is transparent and open. What we\u0026rsquo;ve been doing in this term for the last few months is trying to re-do the online identity of the club. I wanted to share some updates in my speech today. I\u0026rsquo;ll be talking about the setup that was there when we started to work on this restructure; things that we did to set up the new online identity that we have setup; Stuff that we\u0026rsquo;ve worked on, the things that we are working on and the stuff has still to do and places where we need help from our members. This is how our online identity of Fair Oaks Toastmasters looks like before he started. The Facebook page was up to date perfect and very well maintained. The website was there but it was kind of half a decade out of date. We had some real confusing data on the internet if a guest went to the Toastmasters website and wanted to search for Fair Oaks, they would be led to the old location where we used to meet.\nWe\u0026rsquo;ve tried to fix all of those issues in this term. I was the treasurer in the previous term. So I had access to the tax documents and things like that. As a non-profit we can a lot of free goodies from various companies. I registered us to Google for nonprofits and set up Google account for getting some free apps from Google as a bonus some ads from Google as well. The club now is has an G-Suite account all officers and an official email address. We at Fair Oaks Toastmasters now have all the club official communication recorded and stored - all the messages emails all the documents are stored in a Google Drive account. The idea is that when you move from one set of officers to the next you don\u0026rsquo;t need to ping the old officer for any information. Everything is there with you. We\u0026rsquo;re also setting up transition documents where we detail the things that you need to do if you\u0026rsquo;ve come into being a new officer. Tn the next term you\u0026rsquo;ll have a document and have access to everything through the club account. One of the things that we did set up for the phone number. A the club\u0026rsquo;s VP-PR I had forwarded to me the phone number for the club business. Not my personal one any more. We have a Google Voice account a Google Voice account that forwards the calls that come to the clubs phone number to the VPPR\u0026rsquo;s personal phone\nnumber. The next VPPR joins, we just need to change the forwarding of the club\u0026rsquo;s phone number.\nApart from this Google Voice account we have listed ourselves on Google. So if you search for us on Google Maps now, it will take you to this location well and tell you where we are. It also has a few photographs. We are starting to request reviews. We have gotten access back to our Yelp page. Now it has photos and content; it\u0026rsquo;s up to date; it\u0026rsquo;s accessible and we are responding to communication that we get from there. Reviews are welcome. We\u0026rsquo;ve also updated the Toastmasters website. Everything is up-to-date and current. The thing We did this in the last term is that we got rid of sending money to the treasurer\u0026rsquo;s personal account. The club has its own PayPal account paypal.me/FairOaksToastmasters. You do not need to send money personally to anyone. The has an official account and the next treasurer is get a access for the account rather than having to set it up all over again.\nWe are working on a new website we have created a different page. We will be adding posts too. We are setting up new mailing lists. The old mailing system was archaic and it was tied with the old website. We\u0026rsquo;re now on Google Groups. I have a separate list or members. All these the paid members are a part of that mailing list. If you want to send an email to all members send to to members@fairoakstoastmasters.com. All the communication will be recorded so that that stays there. Only members are allowed to post to that mailing list. There is one change from the previous system that the sender does not get the mail back unlike the older system as google groups is smarter than the older one not to mirror the content to the sender.\nWe are planning to get credit cards as another payment option. I know it\u0026rsquo;s difficult to hunt the treasurer each time to submit cash or cheque and credit card is the most flexible option especially for guests. We will have direct access soon. I know credit cards have associated fees and so if you want to pay by credit card, the charges will be slightly different to match up with those fees. We\u0026rsquo;re trying to get our membership forms on the website so that it won\u0026rsquo;t have to hunt for VP membership to go sign up. That will link to the credit card payment page and it will be buttery smooth to be a new\nmember of Fair Oaks. We\u0026rsquo;re also planning more social media presence. It is a volunteer effort and one VP-PR cannot manage all platforms. That\u0026rsquo;s why we need to spend time on selecting a strategy so that it\u0026rsquo;s easy for incoming VP-PRs and for members to be a part of it. We will have a hosting session on this. We need help from all of you. We need posts on our website and on our landing page from members. We will have a blogging policy. Will give the both copyright to the content be happy to link to your blog under our pages. Free SEO. If you want to post something as Fair Oaks send it to me or to the secretary@fairoakstoastmasters.com or to me at info@fairoakstoastmasters.com. Refer your friends guests to Fair Oaks Toastmasters. Things are improving. Our membership dwindled a little last year. We are back on track. We\u0026rsquo;re getting much more professional we need your help in getting further.\n","date":"2018-09-08T00:00:00+00:00","description":"Description of the changes to update Fair Oaks Toastmasters online identity for the modern times.","image":"/blog/2018/09/08/branding/cover_hu49c03114a9ce8ad2bc0bd62c0ddb3f2a_422027_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/09/08/branding/","readingTime":6,"series":null,"tags":["toastmasters"],"title":"Making a non profit more professional"},{"category":"Javascript","contents":" From callbacks to async - await - A migration guide I originally wrote this article for Morning Cup of Coding. Morning Cup of Coding is a newsletter for software engineers to be up to date with and learn something new from all fields of programming. Curated by Pek and delivered every day, it is designed to be your morning reading list. Learn more.\nCallbacks have been at the core of JavaScript and Node.js ecosystem. As much as they are needed for the performance boosts, they have proven to have huge maintenance issues. There have been multiple attempts at fixing these, from generator functions to promises, until async-await came in to the picture mitigating most of the concerns that asynchronous code traditionally used to bring with it. Now that they have been standardized, most developers are stuck with old code still living in callback hell (when you have multiple deep nested callbacks within a function) that needs to be migrated to the sane ecosystem. This blog post gives a set of step by step instructions to ease these migrations. Callbacks to async-await is like the metamorphosis of the caterpillar into a butterfly.\n If you need more than 3 levels of indentation, you\u0026rsquo;re screwed anyway, and should fix your program.\n-Linus Torvalds, Kernel Coding Style Definition\n Why do we have callbacks? JavaScript was built for the web where everything requires network requests to work. When the CPU executes a JavaScript statement like XMLHttpRequest.send() if it waits for the response to come over, the UI would hang as it takes significant time for the request to be sent over to the server, be processed and the response to come back. Therefore it made sense to take a function as an argument that would be called when the response is available, freeing the CPU for other things while we wait for the response. With Node.js, this was taken one step further as even requests to the database or to the hard disk, are also slower in comparison to the CPU, and waiting for them even in a background thread is a waste of resources. That is why in Node.js almost every call is asynchronous and after the success of Node.js, other languages also brought in asynchronous constructs int heir core.\nProblems with callbacks Callbacks are very good for the CPU but they are not so good for the programmer for a variety of reasons. Programmers, unlike computers, think in a sequence and therefore while the CPU should not wait for the database response, the programmer needs to think about the task after the database has responded. Therefore, the logical next step for the program after the database call is handling of the response. With the presence of callback after callback, changing the code into subroutines becomes extremely difficult as the flow of the program does not remain linear. The next line may be called much earlier than the previous one in execution, forcing the programmer to constantly monitor the execution order while writing code. Here is an excerpt of the problem.\nSynchronous Code(Slow but clear)\n1 2 3 4 5 6 7 8 9 10 11  function calculate() { try { // Sequential flow (also logical from the programmer\u0026#39;s perspective)  connection = db.connect(); // CPU waits for the connection  response = db.sql(connection, sql); // Process response  nextResponse = db.sql(connection, nextSQL); } catch (e) { sendToUser(\u0026#34;Exception\u0026#34;); } }    Asynchronous Version(Fast but difficult to follow) **\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  function calculate(done) { // Using callbacks  db.connect((err, connection) =\u0026gt; { //Method is called once connection is available  if (err) { sendToUser(\u0026#34;Exception\u0026#34;); return; } db.sql(connection, sql, (err, response) =\u0026gt; { if (err) { sendToUser(\u0026#34;Exception\u0026#34;); return; } // Process response.  db.sql(connection, nextSQL, (err, nextResponse) =\u0026gt; { if (err) { sendToUser(\u0026#34;Exception\u0026#34;); return; } done(); }); }); }); }    The asynchronous code, though looks ugly, has much better performance than its synchronous counterpart. Once you have more than one independent parallel call to the calculate method, the synchronous code has to resort to threads and that requires creation of huge data structures in memory. While that has been the approach for the first decade of the internet, the costs of that approach have proven to be prohibitively too high and the economics has pushed for adopting the asynchronous version.\nThe callback-based asynchronous code is more verbose and prone to errors:\n If one of the return statements is missing, the callback can be called twice which can potentially break everything.\n Errors are easier to ignore as they have repetitions that are useless and cause more confusion.\n You are more likely to hit the width of your monitor screen because of the indentation.\n You are more likely to turn, say handling the second response into its own named function which would need to be moved somewhere above the entire method making it even more difficult to follow.\n JavaScript has both errors and exceptions. An exception in say db.sql could go into the previous db.sql and then there is no way to understand anything from the call stack.\n Once it gets beyond 3-4 levels deep, you dont really understand what happens when. Accidental parallel code where the response is not present is a side effect.\n  What is async await? Async await is a simple solution to all of the above problems. While the code in async await works just like in the world of callbacks where the CPU is not wasted, it looks like synchronous code that we understand and love, and the extra verbosity is lost.\n1 2 3 4 5 6 7 8 9 10 11 12  async function calculate() { try { // Sequential flow (also logical from the programmer\u0026#39;s perspective)  connection = await db.connect(); //Connection is returned once it is available.  response = await db.sql(connection, sql); // Process response  nextResponse = await db.sql(connection, nextSQL); } catch (e) { sendToUser(\u0026#34;Exception\u0026#34;); } }    Now all those calls that were giving callbacks are still asynchronous. If you put a breakpoint in line 5, it might take a while after line 4 to actually be reached. But in the meanwhile, if you have other JS code, say some timeout elsewhere, those still get hit as the CPU is free to work on other things. Async Await is the cleanest solution to the problem of having lots of callbacks known as callback hell where we had to live with ugly code for the performance benefits that it provides.\n Trivia\nAsync Await is not the first solution to the callback hell problem. Generator Functions, Promises and even strict coding conventions have been used in many places. Node.js had to introduce a huge set of sync versions of its various APIs because writing asynchronous code was so much pain that developers sometimes preferred to just use the inefficient synchronous API to get around it. Async Await provides a proper solution where the code looks like the synchronous API but works like the callback version without the loss of any expressiveness, performance or power.\n The elephant in the room - Promises Promises are complicated and at this point an internal detail. Async await is a wrapper syntax and works based on promises. The concept of promises is therefore required to be known if you ever want to go deeper into async await. We will not be going into the nitty-gritty of promises. A great introduction on Promises can be found in the google developer documentation and at MDN. This article explains how async await are built over promises. Promises are ways for synchronous and asynchronous functions to work together. If you ever need to convert callback based code to async outside of the pattern that we will just be learning or want to use async code in their synchronous counterparts, promises are the way to go. Guru99 provides a good tutorial on converting to promises which could be used as an intermediatory step before going into async await.\nSteps to go async 1) Convert all callbacks to be of the callback(err, data) format that takes one error and one data argument. The task is not very complicated. With ES6, the wrapper may actually end up being extremely small and useful.\nBefore\n1 2 3 4 5 6 7 8 9 10 11 12 13  /** * Task method to performa a custom task. * Takes to arguments and returns two responses * to the callback */ function task(arg1, arg2, callback) { // Perform task  callback(resp1, resp2); } task(\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, (resp1, resp2) =\u0026gt; { console.log(resp1, resp2); });    After 1\n1 2 3 4 5 6 7 8 9 10 11 12 13  /** * Task method to performa a custom task. * Takes to arguments and returns two responses * to the callback */ function task(arg1, arg2, callback) { // Perform the task  callback(null, {resp1, resp2}); } task(\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, (err, {resp1, resp2}) =\u0026gt; { console.log(resp1, resp2); });    2) Use nodes util.promisify method to convert existing method to async one by one. If you are not in the node environment you can use a polyfill.\nAfter 2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  const util = require(\u0026#39;util\u0026#39;); /** * Task method to performa a custom task. * Takes to arguments and returns two responses * to the callback */ function task(arg1, arg2, callback) { // Perform the task  callback(null, {resp1, resp2}); } // Provide a unique name to the promisified function  // You will be replacing this eventually with the  // original name once the original function is not used any more  task_p = util.promisify(task); {resp1, resp2} = await task_p(\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;);    3) Handle one off errors or errors that can be skipped with a .catch call.\nBefore\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  method1(arg, (err, data) =\u0026gt; { if (err) { return handleError(err); } method2(arg2, (err, data2) =\u0026gt; { console.log(err); // Continue after error.  method3(arg3, (err, data3) =\u0026gt; { if (err) { return handleError(err); } // Finish task with data3  }); }); });    After\n1 2 3 4 5 6 7 8  try { const data = await method1(arg); const data2 = await method2(arg2).catch(err =\u0026gt; console.log(err)); const data3 = await method3(arg3); } catch(err) { handleError(err); }    Note that after performing a .catch(cb) based special processing, you can still throw to reach the global handler at the try catch. If you want to do different error handling in all cases which was possible with the callback based code, you can use a .catch clause everywhere. The await calls could still be wrapped in try..catch to handle exceptions in the catch block or otherwise.\n4) Once all methods are converted, run a replace all call through the code base to replace new method task_p with the original method name task if we had used the naming convention like described in step 2 above.\nCommon Patterns 1) Wrap parallel code in Promise.all. If some code is meant to be run in parallel, we should not make it sequential. Promise.all call take an array of asynchronus functions and run them in parallel. Since we can now work with array, all the array manipulation functions like map and forEach can now be used. There is also Promise.race for the cases where we need to wait for any one of the methods to respond and do not need to wait for all of them to continue execution.\nBefore\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  let done = 0; // Collect responses here  let responses = []; // All api in parallel for each data element.  data.forEach((x, index )=\u0026gt; { api.call(x, (err, response) { if (err) { return callback(err); } done = done + 1; responses[index] = response; if (done === data.length) { callback(null, responses); } }); });    After\n1  await Promise.all(data.map(x =\u0026gt; await api.call(x)));    Note that with Promise.all and a sequence of await calls all serial and parallel combinations of requests should be handled.\n2) Leave the side effects without await or use the next tick. Sometimes we do have side effects like leaving a call to analytics that we do not wish to wait for or logging that can happen after the response is sent from the server. For these we can ignore the await call and it works just like before.\nBefore\n1 2 3 4 5 6 7 8 9 10 11 12  function log(data, callback) { formatData(data, (err, cleanData) =\u0026gt; { writeToDisk(cleanData, callback); }); } function handleRequest(req, callback) { prepareResponse(req, (err, resp) =\u0026gt; { callback(err, resp); writeToDisk(resp); }); }    After\n1 2 3 4 5 6 7 8 9  async function log(data) { return await writeToDisk(await formatData(data)); } async function handleRequest(req, callback) { const resp = await prepareResponse(req); writeToDisk(resp); // No await means we will not wait for it to complete.  return resp; }    The above assumes that writeToDisk is not CPU expensive. If it is and there is no way to fix it, we could wrap it in a next tick call, like process.nextTick(() =\u0026gt; writeToDisk(resp)) . It might still be hit before the response is actually sent as there might be multiple async calls after handleRequest but that is not something the old code was doing anyways.\n3) Some code can still have callbacks. Not all callbacks need to be converted. Methods like addEventListener are still callback based and are natural to remain that way. In cases like these, the callback function is called multiple times in response to external stimulus and might not be called for the lifetime of the program. If there is no sequential flow of control that the callback based code was making difficult to understand, there is no point in removing callbacks. They do have their place in modern JavaScript, just not to the extreme level that they had before async await.\nWhat async await is not  Async await is not a solution to poorly structured code. Reducing the verbosity of writing JavaScript can be extremely useful in figuring out places where refactoring is needed but it alone will not solve the problem of spaghetti code. There is no shortcut to proper code organization. It still needs to be split into meaningful chunks contained within separate functions/modules/files and properly documented and handled.\n Async await does not magically make the code synchronous. Everything is still asynchronous. The programmer still needs to understand the concept of event driven programming and the event loop.\n Async await is not a performance booster and will not speed up execution of the code. It might help in the cases where accidental synchronous APIs had been used which was slowing down code but if you are looking for a massive performance boost, this is not the right place. Instead are cases where async await can lead to more RAM consumption and can be difficult to debug if we need to transpile the code and do not have source maps.\n  Summary Async await is a cleaner way to express the same ideas as callbacks and do not incur the performance overhead of synchronous code. They may be promises internally but apart from various method names like Promise.all or util.promisify, there is no need to understand promises in depth to use async await in production. All the code can be converted piece by piece to async functions with simple steps. After the completion is done, it would be discovered that not only is the newer code a lot less verbose and easier to navigate but also fixes many bugs that might have crept up over time into the callback based methods. There is little reason to not move to async await especially as all major browsers as well as Node.js support them natively and they provide the same feature set with a much cleaner API as do callbacks.\n","date":"2018-08-25T00:00:00+00:00","description":"A step by step guide for moving from callbacks to async await in JavaScript applications.","image":"/blog/2018/08/25/from-callbacks-to-async-await/cover_hu3845fae99d4020ecdbc1160257290396_1633072_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/08/25/from-callbacks-to-async-await/","readingTime":13,"series":["Async Await"],"tags":["javascript","async-await"],"title":"From callbacks to async - await"},{"category":"Toastmasters","contents":"Below is an excerpt from a speech that was planned but I changed the topic. Since I had written it down, I had an obligation to share.\n{Wear a hat to differentiate an artist}\nHello everyone. Say \u0026lsquo;Cheese\u0026hellip;.\u0026rsquo; {Take a pic}. We all love photographs. Many have SLRs. But do we know how they work and what we can do with them? {pause} I see a few nods. More accessible than ever, camera havent changed much from the 10th century dark rooms called Camera Obscura. Today I will discuss the science and {art} the art of using cameras.\n{Science} The camera models our eyes. There is a small hole called aperture similar to the pupil that allows light to cross the lens and reach the sensor - retina for the eye, silver chloride for film and CMOS for the digital cameras.\n{Art} The most important piece of a good photograph is the lighting. Remember the ugly pics from the drunk disco night. Not your fault. Even lighting is the first thing an artist should note. Disco lights make it difficult. Remember seeing these{holding up a lens hood}. The lens hood is like the sun cap that prevents sunlight from falling into our eyes.\n{Science} Light hits the lens. The huge bulky lens. We use a system of lenses for variable focus as our lenses technology rigid. The eyes can focus on anything. Here is an experiment I want you to do. Hold your finger in front of your eyes. Close one and try to touch the finger with the second hand. {Wait for a few seconds}. Difficult! Right! We have two identical eyes to capture 3D, not to provide different focal lengths for better zoom like the iPhone 7s. Science still awaits reaching the power of a single eye lens.\n{Art} The eyes are better. But we are used to them. {pause} They are boring. Cameras allow us to capture stuff we dont see often. {Holding an inverted torchlight} Light not necessarily fall from the top of our heads. {Holding the cameras at the edge of the wall} There are areas we dont go to. {Holding the camera at the crowd} Moments we will miss in the future. Artist note 2  Show something new or memorable.\n{Science} Lets complete our camera. The image created by the lens is inverted. We need put in something to reverse this inversion  a mirror. The mirror completes the definition of a SLR  Single Lens Reflex. Light comes from the lens, reflects on the mirror and hits the sensor. Lets come to the settings. A photograph is dark when there is not enough light and bright when there is too much. The shutter speed controls how long we wait. In those dark and dinghy nights waiting for the bogeyman, use a tripod to capture the little ones imagination. It will take a while.\n{Art} Shutter is an artists tool. Make it fast when you need action and slow when you need to make it dreamy. Remember, {slow speaking begin} ghosts do come in the dreams. {Slow speaking end} Artist note 3  You can make dreams real.\n{Science} If you widen the hole of the aperture you get concurrent photographs. This leads to blurring. The lens causes blurring to be asymmetric. It blurs more away from the point of focus. The f number controls this.\n{Artists} Using this bug in the lens system we can create Bokeh, an effect where what we want to focus is visible and everything else is blurred. Here comes artist note no 4  Make the viewer focus. Save your budget. Blur the background.\n{Science} Finally comes ISO  the sensitivity of the sensor. The sensor is packed with millions of cells that convert light to pixels. ISO is the multiplier. Think of it like this. The more data the sensor reads, the better it approximates. If it is very sensitive, it is done when it has read little.\n{Artist} Bad ISO leads to grainy images. Keep the ISO low unless you need to increase it. Artist note 5 - Trust the camera. Play with a setting at a time and touch ISO only if forced to.\n{To the middle} Cameras are complex machines with basic settings, focus and zoom you get from changing lenses. The aperture, shutter speed and ISO you can control. Remember the artists notes  control the light, show something novel, make dreams real, blur to focus and trust the camera. Photographs as good as they may be, are not great substitutes for the experience. Take a small number of good photographs. Enjoying the moments is more important than capturing them.\n","date":"2018-07-20T00:00:00+00:00","description":"A planned speech on role playing an artist and scientist on photography. Never used. Free for you","image":"/blog/2018/07/20/the-art-and-science-of-photography/cover_hud98506ea7ea73676068c18af7db28bdd_185785_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/07/20/the-art-and-science-of-photography/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"The art and science of Photography"},{"category":"Toastmasters","contents":"Now that youve enjoyed the hearty meal, I feel comfortable talking about food. It is not like it is 12 PM on a Sunday afternoon and all of you are gearing up to run for lunch. It is not like I will pick up this bread and someone will come up and snatch a quick bit. Looking at this soft piece of bread I am always amazed how mankind discovered the process of making it. The brutes that hurled stones at their prey. Look at the fine details. The delicate pores caused by just enough bubbles in the flour with so much gluten that it could still stay together and not fall through. Then these pieces of fruit sweet and savory. Yummy - just perfect. Unless you believe that god gave us these recipes, you should be wondering how the cave man discovered everything  first the grains, and then the process. From the look of it, the wheat grain is not really sumptuous, hard and tasteless. It will likely cause stomach upset if eaten raw. Yet it has been grown for thousands of years with this perfect recipe. Now without involving the historians and their learning, I will be trying to apply today Darwinism to the discovery of food and see how pure competition and natural selection can lead the cavemen to such delicacies.\nAccording to Darwins theory, the only reason for all diversity is competition  for the scarce set of resources. From the first amino acids to mankind, all the evolution has been led by the survival of the fittest. Whatever won the genetic lottery was better suited to the surroundings and thrived for generations while the weak was decimated. Let us try and apply this to food discovery for cavemen.\nFrom the apes, the cave men had already discovered two ways of getting food - hunting and foraging. The strong had the power to run around and trap an unlucky beast to make a proper meal. The could climb on the trees and get to the toughest of fruit  tasty and delicious. The most strong and skillful were mostly and like the kings in the medieval times had plenty of left overs while the weak like hyenas ate the trash and were still hungry.\nThese unfed cave men were desperate  find something or die. Desperation is the mother of invention. They were not skilled hunters and therefore had little spoils of the hunt and the best fruits were already gone. So, they were happy to experiment. The needy would pick up whatever they could find  wild berries, barks, seeds of any kind including these little wheat seeds. They would mix these with their meat in their soup so that there is a fair share of the meat in every meal alongside the seeds. Now many of these were poisonous and eating them was certain death. But with the sheer number of experiments, even if one in a hundred succeeded, the information was known. All spices, grains or any plant food has been discovered with such approach.\nThis information would form the first trade secrets. I wouldnt tell {person from audience} about these seeds that you can live off. Let him hunt more and risk his chances while I sit at the comfort of my cave with half the hunt. Eventually he would come to know so I would start hoarding these. Dont know if they last but still, maybe they will for me. So, everything was hoarded. Now the plants were also playing the same games of natural selection as we were. The plants whose seeds could survive the winter were the most precious of human possessions and therefore survived while the ones that did not needed to be extremely tasty to be preserved.\nNow these grains are far from bread, but it is easy to decipher bread once we know eating these grains would not kill us. The kids and the old could not chew these hard grains so grinding them between rocks to a powder was the solution. Flour and dough were the easy discoveries. Some seeds would actually fall down on the ground and grow  so farming is the easily discovered next step.\nDomestication of animals was also an easy step. The pets were easy sources of meat and milk. Why hunt if you could pet. Some pets were there for food others for security. The docile wolves became dogs and docile tigers became cats. The cats are smaller than dogs because the tiger is scarier than a wolf.\nBut what about yeast and baking. Frankly, this is a lucky discovery. Not all civilizations found it. But Darwinism can explain it. Early farmers were far from perfect at weeding. Weeds with wild yeast would grow amongst the crops, through the grinding process right into food. Bad weeds would kill people, but you already know thats how Darwinism actually works. With no refrigerators, any left overs had to be left across meals over time. Guess what, it would grow big with the yeast, and the people loved it. So, they worked hard to figure out what it was and isolated yeast that are now reared. The oven is the easiest of inventions. Cooking food over burning wood means that after the food was cooked and fire extinguished the hot logs were still there. All that needed to be done was for someone to leave mornings leftover dough on the logs and see fine bread. Once you taste it, you will eventually make it perfect.\nNow as you understand the theory you can apply it to anything. Yogurt was likely another case like yeast. Paneer, some desperate individual trying to salvage milk that he accidentally spoilt. It has been subtle, but history has one lesson for us  The weak, the losers and the desperate end up taking the world forward. Whatever be the odds that are setup, the one that survives makes the goliath irrelevant by changing the rules of the game. To survive we have to participate in this high-risk high reward game at all times. By the rules of natural selection, even if we dont risk, someone else will and we will be history.\nThe real video was not recorded. I have one of the rehearsals.\n","date":"2018-07-15T00:00:00+00:00","description":"An application of Darwin's theory of evolution on the discovery of bread by mankind - from cavemen to farmers","image":"/blog/2018/07/15/bread-and-charles-darwin/cover_hu6dfb1b3565e4737d6d78d2c6f92d612c_179880_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/07/15/bread-and-charles-darwin/","readingTime":5,"series":null,"tags":["toastmasters"],"title":"Bread and Charles Darwin"},{"category":"Toastmasters","contents":"Today I am going to share a popular folk lore in India, sung as a ballad with over 16000 verses. The story is historically inaccurate. Historians don\u0026rsquo;t believe in the love story. According to them this was just an arrogant ruler who angered his neighbors and then suffered a shameful defeat from an enemy he had earlier let live. But the folk lore differs, and the story is definitely the one to indulge in.\nThe story starts in the green fields of the most fertile lands in the world. The spring breeze on the sunny day clears up the dew on the grass adding the missing humidity to the atmosphere trying to setup a perfect day. The air has a strong stench of fresh blood, blood of the barbarians desecrated by the royal army. The prince stands with his sword inches away from the neck of the barbarian leader, the clan lord who had come all the way to plunder Delhi. The clan lord, tears in his eyes begs for forgiveness. He had a people who needed him. The prince looks at the destruction all around, sheds a tear and then extracts a promise, promise that he would never venture back far east, into this land ever again. He turns and marches back to Delhi, his army trotting in a fine rhythmic fashion. The story of his bravery strung into rhythms reaches far and wide, including to the neighboring kingdom which has a larger army and a prouder king.\nThe velvety carpet, the ornate flowers and the beautiful paintings marked the essence of royalty. The room was decorated not only by the rarest of the jewels on Earth, but also by the rarest of men, the finest kings and princes all over the subcontinent, the fairest - oiled, shaven with muscular bodies and shining armor. All but one, the neighboring prince who had failed to bow down to the ruler, the songs of whose intelligence and valor pierced through many hateful ears in the courtroom. He was present virtually, as statue  a door boy pushed outside of the room to be shamed. The bride, the most beautiful women of all was to choose her husband today. Women were pawns in the game of the thrones. No one cared that her heart was lost to the statue that stood outside the door. The princess pushed forward trembling with her wedding garland in her hand. The open window brought in the wind and the magic of love took over. She overcame her fears and anointed the statue as her husband. Suddenly like magic the prince of Delhi appeared from behind it, swopped her into his hands as he jumped off the window onto his waiting horse, fleeing away even before the royal army could get their hands on the hilts of their swords.\nThe story lands to the same battle field where it began, this time with the swords reversed. The king had tipped barbarian against his own son in law, the ruler of Delhi who had pardoned him earlier. He had attacked the sleeping army for he believed in no honor or bravery, only in victory. The Delhi king was blinded in both his eyes and left there to die. Delhi fell, and the rest of India was next. The barbarians ransacked kingdom after kingdom including the one of the traitor till there was no other king left. Vanity and vengeance had destroyed the country. The goriest days in history.\nAnd so, ended the rule of honorable kings in India. This story does not end like that. Collecting all his loots the winner rides back home. He amuses himself in wealth and women as well in proud display of the fighting skills of his spoils of war. One such day he amuses himself with the archery skills of a blind slave. Just by the sound of the oath-breaker, the erstwhile ruler of Delhi fires an arrow piercing through the middle of the head. No important person survived that day. Delhi was ruled by slaves for a hundred years. Only the story survived, carried forward in poems from generation to generation as the land still pays its homage to the great Prithvi Raj Chauhan.\n","date":"2018-06-24T00:00:00+00:00","description":"A popular folk lore from India about proud kings bringing down the country for vangeance.","image":"/blog/2018/06/24/vanity-and-vengeance/cover_hu3290808858ed668431117277774101b3_53663_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/06/24/vanity-and-vengeance/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Vanity and Vengeance"},{"category":"Toastmasters","contents":"My challenge today is an entertaining speech with a message on a boring topic - Passwords. So I will start with an exercise. I am going two share with you two passwords and want you remember them both. Try not to write them down - it is a bad practice to write down passwords. The first password is - @t1$#aY123. Directly the popular xkcd comic strip, the second password I want you to remember is correct horse battery staple. Ok so I need a volunteer to tell me both my passwords.So the recipe of a good password is that it needs to be a random set of words. Maybe add a non-dictionary word like from the flintstones - yabadabadoo. These are long, difficult for the machine to guess but easy to remember passwords. Now that we are skilled in this, lets clean up our digital life. I want all of you to write hundred different passwords for the top 100 websites that you use and memorize them all. Also remember, we need to change them after every 90 days and cannot use the same password again for at least 5 years. That is where an offline password manager comes in. It is an essential tool that generates these usable passwords and stores them, while you need to remember just one or two.\nNow all these are lessons that were taught to me by a friend who went though hell two years back trying to secure his own finances just because of these passwords. Now he was much more hygienic with passwords than most of us are. I had a professor in college who gave an analogy - Passwords are like your inner garments - Don\u0026rsquo;t show them to others, mask them under proper clothing and don\u0026rsquo;t wear the same ones all the time. He kept to that and was mostly sane. Except for the fact that, his mother was on facebook with her maiden name, first school in his linkedin profile and wife had tweeted their honeymoon destination when tweeting was a craze. His phone stopped working for around two hours one night that he never noticed and the next day he was in serious trouble.\nMost people don\u0026rsquo;t notice this for days. But he was lucky. As a coincidence, while having the burgers for lunch, he noticed something on his cellphone. It was a small message in the pool of push notifications requesting another one of those cows for Farmville. He had not wired money back home in almost six months but the app said he has. He had accounts in many transfer websites (as he used the cheapest one each time). He quickly got his main bank account frozen and contacted the transfer company. He had important meetings for the next 2-3 hours and he was satisfied that he had no money elsewhere and therefore there was no more damage the hacker could do. In the evening he realized he was so wrong.\nIn cases like this, the most important thing is to determine what has been stolen - the transfer site, his bank account or his identity. Unless you know what is lost, it is plain luck if you get away without further damage. And don\u0026rsquo;t think the same person won\u0026rsquo;t be targeted twice. This is not chicken pox. Ask yahoo. It was not just one account for him. The hacker had hit the jackpot - his Gmail account - which had everything. If the hacker wanted the identity was open. It could have been much worse if the hacker took over facebook, paid memberships or anything else linked to his email. It is extremely difficult to track each and everything in your emails and you don\u0026rsquo;t even have a separate backup. Luckily it was an international hack and US identities are not very useful internationally.\nThe hacker had switched emails in all his bank accounts adding an extra a to his name and was quietly siphoning off money. Do you know bank accounts can be drained to negatives balances? Most international crooks that siphon off money never get caught? Fraud protection in the developing countries is very poor. He learnt a lot more lessons as the case unrolled. Some of the losses in the Indian accounts were lost to bureaucracy and the complicated international situation. The hackers got away with whatever they stole and were never caught. Luckily the bank gave bank his US funds and he lived to tell his tale.\nThe summary of what we should do simple: Always use an offline password manager. Your secret questions are more passwords to remember. Learn what a good password is like - \u0026ldquo;correct horse battery staple\u0026rdquo;. And the most important of them all - \u0026ldquo;Don\u0026rsquo;t keep a lot of money in bank accounts, especially where following up with is difficult and bureaucratic\u0026rdquo;. So, does anyone still remember the XKCD password I shared at the start of the meeting? - \u0026ldquo;correct horse battery staple\u0026rdquo;\n","date":"2018-06-02T00:00:00+00:00","description":"Passwords are a part of our life. It is better to learn how to deal with them rather than suffer.","image":"/blog/2018/06/02/passwords/cover_hu021dcffa8f89d84954a100c96f975efa_122739_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/06/02/passwords/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Passwords"},{"category":"Guitar","contents":" A secret that I have been keeping from a lot of folks around me is that I have been practicing guitar for a while and thanks to my instructor Matthew Fish I think I have been getting somewhere. We have moved from nursery rhymes to songs now and therefore, I can have fun recording. Additional thanks to my wonderful wife for lending her beautiful voice to the song which would have been very boring without it. I am also adding my tabs here so that if you want to practice along you can try it:\nIntro Matt helped modify the original to make it easy for me and also to help sync up with the singing:\nCreated with Raphal 2.2.0TAB00787000787010\nPart 2 -\nCreated with Raphal 2.2.0TAB320120524045757404EmIIIo02232o0o0o0\nThe above ends with a Em cord.\nStrumming Keys Created with Raphal 2.2.0EmIIIo23oooAIIIxo213oCIIIx32o1oB7IIIx213o4EIIIo231ooDIIIxoo132BIIIx13331 Verse I have given each beat and not each measure here for easier understanding. No half beats or confusion.\nThe strumming pattern is ||.\n (Em) (Em) Chura Liya (A) (A) |: Bahaar Banke Aaoon (Em) (Em) Kabhi Tumhaari Duniya Mein (A) (A) Guzar Na Jaaye Yeh Din (C) (Em) Kahin Isi Tamanna Mein :|(2) (B7)(B7)(B7)(B7)(B7)(B7)(B7) Tum Mere Ho, Ho Tum Mere Ho (E) (E) (E) (E) (E) (E) (E) Aaj Tum Itna Vaada Karte Jaana (Em) Chura Liya (Em) (Em) (D) (D) Chura Liya Hai Tumne Jo Dil Ko (Em) (Em) (B) (B) Nazar Nahin Churaana Sanam (Em) (Em) (D) (D) Badalke Meri Tum Zindagaani (Em) (Em) (B) (B) Kahin Badal Na Jaana Sanam (B7)(B7)(B7)(B7)(B7)(B7)(B7) Le Liya Dil, Haai Mera Dil (E) (E) (E) (E) (E) (E) (E) Haai Dil Lekar Mujhko Na Behlaana (Em) |: Chura Liya :|(2)  I simplified the above for myself. The most common one would have 50% the symbols with the strumming pattern   and special casing for certain notes.\n","date":"2018-05-17T00:00:00+00:00","description":"My foray into the guitar - Chura Liya (Yadoon Ki Baraat)","image":"/blog/2018/05/17/chura-liya/cover_hu740e26ccd13a5bd1142d5ab706ac477e_190263_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/05/17/chura-liya/","readingTime":2,"series":null,"tags":["guitar"],"title":"Chura Liya"},{"category":"Toastmasters","contents":"How many people here have been to Delhi? You need not be proud of that. Even I am from Delhi. You guys should know what IST is. IST is the only time zone on this planet where the clock hits 10:30 for the 10:00 clock meeting to start. And it is not our fault. The Delhi traffic is unpredictable. If google says it will take 15 minutes to cross a stretch of 2 kilometers, it could take anything from 5 minutes to 5 hours. How can you plan anything? Today I will talk about this unique beast called the Delhi traffic. It is very different from 101.\nRoad rules are different in Delhi. There is no lane driving and no speed limits especially the minimum ones. Everything shares the same road. A Merc(Mercedes) can lose to a hatchback in a race. Especially if a bullock cart is participating. And if there are cattle on the road, a bike might be the only one reach the finish line.\nDrunk drivers are not an issue in Delhi. They have people with a variety of health problems. One of them are the constipation drivers. It takes them a lot of effort to step on the pedal. Everyone is waiting. The light goes green. It won\u0026rsquo;t go greener. But these guys don\u0026rsquo;t leave until the first biker jumps the red light.\nThen there are the loose motion drivers. They find their way. A gap over there and a gap over here. If you are not driving bumper to bumper, they will squeeze in. And as soon as they get a complete opening - \u0026ldquo;Badhaam\u0026rdquo;. They are always in a hurry. Even if they are going to pick up their mother in law, they are in a hurry.\nThen there is another category called the dementia rivers. These are difficult to locate. You can meet them whenever you hit their car. They come out shouting - Do you know who I am? You know who you just hit. Do you know who my father is? Maybe I should just call him up and tell him that Ive found your missing son. In the age of cellphones.\n  Auto-Rickshaw   But these are normally not the causes of the unpredictable traffic. There is this another category of vehicles. When the rules for motored traffic were made, they crafted two types of licenses, a two-wheeler and a four-wheeler. These people invented a new vehicle category - called the three wheelers or auto-rickshaws. And since three wheelers are between the rules, they have no rules for them. They are literally the moving speed breakers. You know when you are going up at 70 km/hr, you see a fly over. You then start going up a fly over. Suddenly in front of you, there will be an auto, going at 12 km/hr, overloaded with 10 different limbs hanging out of 10 different sides. It is running on CNG. Overloaded auto, on CNG going on a fly over. Like an asthma patient going up to mount Everest .EEEEEEE It can die any time. But that is not the biggest problem. The bigger problem is that it is taking over another auto that is running at 10 km/hr.\nIn Delhi there are different uses for various parts and pieces of the transportation system. The lane markers are parking boundaries. You can safely park your car as long as you dont ouch the line. At least one lane should be free.\nThe traffic signs have a wide variety of uses. From notice boards to hawker stalls, there is use for everything. You have a drying rack for clothes at every intersection.\nThe horns are used for declaring that you are driving. If you see a car and it doesnt honk for 10 seconds, it must be parked there.\nThe hazard lights also have a different meaning. They could mean anything from - it is a hazardous situation - my wife has gone shopping, or it could foretell a hazardous situation  I am gonna break all speed limits. You dont need them in case of a real hazard. A few hundred people will gather around you within a few minutes all looking at you  What happened?\nThat car came from nowhere. It really hurts.\nOk. You should call the ambulance.\nThere are many advantages of driving in Delhi. You can easily appreciate the improvements of a century of the car industry. Those cars are really a tough bunch. After Delhi, you can drive in any part of the world. As a defensive driver, you will never get hurt. God save the others on the road. If you ever go to Delhi, definitely drive. You will fall in love with driving because the other options - like buses and railways  are much worse.\n","date":"2018-03-25T00:00:00+00:00","description":"Driving in Delhi requires is really different, a unique and rewarding experience you could ever imagine.","image":"/blog/2018/03/25/delhi-driving/cover_hu5bcd77dad314172ba343d287fc1f2783_711829_100x100_fill_box_center_2.png","meta":null,"permalink":"https://atishay.me/blog/2018/03/25/delhi-driving/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Delhi Driving"},{"category":"Toastmasters","contents":"Friends, do you remember the speeches last week? One of them had a pyramid called Maslow\u0026rsquo;s need hierarchy theory. Does anyone remember the Physiological need - the bottom most part of the pyramid? \u0026hellip;..How about the internet - Does anyone feel the internet is a basic necessity of human life. I am going to challenge your thoughts. How about electricity - the basis for everything. I am going to describe today a day from back in college when I went almost powerless - fighting for the lowest step of the need hierarchy.\nIt was a Sunday morning just like today. After the Megan Fox movie last night, I was the least prepared to be foxed by the gods that day. I woke up in a pool of sweat, very early from my own standards right when the clock hit 11. The fan had been the first victim of the city wide outage - 12 hours in and counting. I dragged myself to the water bottle in my room, only to find it empty, gorged away by my roommate. I ran out to the water cooler, bare foot and without my glasses. I never noticed that the sun had burned the tap hot. They need power to cool the water. I barely cared. Until I realized that the tank was empty. They need power to run the motors. Everyone had been roaming around foraging for water - beg, borrow or steal. That was the first time I paid for bottled water literally to clean my shit.\nAfter hitting water, the outage was about to hit another of my physiological needs - the Internet. I can live without facebook for a day, for months. But it was the last day of a project submission. There are only two choices in student life - death and homework. My project along with two others laid in my desktop, a brick without the battery. When hunting for a UPS did no good - we realized very soon - we were in big trouble. In the scared Indian text of Ramayana, lord hanuman carried a mountain to cure his god Ram. In the sacred world of college, a student carried a CPU cabinet door to door looking for some spare electrons only to find none. The cyber cafes were also out of power and the world was coming to an end. Desperate times call for desperate measures. The ATM has a power backup. We sent an army to see if we could plug something there. They never came back. The A/C was too good to give up. The next battle was at the server room. The college email servers hadn\u0026rsquo;t been silent for a day. But they were guarded 24x7. The keys were difficult to get hold of. We had to have an insider - the Research Assistant that could be bribed. Jack Daniels old no. 7 was quietly smuggled into college. The CPU was split apart into a hard disk. The guard was distracted by the spillage of a bag of books by a cute accomplice and two students quietly tip toed into the server room. Rest was easy. No one noticed the backup server going down during a power outage. We had the wires sprung and the submission completed in less than hour. Now walking out was another challenge. Our female partner wasn\u0026rsquo;t cute enough to spill books again and get an answer to her call. We were stuck. The professor would show up in fifteen minutes. Instant death. The RA then spun up a brilliant idea that earned him his second JD\u0026rsquo;s. He slammed out of the door shouting at us for enjoying the A/C and not helping with the work we were brought in there for. A gust of cold air distracted the guard as we walked out covering our faces as in shame. That was the biggest margin for a \u0026ldquo;A\u0026rdquo; grade I ever got. 30% of the class re-did that subject. The rest had to work really hard to cover up. The RA became a close friend.\nElectricity is the basis of the lowest rung of Maslow\u0026rsquo;s pyramid. When there is no power, everyone is powerless. From food preservation to water pumping, all other needs depend on electricity. Even our credit cards are useless without power. I really feel for my friends in New York who lost power for a day and those at Puerto Rico who have been living without the necessity for months. I hope their problems are short lived and no one in the world feels powerless.\n","date":"2018-03-11T00:00:00+00:00","description":"The entertaining speech about the need for electricity in life and life without it.","image":"/blog/2018/03/11/powerless/cover_hu6fb8c6913bb380f2d5301eb0071cac4c_87348_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/03/11/powerless/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Powerless"},{"category":"Toastmasters","contents":" Introduction Welcome to the day light saving day! This change marks the special point when we are in the middle of spring and the plants are growing up for an amazing summer. We will having table topics today around this fabulous season-\nQuestions  What are the three things you love about spring?\n What outdoor activities do you enjoy in the spring?\n What do you recall about springtime when you were growing up?\n What calls you to the cold mountains in spring?  What benefits do you derive from going on vacation during Spring season?\n What is your favorite season and why?\n What are your favorite springtime activities? What makes them special to you?\n Are there some things you tell yourself every year that you will do in spring but never get around to doing? Why?\n What role do seasons play in your life and planning?\n Spring cleaning is a reality in some people\u0026rsquo;s lives. What is the relevance of spring cleaning in your life?\n Is spring just a summer \u0026ldquo;wannabe\u0026rdquo; or does it have a value all its own?\n Springtime is often seen as a time of new beginnings and hope. What would be some signs of springtime in our toastmasters?\n We moved the clocks forward today and lost an hour of sleep. How does that affect you?\n What are your thoughts on the pros and cons of Daylight Savings Time?\n Share your favorite spring memory.\n  ","date":"2018-03-11T00:00:00+00:00","description":"Table topics questions used at a themed meeting around spring.","image":"/blog/2018/03/11/spring-time-table-topics/cover_hu0ab92480703566d1debb635b724bf67e_142582_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/03/11/spring-time-table-topics/","readingTime":2,"series":null,"tags":["toastmasters","tabletopic"],"title":"Spring Time - Table Topics"},{"category":"Toastmasters","contents":" Welcome to 2018! A new year is a great way to mark a checkpoint in your life. It is also the best time remember the last year and the years before that, recalibrate your dreams and head onwards with life.\nIntroduction With resolutions in the new year, we plan to do some firsts. Everything we do in life always had a first. Indeed, this is the first time I am writing this post. So everything we do is the first time we have done this exactly that way. Something we did for the hundredth time is also the first time we completed doing that for the hundredth time. Keeping that mindset would really make it feel fresh. The other way to keep something fresh is remember the first time we did it. and that\u0026rsquo;s what the questions are around. We talk of something and you speak about the first time you went through that experience in life.\nQuestions Narrate the experience with/at your:\n First job\n First speech\n First day in college\n First day when you started living without your parents.\n First day you saw your significant other.\n First time you failed in an exam\n First movie you saw in a theatre that you remember.\n First time you made a big mistake\n \u0026lt;Someone with glasses\u0026rt; First time your glasses broke\n First time you were punished in school\n First book you read yourself.\n First crush of your life\n First car\n First day of 2018\n First home\n First fighters meeting at toastmasters\n First airplane journey\n First Time you cooked\n First time you travelled to another state or country\n First trip with friends\n  ","date":"2018-01-07T00:00:00+00:00","description":"Table topics questions used at a themed meeting around first time in life.","image":"/blog/2018/01/07/first-time-table-topics/cover_hu9fb2fa1522fa22f28ae05d0e2cb5b54f_37985_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2018/01/07/first-time-table-topics/","readingTime":2,"series":null,"tags":["toastmasters","tabletopic"],"title":"First Time - Table Topics"},{"category":"Toastmasters","contents":"Here are the contents of my CC#10. Timed right before the new year, this speech explores setting up successful goals and achieving them.\nI was looking through my files last week when I fell upon a rusty old document lying there. It was my new years resolution from last January. It was not a great sight. Do I look better than Brad Pitt? No. Am I richer than Bill Gates. No. Am I more popular than Donald Trump. Definitely not. I couldnt even become happier than the laughing buddha. Friends I have failed at my new years resolutions, this year, just like last year. How many of you actually write resolutions and succeed in them? As a consolation, I got one right this time. In 6 minutes from now, I will be a Competent Communicator. 20% success. Not that bad.\nLooking back, I realize CC was the only goal that I had which was Smart. Not the smart smart  but the smart defined by George Doran in 1981 - Specific, Measurable, Actionable, Realistic, Time-Bound.\nSpecific  CC was my only specific goal. Ten speeches. Twelve months. Bill Gates is a moving target. He is not even the richest man on the planet any more. I shouldnt have tried to beat him.\nMeasurable  CC is measurable. At the six-month line, I had done 5 speeches. I knew I was at 50%. I bought a new dress. Trimmed my hair. By how much did I get closer to Mr. Pitt. I dont know?\nActionable  CC has clear steps to get through. Each speech defines what to do next. Evaluators tell me exactly what I need to improve. What do I do to become happier? Can anyone know.\nRealistic  A speech a month is practical target. To beat Bill Gates, I need to earn 8 billion dollars a month. I wont get that even if I sit on a gold mine.\nTime Bound  The time to finish a new year resolution is and should be one year. Richer than Gates has been on the list for ten years now. Not a good time bound test. Dont write Jeff Bezos in the next list. It is the same resolution. Build a new one.\nNow that the official list is done, let me tell you the real list, were you planning to right one for next year.\n Always cheat  I started CC last year. I was 20% done already. That way I was mostly ahead of the curve. It really felt better.\n Reward yourself  Have a chocolate after each success. Even if you are trying to reduce weight. Reward is important. Just like what I got in the evaluation forms.\n Enjoy it  The journey should be better than the reward. Gorging money from others wont make you richer. Shaming yourself on the internet wont make you popular. Laughing on others wont make you happier. Enjoying the journey while you do it -that will make all the difference.\n  Now I want you all to take your agenda and revert it. Lets write our resolutions for next year. 3 goals in the next one minute. Make them smart  specific  no moving targets, measurable  clear steps, actionable  where you know what to do, realistic  something thats possible and time bound  that completes in one year. Think of things you always wanted to do. Think of things youve already started. Think of things where you can cheat. Think of things that are not on your last years list. Now that the time is up  How many of you want to give speeches next year. Buy a box of chocolates one for each speech and put it next to your alarm clock. Eat it once you complete the speech. Remember to keep it enjoyable for speaking should be fun. And be ahead of the curve by booking it early. There is a meeting on January 7 and one slot is open. I am the toastmaster, you can book it right now. Do I have a speaker?\n","date":"2017-12-10T00:00:00+00:00","description":"My final CC speech for toastmasters - on how to finish CC by playing smart","image":"/blog/2017/12/10/smart/cover_huaa329d7ca086ef8e22e33da2e2ca887b_135738_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/12/10/smart/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"SMART"},{"category":"Toastmasters","contents":"Friends. You know America maintains a list of banned organizations that we as residents are not allowed to join. How many of you think toastmasters should in there? How many are with me on this - toastmasters should be banned. I am surprised. Are you sure\u0026hellip; No one. Do you all think the weapon of public speaking should not be licensed? Well, I need to open your eyes.\nAnyone knows this guy? He was the greatest orator of the twentieth century. He was not only a master of content but also of vocal variety and body language. His speaking skills killed people, burned countries and did more damage to the planet than anything else in history. Had he been a bad speaker, who would have cared? Speaking is a weapon of mass destruction. If it falls into wrong hands, all is lost. Toastmasters gives it to everyone. There is no test of ethics, morality or even sanity. Shouldn\u0026rsquo;t dangerous weapons be kept under wraps. Or should we distribute pamphlets, do open houses and invite guests? Toastmasters teaches weaponry without a license. Scary!!!\nMany of you should know the concept \u0026ldquo;united we stand\u0026rdquo;. A single stick is easy to break. That story is incomplete. The sticks need to be similar  simple, straight. Then the leader, orchestrator, the captain can band them together. Not when they are all different. That is the biggest problem with toastmasters. If you bring hundred people in the room only one would be confident enough to step on the stage. He would motivate them to do something by his skills. But if everyone is a speaker, then it is chaos. Power is not knowledge. If you give someone x amounts of power you lose 2x to that person. Giving it to everyone is a very bad idea. Humanity needs hierarchy to work. Lions dont survive without the sheep. We need people to listen to a leader and follow orders. Toastmasters is bent on giving everyone the skills to affect emotions, be confident and motivate others. What happens when it succeeds in its mission? Everyone pushes their agenda and nothing gets done. I don\u0026rsquo;t understand how toastmasters got employers to pay for it. The idea is totally insane. Think about all your subordinates and coworkers being persuasive speakers. How the hell do you get some work done?\nIf these two reasons are not convincing enough, let me give you another one. Suppose you got your name in the Guinness book of records for being the best player in a new sport. Now you control the rules of the sport. Will you modify them to make it easier to score better or make it tougher. The first rule of climbing a ladder is to the break what you step on so that no one else can follow. Otherwise the beautiful roof is going to be too crowded. You will lose your sense of achievement. Let the resourceful build another ladder. Be greedy. You got toastmasters, why give it to others. Think about it. When all the great speakers around you get old and retire, you will be left with this rare skill. Public speaking is the most important job of a king. There are two ways to achieve it. Work to be better or make others worse. Do you want to take chances?\nThink about what I said. Public speaking is a power and not knowledge. It shrinks when you distribute it. Give it to the wrong person and it causes havoc. Give it to everyone and nothing gets done. Prevent people from having it and you are the big fish in the pond. Toastmasters is distributing it freely. Think before you promote toastmasters else you might suffer.\n","date":"2017-11-19T00:00:00+00:00","description":"Trying reverse psychology to promote toastmasters. Conviction by contradiction.","image":"/blog/2017/11/19/toastmasters-should-be-banned/cover_hu29e03d2f7e76e2edab927b34cc8f072d_37807_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/11/19/toastmasters-should-be-banned/","readingTime":3,"series":null,"tags":["toastmasters"],"title":"Toastmasters should be banned"},{"category":"Toastmasters","contents":" Welcome to the culture special. America is a melting pot of diverse cultures and the american culture has picked up elements from a lot of them and evolved them into something totally unique and american. Today I will be celebrating the American culture with all of you through multiple questions where you can speak what your heart feels:\nMember Questions  Blue Jeans, invented by Levi\u0026rsquo;s Strauss in San Francisco is one of the biggest contribution of America to the way the world dresses up. Imagine a world without Jeans.\n With 96.7% penetration of Televisions into American homes, we are in the golden age of mass media broadcasting in the United States. Suppose you own the TV station of the most popular channel in the US. What would you like to broadcast?\n According to the 2000 census 97% of Americans can understand English. That is the biggest uniting force in the country. Can you live in America without knowing English?\n American Cinema is the most popular throughout the planet. Many movies earn more internationally than with the national audience. What do you think makes Hollywood grand?\n America started mostly as a blank slate being the land of immigrants and could pick up any culture. What aspect from the culture of anywhere else in the world would you like to bring to America.\n Carbonated drinks like coca cola and foods like hamburgers, hot dogs and fried chicken redefined America to be a place where the daily necessities of life like cooking suddenly vanished. Imagine a world without fast food.\n America has more cars than anywhere else in the world. What aspect of driving do you enjoy and what do you hate the most.\n Many American sports are local and not played throughout the planet. Many international sports are not played widely in America. Which American sport would you like to spread throughout the planet or which global sport would you like to bring to America.\n From the 1960s the biggest change in American living has been the shift from one earner families to two earner families. What aspect of the one earner families do the two earner families miss?\n Owning a house is one of the corner stones of the American Dream. Money not being an issue, can you describe your ideal home and the ideal location for such a home.\n In 1919 Alcohol was banned from America. What would you do were that to happen again?\n Innovation has been the heart of America from the light bulb to the iPhone. Which invention is the hardest for you to give up?\n 60% of Americans volunteer to help others in need. If you were the president, what would you do to increase this number.\n Many American federal holidays are celebrated on a Monday. Do you like the idea?\n Americans work almost 2000 hours a year, 500 hours more than the Germans. What would you do if you were given those additional 500 hours and year?\n  Guest Questions  US Dollar is the most powerful currency in the world. If you had a machine that could print dollars that could not be identified as fake, what would you do?\n America redefined world transportation from the invention of the Airplane to the TSA. What would be your ideal trip or journey?\n In sharp contrast to the early 20th century only 2% of Americans live on farms. Would you love to have the rural life?\n Sports are things that bring people together. Teach the audience your favorite sport.\n  ","date":"2017-11-11T00:00:00+00:00","description":"Table topics questions used at a themed meeting around the american culture.","image":"/blog/2017/11/11/american-culture-table-topics/cover_hu35397820b08d742d575b34485d066140_110501_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/11/11/american-culture-table-topics/","readingTime":3,"series":null,"tags":["toastmasters","tabletopic"],"title":"American Culture - Table Topics"},{"category":"Toastmasters","contents":"This is for my CC#09 - Emotional Topic, persuade with power:\nWelcome to November. Today i will give you three short stories. You can imagine them better with eyes closed. First is the story of Abdullah. Abdullah is running. Running like there is no end. Running for four hours continuously. The mid-day sun is searing his body. The temperature is in mid 100s. The scorching desert heat has dried him up. His breath is full. Blood and sweat drips down through his cheeks into his mouth. He continues to run. His throbbing heart asks the question - What mistake did he make? honesty, truthfulness, love for his family. Was it his fault that the ISIS came. Was he wrong when he kept drilling when they threatened his family? How is he now a traitor. Suddenly he trips and falls, bruising both his knees. His cramped legs are crying out loud - they cannot take it any more. He knows he cannot get up. He picks up his gun and closes his eyes. The roar of a jeep falls upon his ears. He presses the trigger.\nBAM\u0026hellip;. The alarm rings. Mr. Peng is struggles to get up to his feet. All three including the crutches. He stretches to get his glasses. Wipes it around the cracks. He has no time to waste. He wishes he could run. He cannot be late today. Today is a special day. The day he has been living for. It is his grandson\u0026rsquo;s birthday. He is going to send him a gift. His entire year\u0026rsquo;s saving. With the compensation from the accident, his life\u0026rsquo;s goal will be fulfilled. His grandson would go to college. No more is he worried about the stench of the place. His tattered clothes are not something to be ashamed of. The food that taktes like vomit is something he doesn\u0026rsquo;t mind. The shift that starts at 8 and goes on till minight doesn\u0026rsquo;t scare him. He is not afraid of getting stuck in the machine any more. He staggers through the door, continues to crawl to the bank, deposits the parcel. Tired he sits on a bench and lies there waiting. Waiting for the parcel to be delivered.\nKwento eagerly awaits the parcel. The best is in the first catch. The truck approaches and dumps its load on the rest. Kwento rushes onto the dump. Quickly he is back with his arms full. There is always some neat stuff that pours in. Makes the stench and the mosquitos totally worth it. Kwento starts slamming some of the items on a piece of rock. With great efficiency he crafts out the batteries, the metal and other stuff from the plastic. He does that for 12 straight hours until the bell rings. Coughing in the cancerous air, he stands up. He submits his work for a reward - a meal for his family for the day.\nOpen your eyes. That my friends is not the story of Abdullah, Peng or Kwento. That is the story of the drone you bought last year at Thanksgiving and the hoverboard the year before. Such a big waste. Folks like Abdullah drilled the oil for the plastic. Workers like Peng assembled them. Boys like Kwento cleaned up the trash. The consumers didn\u0026rsquo;t care and the corporates didn\u0026rsquo;t worry on what impact they were having. So much effort that could have gone into bettering human lives all got lost. We are still in the world of scarcity, of hunger and of need. We have gotten trained to filter that out.\nThe world economy is dependent on American household consumption. The end of the year is a make or break event for multi-nationals around the planet and Americans are their prime targets. Americans have the wealth and the power to change the world. But they are all focussed on the small trinkets that they buy in November, gift in December and throw away in January. The three hundred dollars that were spent on the hover board, had they been put into the S\u0026amp;P 500, would have fetched 450. Had you put them in bitcoin, you could have been in a Ferrari.\nShopping without a need is a pure waste of money. Save it and it will be there in bad times, invest it and it will grow. Donate it and folks like Abdullah, Peng and Kwento would have better lives. Spend it on the same things that you bought last year and the world would continue like it has been. November is the time the stores clean up their trash, it should be the time we clean our minds and not our wallets. Think this November, about these other folks, before swiping the card. Think !! Think !!\nUnfortunately, this speech was not recorded. I don\u0026rsquo;t have a recording to share.\n","date":"2017-11-04T00:00:00+00:00","description":"This November before going onto shop, think about the repercussions of your actions","image":"/blog/2017/11/04/think-this-november/cover_hue85079993f1ee7c5da2115c35d19813f_157514_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/11/04/think-this-november/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Think this November"},{"category":"Toastmasters","contents":" Toastmasters\u0026rsquo; table topics are fun. You are picked up unprepared and told to speak on things you never thought you would speak on. We have been working hard to make it more interesting - getting people to really think on the fly by not letting them tapping into their speeches and past table topics by providing interesting situations to speak about. Here are some sample questions I created for a session I hosted. Enjoy.\nIntroduction Today\u0026rsquo;s topic is around weird situations in life. Our speakers will be told about a weird situation that they have been just been through. They have to tell us how they got out of it:\nQuestions  You invite someone on a date, but forget your wallet.\n You dropped your roommate/partner on the store while going on a 3 day official trip and accidentally took the house keys with yourself.\n You had a difficult client who after 2 months of hard work finally gives you the check and you spill curry on it.\n You are the toastmaster to a meeting and on the last day all speakers back out.\n You are about to be awarded on stage in front of 5000 people and in nervousness, just half an hour before the award you spill water all over your clothes.\n You take a sick leave for a game and your boss shows up at the stadium.\n Your FB account gets hacked and the hacker offends your significant other.\n You are caught sleeping in a meeting that was supposed to decide your promotion.\n You are running late to an important flight and and see a cop car flashing its lights behind you.\n You just moved to a new place and come to know that it is supposed to be haunted.\n You are caught by a casino security team who thinks that you cheated in your winnings.\n You are on board a 10 hour flight and you fear the guy sitting next to you has some wrong intentions.\n You go on a vacation to discover that accidentally the neighbor\u0026rsquo;s pet travelled with you in your car.\n During your school days, you accidentally fall upon the exam papers two days before the exam. Do you sell them, ace them, or be ethical.\n You click on an email to discover that you just got your office hacked.\n You are in a remote area at around 10 PM with no cellular connectivity and you are running low on fuel in your car.\n You fear someone is following you.\n You discover that you and your best friend have a crush on the same person.\n You are driving and took a wrong turn accidentally entering Mexico.\n A tiger is loose in your neighborhood and you hear some sounds in your garage.\n  ","date":"2017-10-20T00:00:00+00:00","description":"Table topics questions used at a themed meeting around weird situations in life.","image":"/blog/2017/10/20/weird-situations-in-life-table-topics/cover_hua3900db0e7901c1bfe255b2fe71929cb_143776_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/10/20/weird-situations-in-life-table-topics/","readingTime":3,"series":null,"tags":["toastmasters","tabletopic"],"title":"Weird Situations in life - Table Topics"},{"category":"Deep learning","contents":" Tips from the experts This is the tenth part of a multi-part series on deep learning. You should start with Part 1.\nRecap So far we have looked at dense and convolutional neural networks. Then we tried our hands with transfer learning, that is using a pre-trained complicated model and tuning it to our different data set and getting wonderful results for that data set.\nIn this post we look at the identifying characteristics and new techniques that we can pick up from the best papers in the image-net challenge.\n5x5 as two stacks of 3x3 We already talked about how two 3x3 networks are more efficient than a 5x5 network. Now is a good time explain why. Lets take a pixel. For a 3x3 filter(3 along width and 3 along height), we use 9 variables while for a 5x5 we use 25 variables. With two 3x3 layers, we got to use only 9+9=18 variables. This means the same data is represented by fewer variables that bring faster processing on the table. With more experiments we have figured out that the additional variables makes the overall model slower and does not add enough value for justifying its inclusion.\n1x1 Convolutions These convolutions were popularized by GoogleNet\u0026rsquo;s usage in Inception. The idea looks stupid at first. We are looking at a single pixel, how does this hold up in the growing knowledge of the network. Doesn\u0026rsquo;t make any sense. We already talked about how CNNs tried to map hierarchy and 1x1 did not make sense. Well there is one thing we forgot to take note. A pixel is three colors - R, G \u0026amp; B. A 1x1 convolution is done to convert these three dimensions to one number. That reduces the operations required in the future 3x3 convolutions because otherwise they need to be run in all layers. This is a useful performance optimization as you might have seen, we are already running into bottlenecks with the processing power of the machines. The relation between the RGB color space components may not be based on the location and therefore it does not make sense to put them as a part of the 3x3 convolution.\nAnother point to note is that these may not be just 3 layers. We could have 200 parallel 3x3 convolutions running on an image that gives 200 dimensional image which would really save a lot from the 1x1 convolution.\nHighways and Residual Networks One problem with making the networks very deep is loss of signal from the leaves to the root. At each stage, if you look at it, we are multiplying by a weight and therefore the early few players get weighted down by a lot of managers that have their own biases and weights which causes the information to die down. Residual networks solve this problem by creating skip level connections. If a level can skip a few managers and end information as well get feedback by a fewer levels and the overall flow of information will be much smoother. The intermediate managers do their processing but skip level managers can take the input both from the managers and the nodes that report to them. This allows the skip level managers to provide a more direct feedback and hence fix the problem of information loss. These networks are also called highway networks as we can create an information highway that allows fluid running of information from the lower level employees to the CEO.\nInception Inception is kind of the next level of information sharing at least at the lower level. The concept of inception is that a the manager of a pixel should look at the results of a 3x3 as well as a 5x5 (which can be represented as two stacks of 3x3 one over other) subordinates to take a decision for that pixels and pass over. This concept can be used in tandem with ResNet and the information highway. Essentially, instead of having a 3x3 convolution, we have a single pixel, a 1x1, 3x3 and a 5x5 convolution which is used as an input to a cell that can act on the combined information. In our organization analogy, the director does not just rely on the managers but the individual employees as well (all of them for his inputs). Then his boss\u0026rsquo;s boss relied on all the directors as well as the intermediate manager.\n7x1 and 1x7 shortcuts After multiple experiments we are at a point where we know it is better to go deeper than wider. Therefore we have tried various approaches that reduces number of variables so that we can go deeper with the same CPU power. In the 3x3 chain, you might have noticed the redundancy where each pixel is visited 9 times so that each future pixel can take input form 9 different pixels. This seems like a good opportunity for optimization. Here comes the 3x1 and 1x3 networks. First create a single pixel from the 9 pixels by not visiting the same pixel twice. This will reduce the dimensions across the width and the height by a 3x1 filter (hence the name). Then get back to the original dimensions by a 1x3 filter. This allows stacking to continue normally. This drastically reduces the number of parameters for a look across the 9 pixels from 9 to just 4\u0026frasl;9. Now the information cannot really travel though such a network. There will definitely be losses. We cannot really squeeze in so much information through these variables especially in the layer of 1/3rd the size. There are tricks that the network can follow if the need comes up. For example packing the information in regions or bits in the input. But yes, a lot of information gets lost. That is why inception uses this technique as there is a parallel track that passes the useful information from the lower pixel in parallel. Another thing to remember is that there is a lot of redundancy in images. If you down-sample an image, it is very likely that you will still be able to recognize the regions inside of it. SqueezeNet has also found that this technique works without the parallel inception track in some cases.\nSummary In this post we looked at more techniques, 3x3 stacks, the 1x1 convolution, 7x1 and 1x7 shortcuts, residual networks and the concept of inception in convolutional neural networks.\nIn the next post we will play more with the convolutional neural networks and look at an interesting application of convolutional neural networks - style transfer.\n","date":"2017-09-21T00:00:00+00:00","description":"The best models have some real clever tricks to get through the last mile. They are worth learning.","image":"/blog/2017/09/21/deep-learning-part-10/cover_huad45a47a122f959edb1dba3cb357c146_233580_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/09/21/deep-learning-part-10/","readingTime":6,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part X"},{"category":"Deep learning","contents":" Using the model library This is the ninth part of an intended multi-part series on deep learning. You should start with Part 1.\nRecap In the previous posts we got to understand the intuitions behind regular(dense) and convolutional neural networks. Now it is time to see why we could skip all that.\nTransfer Learning Building neural networks from scratch is a great way to learn the details of how they work, but there is a much better way if we are looking to apply the principles in practice. We talked about when we introduced convolutional neural networks the fact that we can start with the path of 9 pixels and then collect the information from there. The key point in this architecture is that there is not a lot of differences in 3x3 patches of images from many different categories. So if we have a good enough database of real life images (imagenet is one such database), we should have the most practical 3x3 patches covered. That means we can reuse the weights from this learning on a new task.\nThe concept of reusing parts of the model from some of the state of the art trained models is called transfer learning. This is very powerful. This instantly makes deep learning very accessible. You do not need tons of CPU power and a huge data set to get going on a specific problem. You can tune some of the most complicated networks to work reasonably with very little data.\nModel Zoo The concept of model zoo is to have a place where we can download pre coded and pre trained models for common tasks. Keras comes in with a built in set of certain models.\nHow do we transfer the model? If you are training the model to recognize an image, you need to change the set of classes or categories you are grouping the images into. The way to do that would be to change the last layer to group the images into a different set of classes and then retrain. You will notice that in many state of the art models, the last few layers are dense. This is because the early few layers summarize the local information into meaningful chunks that can be properly classified by the equations in the final layers. And it is that summary that needs to be reused. Therefore we knock off the final dense layers and replace them with a fresh set of dense layers that train with the new data that we have.\nFreeze There is one more concept that is very important in transfer learning. Say you have very little sample data. Now if you change the scores at the first few layers during your training phase (by taking the pre-trained weights at just initialization) and using the new model that you generated using the pre-trained one, there is a high chance that you end up throwing out a lot of use cases that the initial model cover and you did not. Since the data set is small, it may not have all examples of 3x3 patches that may be present in the real world where this sample is to be used. And during training, you might throw down the better weight a present in the initialization. Therefore it is a good idea to freeze the initial part of the network. Now how much you freeze depends on the data you have. If you have a lot of data, freeze the least. If you have very little freeze most of the network and your trained model will handle more cases that your data has.\nCifar 100 The models are so good that CIFAR 10 is not really a challenge. So we are going to go to its bigger brother CIFAR 100 where we will realize that even a set of 100 classes is a cinch for Xception neural network.\nCode time 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  from keras.applications.xception import Xception from keras.layers import Dense, GlobalAveragePooling2D from keras.models import Model from keras.datasets import cifar100 import keras # Load CIFAR dataset (x_train, y_train), (x_test, y_test) = cifar100.load_data() # Convert inputs to float between 0 \u0026amp; 1 x_train = x_train.astype(\u0026#39;float32\u0026#39;) / 255.0 x_test = x_test.astype(\u0026#39;float32\u0026#39;) / 255.0 # Convert output into one hot encoding (Just like before) y_train = keras.utils.to_categorical(y_train) y_test = keras.utils.to_categorical(y_test) # Download the Xception model. base_model = Xception(weights=\u0026#39;imagenet\u0026#39;, include_top=False) # add a global spatial average pooling layer. Just like # maxpool takes and average. # You can use maxpool here as well, hardly makes a difference. x = base_model.output x = GlobalAveragePooling2D()(x) # let\u0026#39;s add a fully-connected layer x = Dense(1024, activation=\u0026#39;relu\u0026#39;)(x) # and a logistic layer to the 100 classes predictions = Dense(100, activation=\u0026#39;softmax\u0026#39;)(x) # this is the model we will train model = Model(inputs=base_model.input, outputs=predictions) # first: train only the top layers (which were randomly initialized) # i.e. freeze all convolutional Xception layers for layer in base_model.layers: layer.trainable = False model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;sgd\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=5, batch_size=32) loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128) print loss_and_metrics   The code is terse and clear. I don\u0026rsquo;t think there is much commentary to add. The comments explain everything.\nSummary In this post we reused a pre-existing model and transferred the learnings into the Cifar100 model that we built and trained. The concept of transfer learning is very important in the deep learning toolkit. It provides ways to train using minimal data and get some great results.\nIn the next post we will discuss some of the pieces of the pre-existing models so that we can learn from their tools to improve our trade.\n","date":"2017-09-19T00:00:00+00:00","description":"The real power of deep learning is reuse - Stand on the shoulder of giants.","image":"/blog/2017/09/19/deep-learning-part-9/cover_hue64e30026af63da2e3bad650c8ce061a_214978_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/09/19/deep-learning-part-9/","readingTime":5,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part IX"},{"category":"Deep learning","contents":" ConvNets on CIFAR 10 This is the eighth part of a multi-part series on deep learning. You should start with Part 1.\nRecap In the previous posts we introduced neural networks, what they are and how they work as well as convolutional neural networks that provide methods to look at local information and generate the next layer by collecting information from a set of 9 neighbors.\nCIFAR-10 We have played a lot with MNIST and now it is time to introduce a much more complicated CIFAR data set. With this, we will finally fulfill the detection of \u0026ldquo;is a cat\u0026rdquo; that we discussed in our early post. In comparison to modern day data sets, CIFAR-10 is very simple. It does have a bigger brother CIFAR-100, but for now we will not talk about it. This data set consists of 50k images of 10 types of objects - airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. This one though just has 10 classes, is a lot more complicated. All 8s look very similar but all birds are very different. Automobiles have variety of shapes and sizes, colors etc that make this a much more difficult problem. CIFAR provides 32x32x3 colored images to test against.\nCode I am now going to put in vanilla code with very few tricks from the set I described in the previous posts. I will not be optimizing this and playing around with all the options. You will understand why in the next few posts.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  from keras.models import Sequential from keras.layers import Dense from keras.layers import Dropout from keras.datasets import cifar10 from keras.layers import Flatten from keras.layers.convolutional import Conv2D from keras.layers.convolutional import MaxPooling2D import keras # Load CIFAR dataset (x_train, y_train), (x_test, y_test) = cifar10.load_data() # Convert inputs to float between 0 \u0026amp; 1 x_train = x_train.astype(\u0026#39;float32\u0026#39;) / 255.0 x_test = x_test.astype(\u0026#39;float32\u0026#39;) / 255.0 # Convert output into one hot encoding (Just like before) y_train = keras.utils.to_categorical(y_train) y_test = keras.utils.to_categorical(y_test) # we could have said 10 here but this allows to change to CIFAR 100 and work with the same code. num_classes = y_test.shape[1] model = Sequential([ Conv2D(32, (3, 3), input_shape=(32, 32,3), padding=\u0026#39;same\u0026#39;, activation=\u0026#39;relu\u0026#39;), Dropout(0.2), MaxPooling2D(), Flatten(), Dense(512, activation=\u0026#39;relu\u0026#39;), Dropout(0.5), Dense(num_classes, activation=\u0026#39;softmax\u0026#39;) ]) model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;sgd\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=20, batch_size=32) loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128) print loss_and_metrics   This code should look almost the same as the first code we wrote for MNIST apart from the fact that we are using ConvNets. We start by a 3x3 conv layer, add some dropout, add a Maxpool to reduce to a 16x16 image, then convert it to a a flat list of numbers to feed into the same dense network as before. We use MaxPool as without that it would be a lot slower. It is a good time to discuss performance. Dense layers are heavy. They involve a lot of computations. They are good as they can take information to anywhere but we need to be extra careful not to use too many of them as they really slow it down. Softmax is also a heavy operation and a good advice is to reduce the number of parameters to manageable levels before involving in the complex softmax method.\nSummary In this post we built a very simple convolutional neural network to classify the Cifar 10 images into various categories. We realized how simple the neural network engines make it to model a complicated piece of the network by just one function call.\nIt came out to be a short post as we did not go through many of the optimizations. The reason why we did this will be very clear when we will in the next post use the model zoo to solve CIFAR-10.\n","date":"2017-09-18T00:00:00+00:00","description":"Using ConvNets in Keras is as easy as it gets. This post shows some sample code.","image":"/blog/2017/09/18/deep-learning-part-8/cover_hu78eb1539a9346372cee72f88d831f77a_213907_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/09/18/deep-learning-part-8/","readingTime":4,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part VIII"},{"category":"Toastmasters","contents":"This speech went with a slide show that you can view here. This one was a very technical topic to be presented to average individuals uninitiated to the world of technology and code. The biggest challenge for ths speech was to get some content across and still make sure everyone understands it.\nAristotle believed, as many of us still do - the heart is the seat of love, kidney is of fear and liver of anger. Neurologists have found that the most complicated organ, the one protected by the hardest layers of bones in our body, the brain is the seat of all emotions. We have been trying to understand it for centuries and after years of research we have started to map parts of it into code. I have been studying this now for almost a year. Fellow toastmasters, citizens of the silicon valley and dear guests - Deep learning is a direct result of messing up with the gooey stuff inside of the head. We are now living in a world where the machines have a true brain - they can see \u0026amp; hear, read and write, speak and understand the world around them just like us. I am to show you today how it works.\nLets go back 60 years into the research lab of Nobel Prize winners Hubel and Weisel. They wanted to know how vision worked. They took an unlucky cat, put a hole inside its head and inserted electrodes. Fun fact, the eyes are present here but the occipital lobe that creates vision is here, right at the back. Hubel and Weisel wanted to see what excites that cat. They showed it pictures of food, fish or females. The answer was - none. Frustrated the scientists spent days trying to figure stuff out. 10% of science is work. Rest is just luck. What they realized and won the Nobel price for was - it was not the rat, but the insertion of the next slide that really excited the cells. Not the food, not fish, not even the female, the first few cells look at simpler things, like the dark and the light, the horizontal and the vertical, the circles and the squares. It is a stack of neurons, like an organization\u0026rsquo;s hierarchy where the information is sifted until the condensed summary goes up to the CEO.\nDeep learning works the same way. Each image consists of millions of pixels. At the lowest level, the equation consists of assigning each pixel a weight. A few layers later, it looks at lines, circles and squares. Come down a few more and come ears, eyes and nose and then after a long chain we get the results of what the contents of the image are. That is why it is called deep. It consists of a very deep chain of very easy mathematical equations that eventually come up with what the image consists of.\nNow why is it called learning? Because we train it like the big cats. It looks at an image. If it identifies correctly it gets the meat. Otherwise the whip. Let me explain you how that truly works. I already told you it resembles the organization hierarchy where managers upon managers condense information. Lets assume each of us is a brain cell. the question I have is - Is this a cat?\n{member 1} Do you see eyes of a cat?\n1 point.\n{member 2} Do you see whiskers?\nI trust her more - 2 points.\n{member 3} Do you see a tail?\nI do kind of trust him. So -1.\nNow for my personal judgement = hmm. 1 point.\nSo I say yes - 3 points. And then of course my manager will punish me. It is not a cat. And I will distribute the punishment. I will take two dollars from her, one from him and give him back one. I take one from my pocket and give it back my manager. Next time, she will be more careful, he will be more careful and he will be more confident.\nThis is 90% of deep learning. Add a few more tricks and you can really go deep. This creates a wonderful set of pattern recognition and pattern creation systems. The sights, the sounds, the smell are all patterns. Now the big deal about patterns - Deep neural networks are so good at it that Elon Musk fears machines getting better than humans.\nWe may know our brains a lot better now, but we haven\u0026rsquo;t yet built robots with emotions. These complicated machines that we currently have consist of layers of simple equations that bring enormous pattern recognition capabilities. Even though a lot of our lives involves pattern generation and recognition, we are still a lot more. Machines have been and will continue to be faithful helpers that do the boring stuff while we imagine and work towards a wonderful future. Deep learning is a wonderful application of the gooey stuff inside our head. Fear not and enjoy the wonderful future where machines speak and hear, read and write, see and show the wonderful world around us. Thank you.\nUnfortunately, this speech was not recorded. I don\u0026rsquo;t have a recording to share.\n","date":"2017-09-17T00:00:00+00:00","description":"Deep learning as a speech for toastmasters. The very basics for the very simple.","image":"/blog/2017/09/17/the-gooey-stuff-inside-of-your-head/cover_hu4fb31ed0eb1526356e49c3a82ac298a4_75949_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/09/17/the-gooey-stuff-inside-of-your-head/","readingTime":5,"series":null,"tags":["toastmasters","deep learning"],"title":"The gooey stuff inside of your head"},{"category":"Deep learning","contents":" Convolutional Neural Networks This is the seventh part of an intended multi-part series on deep learning. You should start with Part 1.\nRecap By now you should be comfortable with what a neuron is, what a neural network (or a stack of neuron means). We have so far described a neuron to represent g(AX + b) which was chained together in multiple layers that created a deep network. Next we talked about concepts like dropout, different activation function, regularization and different initialization to get better results.\nWhat is missing? When I described the core concept of having depth, I talked about teams looking at different parts of the image adn giving a decision. But when we implemented it, we created a dense layer where everyone looks at everything. And we know that that may be a bad use of resources. Most information in the image is associated close to each other. Randomly arranging the eyes, nose and ears won\u0026rsquo;t make a face and looking at random places for that is definitely not a great idea. Therefore it makes sense to have teams look at small parts and then take their decision. The next question would be team size. The bigger the teams, the closer we get to the original dense network problem. Therefore its better to start with the smallest teams and look grow them if things don\u0026rsquo;t work well. So what is the smallest team size. An image is two dimensional(actually 3 because of RGB, but since the third dimension is so small, we don\u0026rsquo;t really talk about that in our convolutions here) and therefore, we need a 2D convolution. The smallest symmetrical one is everyone looking at one pixel. But then we can\u0026rsquo;t build a hierarchy with one element in the next layer looking at only 1 pixel(1x1) (There is a 1x1 module you might find in certain networks. It is too advanced for now. We discuss that in part 10.). What is the next one. It is not 2x2. Because we cannot chose which 2 we need(left or right). Therefore it has to be 3x3 i.e. 9 pixels. People have tried 5 and 7 pixel rows but have realized over time that adding another layer is better than making it bigger. It is faster because of lesser variables and leaves little reason to go higher (More on this in Post 10).\nSo how does it look like to a user. You can get a fair idea from the visualization from vdumoulin displayed in the first image below.\nIdeas from classical computer vision Convolutions are not a new concept. They have been there in computer vision for a long time. The idea of a convolution is very simple. If you look at an image, one thing you definitely see is the color, but color in itself is not very interesting. It is the change in color that interests us. The change in color across individual pixels is is really what defines everything. Smooth change would probably mean a gradient, zero change would be solid color and a huge change would be an edge. A lot of effort has already gone into finding hand coded kernels (specific values of these convolutions) for detection of edges corners etc. as well as for styling images into different variants like blurring or sharpening.\nYou can play with and understand the concepts using the visualization here.\nSize problems You might have noticed, the approach above would reduce the output prediction size by two pixels in both rows and columns. Going back to manager analogy, each manager has 9 people reporting, but not all people have 9 managers. The pixels at the edges don\u0026rsquo;t have all neighbors and therefore the calls from the higher level don\u0026rsquo;t really center them. In a classic organization that is not a problem (rather a good thing). You may assume that since we want a single number as an output, it is a good thing. And I would agree. But there is one reason why we want this to be the same. The reason is simple. We want to stack multiple layers. We cannot go very deep if we reduce pixels each time. Also we will have to write separate layers for each kernel size. We cannot try different model pieces at different parts of the network and all that together makes our work difficult. Therefore we add padding to the original image so that it becomes consistent. The padding is all zeros and a smart network should be able to set the scores properly that those pixels won\u0026rsquo;t matter. Anyways, if x is 0, ax is also gonna be 0. The second image below is another image from the same visualization on padding.\nMore tricks Stride: You might have also noticed that reporting to 9 managers is sort of a confusing. There is a lot of duplication of information. Of course it is good to some extent that the same pixel can be measured differently, but do remember that the basic thing we did with MNIST worked well. There might not be enough information in a single signal(pixel or manager\u0026rsquo;s output), to require a huge set of weights looking at it. Therefore to speed up the network we use a stride, i.e. have only a few center pixels and consolidate the output. You can understand stride by the third visualization easily.\nTranspose With a stride we lose the benefits we added padding for. So we add the padding back to get to the same size via a transpose. The fourth visualization explains this concept.\n  Convolutions     Convolutions with padding     Convolutions with stride     Convolutions with transpose   \nWhy these tricks? You should be tempted to ask, why do these tricks? What do we save? Why not just pad. And the answer is just pad. That is a great starting point and indeed works the best. The tricks that are applied is just to save calculation and speed the network up. Let me explain that. Say you have 81 pixels. Now a standard stride will mean you will have 81 managers where each pixel having 9 weights. That means 81*9 weights. Now look at a stride/transpose chain. In the stride part each pixel has just one weight. So we have 81 weights. Now the pixels reduce to a square root to 9. Now each of these has 9 weights (rest are all zeros). So we are reduced to 81 + 81 weights from 81 x 9. Thats a lot of saving. Using this we can add a few more layers to make a network deeper and still fit in the same RAM. As I said at the start, the concept of a neural network is simple, it is the optimizations we need because of our slow machines that make it complicated.\nMaxout/Averageout There is one more concept that needs to be understood before going to code. This one is more of an optimization than a real trick. We can run multiple convolutions on the input data and it is a good idea to do that. This is because one convolution ideally carries only type of information. Eg one convolution could be a line detector, a corner detector, a blob or circle detector etc. With many convolutions on a big image we have a lot of data. We reduce this for getting better performance. There are many ways to reduce data, averaging(Averageout), picking up up one of them or picking up a min or max. Maxout or picking up the max in a set is very popular. We run a convolution and pick up the max of a small kernel (convolution area like 9 pixels) and keep that discarding the others. Why Max- because based on the intuitions from ReLU it seems like a good idea. But we are free to try other optimizations. It is an important trick to summarize the inputs and that is why very popular especially after a few Conv layers.\nConvolutions outside images The concepts of dividing local stuff and then putting a manager onto global stuff is not just applicable to images. Words are formed by looking at nearby characters, sentences via words and paragraphs via sentences. So this logic can be used on sentences of text. This logic can also be used with voice as that also consists of a similar pattern. I hope you can imagine how these simple concepts change everything.\nSummary Here we discussed the intuition and some concepts around Convolutions and why having local information passed onto the next layer is a good idea.\nIn the next post we will apply this to the CIFAR data set and show some results from the convolutional neural networks that can really amaze us all.\n","date":"2017-08-30T00:00:00+00:00","description":"CovNets and local information can really make results better. Simple Problem - Simple Solution.","image":"/blog/2017/08/30/deep-learning-part-7/cover_hufa172c321ff2040377cf4e9014ea60dc_68876_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/30/deep-learning-part-7/","readingTime":7,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part VII"},{"category":"Deep learning","contents":" Contracts, Options and Futures This is the sixth part of an intended multi-part series on deep learning. You should start with Part 1.\nRecap In the previous posts we came up with the equation of a neuron to be f(X) = g(Ax + b) and talked about how we can stack one neuron over other to get a chain and make the network deep. We also talked about SGD and how we can slowly change our random parameters to get to the correct answer by going in the direction of the gradient. We also talked about how over fitting prevents us from going deeper adn also the fact that deep learning is slow and most of the difficulty is that machines are not fast enough.\nRegularization Now that we know over fitting to the data is a problem, we need a way to prevent that from happening. If you are still in the world of the cat eye teams, you would call me stupid. Because your task was to classify the given images correctly and you are doing that, and getting great outputs. Now you follow the contract word by word and I don\u0026rsquo;t get what is needed means that I have to mess with the contract and change it to reflect what I want. So what do I want. I want you to give correct output for images you have never seen. How do I go about to do that? By preventing you from making your output too specific.\nThe answer is to force our outputs to be uniform. We don\u0026rsquo;t want it turn most As to zero and only take a few inputs. What we want from the A and b to be mostly uniform. Therefore we change our loss function. Well dear maths, don\u0026rsquo;t just optimize for giving the right probabilities, optimize for giving these A and b as uniform as possible so that it generalizes.\nWe use sometimes the L1 loss which is the average of the values of A, but mostly L2 loss is better (average of squares) so that the -ve and +ve values do not cancel each other.\nDropout Another trick to get a good improvement in the models is dropout. The key concept is very simple. Say you are again managing a team looking at the picture of a cat. If in all training examples cats have ears, you will assume that without ears a cat cannot exist. Now in the real world, if you find an image of a cat with headphones, you are likely to label it not a cat. This is the same over fitting problem we talked about earlier. In dropout we solve it by cheating. After seeing an image, we randomly select some teams to walk out and not give any feedback. Now we are left with a smaller number of teams and we learn to understand that we cannot rely on just one signal to identify. This diversification makes our network stronger. Mathematically we just need to set all A and b to 0 in a neuron we want to disable. It would be dead in the rest of the calculation. In most libraries drop out is just a function call. So there is no likely reason to reject that.\nActivation Function We used softmax as our activation function for the inner layer. Now the network can work with scores and doesn\u0026rsquo;t need to emit probability. That means we have a lot of other options inside. The most popular one is ReLU. ReLU has a very simple concept. It sets the score to 0 if it is negative and lets it pass through otherwise. This gives a lot of advantages. For all continuous functions, there is no clean way to say - \u0026ldquo;This factor is irrelevant\u0026rdquo;. With the slow gradient it really will take some time before we get close to zero and we will never get to say 0. ReLU is fast. We do not need logs any more and therefore the computation gets real quick. Unless you are a researcher, ReLU should be the default middle layer.\nWith softmax the sum of probabilities has to be 1, which means a neuron can give only one useful signal. Now suppose we had both cat and dog in the picture, softmax would get lost. In this case a sigmoid would be better. Sigmoid gives us a number between 0 and 1 and we can treat is as a probability even though it may not be exactly the same. (I won\u0026rsquo;t go into what makes sigmoid, but if you read the theory, you can easily understand how it squashes the inputs to be between 0 \u0026amp; 1. It again comes from statistics\u0026rsquo; world of logistic regression).\nInitialization I already played a trick on you when I said random initialization. Why not 0? Why not anything else? Well, this requires research and experimentation. Xavier et. al did that and found an initial state that works better(glorot_normal). The exact theory you don\u0026rsquo;t really need to know. It is a better parameter for softmax in most cases and worth being the default. For sigmoid, 0 is a good default. This initialization theory has been subjective and may not yield better results but do serve a better default anyways.\nFaster descent Now SGD is very good but it is slow. The reason is that it moves one step at a time. Therefore we may take a lot more time to reach optima than we can if we move faster. The solution that was discovered was momentum, i.e. move faster in the direction of change if we are going in the same direction as before. If most previous images are decreasing a variable, maybe we can decrease it more and get faster. Of course you can overshoot and the rest of the images will bring it back. Momentum gives a good boost over raw SGD. The overshooting problem was later solved by other methods and we should be using ADAM to get to the results faster.\nLearning rate and decay The learning rate we talked about is defined in keras, but the default decay is 0. Adding some decay can get a little bit closer to the local optimum than before.\nValidation You might have realized that for all these options require a lot of trial and error to be optimized. If we are experimenting, it is a good idea to split the training set into a training a validation set. We can then use the training set for training, validation set to try out various hyper parameters and the test set for the final verification before putting the code to production.\nCode changes Again all the numbers I have put in are hyper parameters and playing with them you might find better results. This post is to introduce the options that you have not find the optimal for MNIST. Let us put all these in code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Activation import keras import numpy as np (x_train2d, y_train), (x_test2d, y_test) = mnist.load_data() x_train = x_train2d.reshape(-1, 784) x_test = x_test2d.reshape(-1, 784) y_train = keras.utils.to_categorical(y_train, 10) y_test = keras.utils.to_categorical(y_test, 10) model = Sequential([ Dense(units=1000,input_dim=784, kernel_initializer=\u0026#39;glorot_normal\u0026#39;, kernel_regularizer=regularizers.l2(0.01)), Activation(\u0026#39;relu\u0026#39;), Dropout(0.4), Dense(units=10, input_dim=1000, kernel_initializer=\u0026#39;glorot_normal\u0026#39;, kernel_regularizer=regularizers.l2(0.01)), Activation(\u0026#39;softmax\u0026#39;), ]) model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;adam\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=20, batch_size=32) loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128) print loss_and_metrics   Summary We are a long way from the AX + b that we started with, but the changes are all minimal and incremental and conceptually nothing much has changed. Here we talked about some of the options that we have while starting with the model how to tweak the defaults.\nIn the next part we will figure out the way to use some of the local information in the image and get some great improvements via another of the buzzwords - Convolutional Neural Networks.\n","date":"2017-08-29T00:00:00+00:00","description":"Defaults are good, but playing with them can eek out the next 2% that we are looking for.","image":"/blog/2017/08/29/deep-learning-part-6/cover_hu9309c10ab7a912a0e9a0f23bbcf981d2_96915_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/29/deep-learning-part-6/","readingTime":7,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part VI"},{"category":"Deep learning","contents":" Lets go Deep This is the fifth part of an intended multi-part series on deep learning. You should start with Part 1.\nRecap In the previous sections we defined our deep learning task of identifying the contents of an image:\ng(AX + b) = Probability of being a content type  where X is the huge matrix that makes up the image and A are the weights, b the biases and g is the function that converts scores into probabilities like softmax.\nWe realized that the traditional way of solving equations does not work well with this case and therefore we described SGD as a means to solve the equation to get A and b. Then we wrote the code for the same using Keras.\nLimitations with our equation Let us congratulate ourselves for solving the seemingly impossible problem on the previous post. Now for some reality check. The current equation is very basic and does not solve many cases. Here is why:\n* The information in the neighboring pixels is not shared and therefore all weights are on individual pixels.\n* The global information about the entire contents of the image are also not available.\nThis makes it harder for complicated models. A cat is a lot more complicated than a digit.\nIntuition behind depth Now for the time being forget that you are someone reading the post. You are now the manager that manages the vision in the eye. Now you want to recognize a cat. The first thing you would do is to find a team. Then to this team you would divide work. Team A - try finding the whiskers, Team B - The ears, Team C - the eyes and so on. And then based on the results of what those teams find and adding your own personal belief you will give the probability to the user. And back propagation works the same way. You punish those people more whom you relied on the most if they made a mistake. Also you can now also play the majority rules game where if the ear team does not find the ear, but the others say, it is a cat, well it might be a cat wearing headphones. So they might just be missing ears or our ear folks are wrong and if this turns out to be a cat, they will be punished.\nSo the passes remain the same, we just ask the teams for their probabilities and then decide. The code is also very similar. Here is the set of equations:\ng(AX + b) = X' g'(A'X' + b') = y  You might have seen in the code already, the model consists of just these equations for the forward pass.\nThe other intuition comes from statistics. The original equation is very close to linear regression (which in 2D space is fitting a line). As you can expect, the images are a lot more complex and we cannot divide them into is cat or not with a line.\nWhy g \u0026amp; g\u0026rsquo;? Now we don\u0026rsquo;t necessarily need probabilities and we could work with scores right. But let me show you the maths again:\nAX + b = X' g'(A'X' + b') = y Substituting X' g'(A'AX' + A'b + b') = y  Now A'A is a constant and A'b + b' is another. And we haven\u0026rsquo;t earned anything. g and g' are both essential. The function g in a neuron provides a way to make the method non-linear, and is therefore called non-linearity apart from the activation that we already defined it with. The neural network we just created is two layers deep. A strong neural network can have hundred of layers.\nIsn\u0026rsquo;t the back propagation affected? Well that is why we found the formal method with calculus. There is a chain rule in calculus that makes this very simple as we multiply gradients until we get to the right weights to update.\nShall we make it deeeeeeeeeeeep Mostly deeper networks do produce better results. But there is a limit. You can see this in organizations from our analogy too. The longer the management hierarchy, the more is the signal loss from the lower down to the higher ups. In a neural network during the back propagation steps, each time we go a layer deep we have to multiply with the weights of the next layer. After a few hundred layers the product of these weights make the updates so small that the initial few layers live on with their starting random weights for a long time. This is one form of the so called Vanishing GRadient problem. The data requirement increases with the depth of the network. If we really want it deep, it gets a lot more hungry. That is why the state of the art networks take weeks to finish training on the fastest GPUs and need huge data sets. There is one more reason attached to the same thing. The number of parameters in A \u0026amp; b as they increase, well the model has a lot of leeway and after some time, it actually gets enough parameters to fit the entire data set in the if this image then this kind of a equation. Then we have the same old over fitting problem. So going deep is good, until some depth.\nLets see some code Well, the beauty of the libraries that we use is that, going deep is fairly easy if we do the basic thing. The only code change that keras really minimal.\n1 2 3 4 5 6  model = Sequential([ Dense(units=1000,input_dim=784), Activation(\u0026#39;softmax\u0026#39;), Dense(units=10, input_dim=1000), Activation(\u0026#39;softmax\u0026#39;), ])   We have brought 1000 teams that see the initial data and we take input from those 1000 outputs. This will run very slow. We will get to speeding it up and improving it in the next post.\nSummary In this post we talked about how we can all more variables and allow the equation (from now on called a model) to be more complicated by having a chain of layers. We also discussed why it seems like a good idea and how we can get the model made deeper in keras.\nIn the next post we will talk about how to solve some of the problems and roadblocks we hit by depth and some common tricks we can use to get improvements.\n","date":"2017-08-24T00:00:00+00:00","description":"Lets make the network actually deeper. Understand how the maths changes - Or does it?","image":"/blog/2017/08/24/deep-learning-part-5/cover_hu5c17175252bdb0735400ab31082c8ca3_153914_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/24/deep-learning-part-5/","readingTime":5,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part V"},{"category":"Deep learning","contents":" Working code This is the fourth part of an intended multi-part series on deep learning. You should start with Part 1.\nRecap In the previous sections we defined our deep learning task of identifying the contents of an image:\ng(AX + b) = Probability of being a content type  where X is the huge matrix that makes up the image and A are the weights, b the biases and g is the function that converts scores into probabilities like softmax.\nWe realized that the traditional way of solving equations does not work well with this case and therefore we described SGD as a means to solve the equation to get A and b.\nTechnical Considerations I hope you feel the same as me right now that deep learning as a concept is not very difficult. We use a very simple equation, fill it up with random numbers and slowly tweak that until we are done. The challenge comes up with the implementation. In any practical use case we are talking about a few million multiplications per image. Now that means we need a beefy GPU as running those multiplications one by one will turn out to be very slow. Add to that, we need floating point numbers (not integers) which take more space (4 bytes by default). Therefore for a single 1 megapixel image we are talking about 3GB of GPU memory to store A alone. Still it takes hours to train. The ImageNet model that is used to recognize images takes a month on a cluster of 5 of the fastest GPU available.\nSo make some compromises:\n We take small images and most of the time their size is a power of 2.\n We train in batches. Since gradient calculation is very expensive, we run the forward pass for multiple images at a time and once one set of images goes through we calculate the overall loss across all those images and push that back into the equation.\n Deep learning libraries do most of the heavy lifting for us and automatically divide between the various machines, effectively use the GPU, and also calculate the gradient to run the back propagation. We just define the model.\n Because of the very specific input requirements, the data gathering is the toughest part of a deep learning system. We need to clean the data and get it to the correct shape and sizes.\n  Libraries This is a very biased topic. I don\u0026rsquo;t want to go in the benefits and disadvantages of a library. Any ways, if you are not doing research but instead just tweaking something that is already there(which you should be doing), there is no point in arguing about it. All are good enough. The biggest guns in the market are with caffe (facebook), tensorflow(google) and CNTK(microsoft). Again the goals of all these libraries are different. They are made for modifying the core of the networks, and messing up with the stuff like calculus which you don\u0026rsquo;t need to go into just right now.\nFor the sake of simplicity, I use keras. This is one of the simplest to use libraries with the minimal amount of code you need to write. The library is built over CNTK, tensorflow and theano and therefore you can go deep into lower level if you so desire. This library also enables me to export models that you can visualize in Javascript. Since it is built over tensorflow, you can export its models to mobile and run them there.\nMNIST The MNIST data set is a data set of black and white (saves us the RGB channels) images of handwritten numbers(not cat pictures) from 0-9 all labelled correctly. They are available as 28x28 pixel images (not 1 megapixel). It is a very popular data set for tring out complicated networks as the problem is just perfect - not too heavy to require huge amount of processing time, not simple to be solvable easily by other means and not too complicated so that it can be solved by the simplest of neural networks.\nInstallation From the python website install python. Remember to enable pip(or use get-pip.py to download pip). Then run pip install keras to get keras.\nYou can now run python files by python filename. Google is your friend here (better than me) and you can always go to keras.io to find the latest installation instructions.\nCode  Import the python modules to use\n1 2 3 4 5  from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Activation import keras import numpy as np   Load the data Now keras comes bundles with MNIST. This is a data set of handwritten numbers (0-9). The images are all 28x28 and labelled with the correct number. Keras defines 60k images in the training and 10k in the testing set.\n1  (x_train2d, y_train), (x_test2d, y_test) = mnist.load_data()   Fit the data to our equation We do not use the fact that the image is 2 dimensional. we just create a flat list of 784 numbers. The -1 in the reshape is to keep the first dimension with the remaining dimension. We create 1 matrix of size [1x784] for each image and put all the images one under the other. Also the output is written as a single number. We convert that to categories, i.e. 1 row per output. This is because we want the probabilities of each number (0, 1, 2..9) separately. This type of encoding is called categorical or one hot encoding. In a more advanced network, we can also keeo this as a single number where the equation outputs between 0 \u0026amp; 0.1 for 1, 0.1 \u0026amp; 0.2 for 2 and so on. Probabilities are easier to understand and therefore we like the one hot output.\n1 2 3 4  x_train = x_train2d.reshape(-1, 784) x_test = x_test2d.reshape(-1, 784) y_train = keras.utils.to_categorical(y_train, 10) y_test = keras.utils.to_categorical(y_test, 10)   Define our equation The equation is called a model in keras. The code is should be very intuitive. You can ignore the term Sequential for now, since we have only one element, that does not technically mean a sequence. Next is Dense with 10 outputs and 784 inputs. Here we define the size of y \u0026amp; X in AX + b = y. The size of A and b is inferred by the network automatically. Dense means all inputs and outputs are connected. We will get into other types of networks later. The activation function is softmax, the only one we have discussed so far.\n1 2 3 4  model = Sequential([ Dense(units=10,input_dim=784), Activation(\u0026#39;softmax\u0026#39;), ])   Define the loss function We apply cross entropy loss to multiple categories. The optimization algorithm is SGD and we are looking for better accuracy.\n1 2 3  model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;sgd\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;])   Run the training set This method takes a lot of time. This takes the batch size(to group multiple images in a single pass) and the number of epochs(number of times to run this).\n1  model.fit(x_train, y_train, epochs=20, batch_size=32)    That is it. We have a trained model. Now we can pass a new image and get the corresponding probabilities. To verify the accuracy of our model (remember the over fitting problem. We need to know how it performs in a new unseen data set) use test the model\n1 2  loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128) print loss_and_metrics   \nThis should give you an accuracy of 92-93%. Just like that.\n\nHere is the full code:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Activation import keras import numpy as np (x_train2d, y_train), (x_test2d, y_test) = mnist.load_data() x_train = x_train2d.reshape(-1, 784) x_test = x_test2d.reshape(-1, 784) y_train = keras.utils.to_categorical(y_train, 10) y_test = keras.utils.to_categorical(y_test, 10) model = Sequential([ Dense(units=10,input_dim=784), Activation(\u0026#39;softmax\u0026#39;), ]) model.compile(loss=\u0026#39;categorical_crossentropy\u0026#39;, optimizer=\u0026#39;sgd\u0026#39;, metrics=[\u0026#39;accuracy\u0026#39;]) model.fit(x_train, y_train, epochs=20, batch_size=32) loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128) print loss_and_metrics   Now that we have working code, we can really zoom ahead. You know the basics. Give me some time to build upon it. In part 5 we will talked about deeper networks, how and why.\n","date":"2017-08-22T00:00:00+00:00","description":"Drawing MNIST - handwriting recognition with Deep Learning","image":"/blog/2017/08/22/deep-learning-part-4/cover_hub5d5907fa7f72c98d3d540f4c93c79f9_243177_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/22/deep-learning-part-4/","readingTime":7,"series":["Deep Learning"],"tags":["deep learning","keras","python","mnist","handwriting recognition","tensorflow"],"title":"Easy Deep Learning Part IV"},{"category":"Deep learning","contents":" Training \u0026amp; Testing This is the third part of a multi-part series on deep learning. You should start with Part 1.\nRecap In the previous sections we defined our deep learning task of detecting if an image is of a cat via the equation:\ng(AX + b) = Probability of being a cat  where X is the huge matrix that makes up the image and A are the weights, b the biases and g is the function that converts scores into probabilities like softmax.\nUsing this equation we need to find A and b using the known image label pairs(in the training phase) and then use this A and b to find the label for a unlabelled image(in the testing phase).\nWhy is this so hard? Let me remind you that AX + b is a lot of numbers (3 billion parameters for 1000 categories from 1 megapixel images). So we have 3 billion unknowns. And one image just gives us one equation. So we need 3 billion images to figure out this equation. And this is the simplest equation possible. Add to that the fact that the images need to be independent (2x + y = 4 and 4x + 2y = 8 are dependent equations). Also we need to make sure that the equations don\u0026rsquo;t contradict(Eg x + y = 5 and x + y = 6 cannot be solved). Now with images being a huge set of numbers, this is a bigger problem. Also we can have more images than the variables and in that case, we are stuck with unsolvable equations. Testing is easy as you just have to multiply and add and run softmax on a calculator. But getting perfect equations is impossible.\nWhat do we do? We approximate. We cannot expect to solve the equation but what we can do is find one of the solutions that satisfy all or most of our training data and assume it is our solution. Since it works for most of the known cases, it is very likely it will work for the unknown ones.\nHow do we do that? Since we are already in the realm of approximation, we start with a real approximate - all random numbers. That somehow gives us an answer. Though the answer is wrong, but from no answer we have and answer. Now we need to tweak it to get the right answer. Here is how we go on to do that. We put the first image in. We get a probability for each class. Say for example it said with probabilities of 0.2, 0.7, 0.1 that it is a cat, a dog and a horse respectively. But we know it is a cat. So we take the error which is 0.8 in the cat and modify A \u0026amp; b such that the error would be 0. Then we pick up the next image and continue to do this again and again. We repeat the same images and after a while considering the huge number of options we have for the variables(we have very few images and a lot more variables), they adjust themselves to a value that passes in most cases.\nWhich variables do we tweak and by how much? A billion options is not a great thing. We cannot possibly keep track of all the variables we modified for the previous image. So we definitely need a way to pick variables. This is a clever solution, but very practical.\nLet us pause from the maths a little and go back to common sense. You take a decision (like whether to buy a Honda or a Ford). You ask multiple folks for scoring one of them(whichever they think is the best) and pick up the one with the maximum score. Now the decision turns out bad. Who would you blame? The ones that gave the score for the car you ended up buying. Do you punish them equally? Definitely not. The one who gave a higher score gets more punishment. The more the impact on the results, the more the rewards and the punishment.\nThe same logic applies here. You look at the raw numbers. The weights on the cases where the output was higher get reduced by more than the ones where the output was less. First convert the probability back to the score amount. Since we used powers ( e^x       ) we use log to get back to scores. Then we subtract the error. This is the beauty of the simple equation AX + b that we started with. Note that in the day and age of computers, unless you are doing it on paper, you can re-use the mathematics already done in the library. So I am not going into the raw equations which you can find in any text book on the subject. I hope you can guess that doing this multiple times should ideally get to some good result. We can have multiple results all good enough based on where we start and which images we see first. You can compare it with a child learning. The lessons learnt when we are young leave a deeper imprint into us that those that we learn later.\nSome terminology The phase of training where we push the error back into the equation is called back propagation or backward pass while the calculation of scores(and probability) by using the equation is called forward propagation or forward pass. Note that in the testing phase we only do forward propagation. The error when converted into the score is called loss and is calculated only during training. This loss is applied based on the impact of a weight. The loss type for the softmax function we just described is called cross entropy loss. It is just the difference in the logarithmic space to counter the power we raised for making it all positive. The impact is officially called the gradient. The method of slowly going to the results by modifying the value in the direction of impact is called stochastic gradient descent(SGD).(It is called stochastic because we don\u0026rsquo;t wait for all pictures to take some decision). Also during the training we repeat the same images again and again. One run with the images is called one epoch. We run multiple epochs to fit most of our training data.\nThere is one more term that I would like to introduce. Now images come in all shape and sizes. It might happen that outliers(one weird test image) throw the equation in a weird direction. What we want is a slow and gradual learning so that we get to the conclusion that most images follow. We might not get to 100% accuracy but we will not be jumping around forever. And we can stop when we do not get better results any more. Therefore we multiply the loss with a number called the learning rate before we go onto modify our variables. And to get the best results we decrease the learning rate over time. Because closer to the results we do not want to lose the accuracy that was gained by so many images earlier.\nOver Fitting There will be one problem we have to deal with and that is over-fitting. With 3 billion variables, these is a possibility to tie in too tightly to the known cases. Eg if image 1 then this else that kind of solutions. We won\u0026rsquo;t notice it but somewhere that might happen. The solution to this is to reduce the number of variables or force using different variables each time. No need to think too much about this, just wanted to introduce the term. We will talk about solutions when we get to more complicated networks.\nGeneralization The logic that I defined for back propagation of taking the log and subtracting is specific to the softmax and the equation AX + b. It is good to start with a simple equation. But we know this is not enough to capture all image use cases. (We might need even more variables). So we need to formalize the method and find some way of measuring the impact correctly. In early days of deep learning, for complicated equations, the amount was calculated manually using some clever equations until it was figured out there is a way to get the best possible value of the impact accurately. I do enter a bit of hated maths but I have to. The solution is calculus. Don\u0026rsquo;t worry, you don\u0026rsquo;t need to know calculus to do deep learning in the modern world. The libraries have calculus inbuilt and we don\u0026rsquo;t need to do anything manually. Via calculus we can calculate the derivative or gradient of the entire equation f(X) with respect to any of the individual variable like \\frac{\\delta f(X)}{\\delta A}                     and then multiply the loss with the learning rate and this impact to apply it onto the value of A.\nRegression For the statistics lovers, the logic is same as regression that we use to get a equation to fit a set of number in 2D space. Indeed deep learning is just a generalized version of\nlinear regression where we have a lot more features and inputs and more vague and complicated. The loss has been replaces from L2 loss to cross entropy (which to some extent the same thing just with the scores).\nFor common folks who don\u0026rsquo;t understand statistics, congratulations you just learnt your stats 101. This is exactly the method to divide a set of inputs into two groups by a straight line(you might have heard about the method of least squares). In stats, you use the same equation without the logs (as we started with) and use the loss as the difference in scores or mean square root difference (as loses of -5 and +5 end up being 0, but if we really want some better scores).\nThe calculus idea also came from statistics as that is what we use for finding the minimum in linear regression.\nSummary Since we cannot get exact answers, we approximate. We start with random weights to all variables. We have two passes over the equation, a forward pass where we use the weights to get the probabilities, and the backward pass where we use the true answer to calculate the loss. Then based on the weight that had most gradient for a particular loss, we adjust our weights. We keep doing this multiple times until the results are good enough.\nNow starts the fun part. In the next part we apply the learnings we just did to get to some real action. We will do a full pass over our basic neural network to create some real fun - handwritten number recognition.\n","date":"2017-08-21T00:00:00+00:00","description":"Now that we know the equation, it is the time figure out how to fill it up with all the knowns \u0026 solve it.","image":"/blog/2017/08/21/deep-learning-part-3/cover_hu8bcebe0092ff0aa3a949fb28f842da53_166992_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/21/deep-learning-part-3/","readingTime":9,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part III"},{"category":"Toastmasters","contents":" This time I have two versions of the speech the initial draft which makes a good read but gets a beating when we get to the understanding and the final one that I delivered.\nInitial Draft Introduction before speech: Atishay wants to apologize to all medical professionals. The contents of his speech are partially true and truth hurts.\nOn April 24, 2010, in White Bear Township, Minnesota, a 68-year-old retiree, Erwin Lingitz was hungry. Very hungry. So, hungry that he committed the biggest heist of the century  1.5 pounds, mainly sausage and beef sticks, all free samples, were stolen He was beaten up and arrested. CCTV cameras were install in all stores. (slight pause) My retirement plans were ruined.\nFree is a marketing term - Fools Ready for Easy Extortion. There is a star at the end of each offer  Conditions Apply. Even if I could catch a hawk and transplant my brain inside of it, I wouldnt be able to read those conditions.(pause) To get them you need to go to customer support, (hush) quietly tiptoe inside and (bend) hide under the table.(Pause) (speak fast)Or just go to Facebook.(Pause) Last month on Facebook, I found one such benefit in my health insurance  Free Health checkup. Free. Who would miss it. They have free candies in the waiting room.\nI was about the learn their price, the hard way. Right as I entered a sexy salesgi, attendant gave me this (Take out paper). I am good with form filling. Throwaway email Done. Correct Phone number at the bottom. Just in case. No extra check marks. Careful with that opt-out. Do I mention the sick leave for the giant\u0026rsquo;s game? Na. And dont forget to leave a few blanks \u0026hellip; she would come over. (Fold paper) She did  no ad on the internet can match this. This is like a salesman telling you that the car is free. (Aside with smiling face) Sir, we only charge for the brakes. I happily parted five-hundred-dollars.\nNow I was a lab rat  oversized gown, labelled collar and always scared. (Fidgety eyes)Those machines. Hope they wont turn me into a frog. For the next one hour, I was a voodoo doll pinched to punish. Then came optometry. Ok Sir, do you know English? Is A better or A? A or A? {I think A}. Okay. Lets go with B And then the last one  masters of trickery. Have you eaten. After two hours of this ordeal who would say yes. \u0026ldquo;Good\u0026rdquo;. Trick question - No food. Had it been a yes, (in muted voice) You would have won another day off from work.\nThose who think failing college exams is difficult, you always have an option  Sit behind {someone from audience}; next time. Not with this (Take out paper). Fidgety Trembling I opened the sheet. \u0026hellip; (Wide open mouth, to exclaim) - \u0026ldquo;Aaa\u0026hellip; Ancient Greek. Where do you find an interpreter? Another \u0026ldquo;Free\u0026rdquo; session with the doctor.\nI was scared but prepared. Twenty minutes are free. Rest I pay. The doctor pounced upon the report. (Doctors Voice, again with the same sheet of paper. Serious look) \u0026ldquo;Hmm Interesting The results look good. \u0026rdquo; (Fold paper)\n{sigh}.\n\u0026ldquo;Except this one thing. (Pointing finger) You ate all my candies. You are overweight.\u0026rdquo;\nMy life flowed in front of my eyes. I had always been so thin that I fell between the cracks.(Pause) As a child, I was face to face with the manifestation of God  my fat young brother. Of course, I lost. \u0026ldquo;Oh so cute. Le Le Le Le.\nI waited in a corner (Aside, eyes wide open, slightly bend) \u0026ldquo;Momma, my candy.\u0026rdquo;\nIn my teens, I faced worse odds, against the manifestation of the devil - the bully KR - two times my size - \u0026ldquo;Hey matchstick, wheres my treat?\u0026rdquo;.\nBy college my enemies had completely taken over - the manifestations of laziness.\nNow when I finally get to have candies, you wont let me. I am a toastmaster. I will I will evaluate you. (Pause for effect) Good. Very well practiced. No Ahs and Ums or Filler words. Look again. Youre using notes. Thats my Ice Breaker. You do it every day. Where is the vocal variety? The three-act structure. (Pause) (Strut across the stage) I decided to show some body language - Get to the point.\n(Looks around and walks to a spot.) Is this the point?.\n(Raised eyes, angry look as if to question) Hmmm.\n(Scared, shivering) 200 bucks.\nI took the prescription (take out the paper again) and left. Our founding fathers wanted free to stand for freedom. Free to think, free to say. By the twenty-eight amendment, free only stood for free beer, that too with a star. Erwins case has been dismissed. But the fact remains - the last E in Free stands for \u0026ldquo;Extortion\u0026rdquo;. (Flip the paper)\nThe Paper had Free written where the last e spelled into extortion.\nFinal Version Fellow Toastmasters and Guests, what do you think when you see the words On Sale?\nHow about Free ?\nLast month on Facebook, I found an ad for a free health checkup.\nInstantly my brain said, Dont be a sucker !!!!\nBut my heart went on  Awwwww,,,,, give it a try ,,,, see what happens .\nNext day I was off from work and into the hospital. As soon as I entered, a very attractive receptionist gave me a form to fill out.\nI signed up for all free stuff. I even picked up some of the candies from the waiting room. Then she explained me that some of the most important tests paid and the free ones dont really make a sense without them.\nUh-oh\nBut .Charmed with her attraction and seeing my effort to go over there go to waste\u0026hellip;,\nI signed up for the paid tests.\nWithin minutes it began.\nHospitals are gloomy. Seriously, after the cemetery, where else do you expect to find all those dead.\nFirst was the CAT scan. They made me lie down in a small coffin, like box that went into a machine. I expected a frog to come out from the other side.\nThen the eye exam. He made me recite the alphabet in random order multiple times.\nThe worst part was  with and without that special lens, it all looked the same.\nNext, I went through the blood test. He asked me whether I was fasting.\nI misunderstood and thought that he was offering me food. (funny)\nIt turns out they dont provide food, but instead ask you to come over again if you had eaten something.\nAnyways, I finished the tests and went headed back home.\nA few days later \u0026hellip; the results . Yes, the results . came in the mail.\nNot email  but snail mail.\nI opened it, What\nI couldnt understand anything.\nI needed an interpreter !!!!!\nSo,I had to have another visit to the doctor.\nHaving already shelled out money the last time, I got smart and I did my homework.\nI knew I had to be back within twenty minutes to save myself from paying.\nBut the doctors are so clever. They take so much time.\nHmmm.\nHmmm.\nWhat is it?\nAll is good.\nSigh of relief.\nJust one thing  You ate all my candy. You are overweight.\nThen he began his long speech about the problems that could arise by being obese. I did not believe I was fat. I had always been thin. And no one likes being poked for his/her flaws.\nNow it was my turn.\nAs a toastmaster, I evaluating his speech. His speech was dull and boring. I stopped him asked for what he wants me to do. He prescribed me some expensive drugs from his pharmacy and I left.\nAnd by the way, he had 10 ah and ums.\nAfter the entire experience, in additional to the reports and what the doctor said, it felt like they were trying to extract as much money as they could out of the health examination that was supposed to be free.\nEven if we continue to fall for free stuff, we should remember that the real motive of giving free things is to make you pay in some other way.\nFellow Toastmasters and Guests, would you ever do this?\nWould I ever do this again ?\nMy mind says . Hell No !!!!\nBut my heart says.Maybe . Just Maybe .\nToastmasters ????\n","date":"2017-08-20T00:00:00+00:00","description":"If you really love free stuff this one is for you. I share an experience of a free health checkup.","image":"/blog/2017/08/20/free/cover_hu46a62b63cd87e70c9c6a355e73f25e8e_65916_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/20/free/","readingTime":7,"series":null,"tags":["toastmasters","life"],"title":"Free"},{"category":"Deep learning","contents":" Finishing Problem Definition This is the second part of an multi-part series on deep learning. You can read Part 1 here. In this post we complete the minimum equation of an image classifier that takes an image and gives us the likelihood that it is that of a cat.\nRecap In the previous section we defined our deep learning task of detecting if an image is of a cat via the equation:\nf() = Probability of being a cat = y  where\nf(X) = AX + b  Here X is an array of a huge set of numbers (3 million for a 1 megapixel image) and therefore A is also a huge array.\nOutputting probability You might have noticed once issue with the equation above. The value y needs to be between 0 \u0026amp; 1 as it is a probability. You never say you have a -10% confidence or are 200% sure. (We do say it but that doesn\u0026rsquo;t make mathematical sense). But the maths needs a way to make sure that happens. Therefore we have to slightly change our equation to:\nf(X) = g(AX + b)  here AX + b now gives a score while g(X) is a magical function that converts a score into a probability. Here are the limitations of being a probability that g needs to solve:\n* It has to be positive.\n* The sum of all probabilities (eg cat and not a cat) has to be 1.\nNow folks, this is very clever. But do stay with me. The easiest way to make a number positive and retain all the power of its score is to raise it to an exponent. The powers of a positive number are always positive whatever we do: 2^{-100}              , 2^0        or 2^{100}           . All are positive. Really clever right. The only difference is as pure mathematicians, we prefer to use e instead of 2. It simplifies our maths a little in a process I will talk about very soon. No one stops us from using 2 and 2 will also work correctly. Let call this positive version of the score as positive score.\nNow from positive score to probabilities is very simple. Just divide the positive score of being a cat by the positive score or being a cat and not being a cat. This makes g(X) a little bit complicated but I hope you can find the logic behind making such a function:\ng(k) = \\frac{e^k}{e^k + e^n}                               where k is the score of being a cat and n is the score of not being a cat. The official name of this function g is softmax.\nThis is not the only way to get the probability. There is a whole family of functions that can be used. This is just the most popular one to get proper probabilities. I will come to some other functions in a while. Also from the brain analogy, this is called the Activation function. It is called that because if it gives a large value, the connection is active and the light bulb in our brains glows. Also g(AX + b) is called a neuron to match a single cell of the brain (we like to be so proud that we have deciphered the brain) and a network with a lot of neurons(which we will come to in a while) is called a neural network.\nDoesn\u0026rsquo;t this way affect our scores, our weights and all that logic we just built? Definitely it does. With and without the function g we will get different values of A and b. But the thing is we don\u0026rsquo;t know A or b and we do not care. When we learn they should be flexible enough to adjust. Remember what I said about AX + b earlier. We are looking for the minimum equation because we already have a lot of variables. The conditions are clear. We need a probability as an output and we should be able to weigh individual pixels. And if this requires an exponent and a sum so be it.\nMultiples I am adding a twist to the question. Instead of looking at the image and telling me if it is a cat, now I give you an image and you tell me if it is a cat, a dog, a horse or any other animal in the given set of k(eg 1000) animals that has been provided. There is a constraint that the image contains a single animal and there is always a animal from one of the known classes. How does this change the equation above. Actually not much. We can use one equation for each type e.g. g(A_{cat}X + b_{cat})                               and g(A_{dog} + b_{dog})                            and so on. Now in g the denominator can be the sum of positive scores of being a cat, a dog a horse and all the other animals. Since all these equations are similar there is no point in doing them separately. That is why in the deep learning world, you will find a single network doing this. Now A becomes a 2-dimensional matrix and b becomes 1-dimensional. We still keep the capital and small distinction and keep this multiple category information a side note. A neuron still caters to a single output. It is a stack of many neurons that cater to a multiple outputs.\nPerfect answer Back to middle school/high school mathematics. For finding out 1 million variables how many equations do we need? The answer is 1 million. For 1000 animal types, this becomes 1 billion. That is lot a of data. And remember we are still in the process of framing the problem. What we have been trying to do so far is to make the simplest and the easiest equation possible to answer a question. Add to that we don\u0026rsquo;t even consider the connection between pixels. In the formula that we have so far, if you move the cat a little to the left in the image, it will wreck havocs on the weights that we have given. Lets assume each weight is a human. Now given one color you are giving the likelihood it is a cat. Of course you can guess a little. Green is unlikely to be a cat. But that\u0026rsquo;s all you have. You need to see more data or interact with people who have seen other parts to make out the whiskers.\nThe point I want to put across is that getting a perfect answer is hopeless and going in such an endeavor is likely to be doomed. So we have to go into approximations and find the approximate values of A \u0026amp; b that do the job for us. There are many possible imperfect answers and we find one of those that is good enough. Two runs of the same network can give different training weights A and b and both of them are approximate.\nSummary We have come a long way from where we started although the maths doesn\u0026rsquo;t look much different. But now that you are here, you would be realizing that deep learning is no magic and we are not messing up with the brain. It is high school mathematics just scaled to a million parameters. We went through how a neuron can be defined as the simple equation - g(Ax + b) where A is a set of weights for each pixel, b is a bias we added to help have some control initially and g is the activation function like softmax that converts output weight to a probability.\nIn the next part we will go into the training phase of the network describing how to use the equation we just came up with.\n","date":"2017-08-18T00:00:00+00:00","description":"We finish the mathematical equation of the core component of the deep learning network, realizing the extent of the problem and its solutions.","image":"/blog/2017/08/18/deep-learning-part-2/cover_hu81172b8041d40b22f94e936bb3b99f46_92835_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/18/deep-learning-part-2/","readingTime":7,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning II"},{"category":"Deep learning","contents":" Defining the problem This is the first part of a multi-part series on deep learning as I sort my thoughts around the learnings in the last 1 year and put them here for my memories and help fellow humans get rid of the fear of the mechanical brain. In this part we describe what deep learning is and start formulating an equation for the image classification problem in deep learning.\nDisclaimer Before you go on to read my post, do understand that this is a set of intuitions to make a layman understand the concepts. Some of the concepts have been modified, wrangled and some have been omitted just for the ease of understanding. Take all of what comes next with a grain of salt. I do start with the very basics but do build up very quickly. So if you find something to slow and boring just skip a few paragraphs.\nWhat the hell is Deep Learning? What does it do? Let me start by calming all fear. You might have heard a lot about AI replacing jobs, superhuman robots coming in to kill us all. Now deep learning and the new AI rush is not about all that. That is the marketing that the media is putting at us all. Deep learning is just pattern recognition. We show a machine millions of photographs of a cat and also show it photographs of what is not a cat. Then we ask it with another photo. \u0026ldquo;Is this a cat?\u0026rdquo; The machine now is capable of answering that with some degree of confidence. It is true that a lot of what we do in daily life is pattern recognition and machine can be the assistant like it always has been. It will tell us what it feels the pattern is and then we will verify and decide the action to take.\nA sample problem For the sake of understanding lets pick up a problem of classifying an image. Here given an image we want to know if the image is of a cat. The same concepts apply to other pattern matching problems. This is the signature problem of artificial intelligence, one of the most complicated pattern recognition that humans and animals do so easily millions of times in a day. Again not superhuman machines coming to kill us all, just a small piece of the way our eyes work.\nWhat is an image? The question for you - mathematically - What is an image? An image is a set of pixels. A pixel is a box of color. A 1 megapixel image contains 1 million pixels. Now what is a pixel - A pixel is a set of three colors - Red, Green and Blue. Remember your art classes - Primary Colors. All colors can be made by mixing by various amounts of these primary colors. Due to the way computers are designed each color is represented by a number between 0-255. No other reason - just limitations of the machine. So a 1 megapixel image would be 3 million numbers between 0 and 255.\nNow thinking a mathematical equation with 3 million number is a little two difficult. So instead let us put them in a variable X(we will later see how X is 3 billion numbers).\nBasic Mathematics Now with the X we just defined, we need an equation to find y given X. Lets start with the simplest equation possible.\ny = f(X)  where\nX =   y = Probability of being a cat.  Now we need the simplest f(X) possible(we are dealing with a million numbers). Here is the simplest one(see below for why):\nf(X) = AX + b  This is very simple mathematics from middle school. I hope you remember solving equations like 3x + 5 = y where x = 3. Then we figure out that y = 14. This is the same thing.\nI hope you are still here with me. We looking for a function f(X) such that if X is a photograph the function would return the likelihood that it contains a cat according to the knowledge that is built into the function. We came up with one possibility.\nStatistics This is the same equation as fitting a line though a set of points in X as used in linear regression with statistics. Machine learning is stats on steroids.\nThe true equation Here is the equation: f() = Probability of being a cat. Now here the image,  is 3 million numbers. Naturally A has to have 3 million numbers as well. So the true equation actually will become:\na_1x_1 + a_2x_2 \\dots a_nx_n + b = y                                      But we can live in matrix form. This makes the life easier. We can write it like - AX + b = y where A and X are matrices, X representing an image and A a set of parameters. I know matrices get into complicated land. But you don\u0026rsquo;t need to go deep right now. You might have noticed I used capital X and a small y and similarly capital A and small b. That was the idea all along. Capitals are matrices.\nWhy AX + b? I know you might be wondering, where did this equation come from? And why only this? How come this is the simplest one? Now is a good time for me answer that question. And the answer is very simple. We know an image has a million pixels and we want each pixel to count. There is one desire that we also have - each pixel should have the possibility of a different weight. A portion of the image defining the sky is not as helpful in determining if the image is a cat but a whisker surely is. So we need different weights for each pixel. That gives us a bare minimum equation where we have AX. Now adding a b has some very little cost. It is just a number. But you will see later this b gives us a lot of power and control. We can use b to balance out some of the initial values of A and make the results cleaner and easier to work with.\nWhy Probabilities? You would be imagining why the right hand side of the equation are probabilities. They could be discrete yes or no answers. You normally want f() to say \u0026ldquo;Yes this is a cat.\u0026rdquo; In the early days (1950s) that approach was tried in something called a \u0026ldquo;Perceptron\u0026rdquo;. It is very easy to guess why those would not work. We all know there is no white and black. There are millions of illusions, cats that hide in the environment, dogs that look like cats and so on. If we can\u0026rsquo;t be a 100% sure, why should we expect the mathematical equations to be. It is more practical to ask how likely the equations match and then we can improve the formula to give us better values.\nTwist There is one twist to the equation above that needs to be clarified before we go ahead. The question that I want you to think about is what are we trying to find? In traditional mathematics the answer is always X or y. But in this case the situation is slightly different. We do need to find y for a given X. That is - Given an image(X), what is the probability(y) that it is a cat. But we don\u0026rsquo;t know the values for A and b to plug into AX + b. Instead we have some samples that have the correct X and y, and based on those samples we will first find A and b. Then we go back and look for y for another X whose y we do not know.\nLet me rephrase this for folks that might find it a little bit confusing. (And yes it is.) A and b are the known constants of the equation which will help us find y for a given X. If we know f(X) we can plug in any X and find the corresponding y. But we do not know the magical A and b. So we first use the known values of X and y to find approximate values of A and b.\nTherefore there are two phases in a deep learning setup - The training phase and the testing phase. The machine first see a million cat images(X) where y = 1 and millions of not-a-cat images(X) where y = 0 in the training phase. Using these the machine will create a f(X) which would be correct for most of the examples it had seen. Then in the testing phase we can use a different image X'        and then find f(X')               which will tell us whether the new image is a cat.\nBrain Analogies Deep learning has a lot of brain analogies and things like Google Brain further put the pressure on our minds that we are doing something in the realm of god. Unlike what the media proclaim it is very different. A deep network requires a very beefy huge set of expensive machines to train to do something that a normal animal brain can do a lot better. We are not there. And we haven\u0026rsquo;t done everything.\nTake an example. Say you get a model of the Statue of Liberty. It looks like the same and maybe by a photograph you might get an angle to fool some naive individual that it is the real thing. But it is neither as big as the real thing nor as complete. Add to that it is not the entire new york city. Don\u0026rsquo;t expect to find the mini empire state building in the statue of liberty model that you have. Similarly copying a small part of the brain (like the visual cortex) and applying it to a very specific problem using a very different set of tools and resources at a very different cost is not really going into the superhuman realm.\nThere is one thing to note. A lot of the research was initially based on how the brain works (though we have diverged quite a lot), and therefore a lot of terms come from that world. The training and testing are terms like these which can refer to a brain learning something and then proving the learning. There is nothing to be worry about. No messing up with the gooey stuff in one\u0026rsquo;s head apart from sharpening it with new learnings.\nSummary The problem that deep learning solves is (in image classification) - Find a million sets of parameters A using multiple training images that classify them correctly. Then use those million parameters to answer the same question for an unknown image. We started trying to formulate this problem as an equation where we could give weights to each pixel of the image and came up with AX + b as the minimum equation to get this task done.\nNOTE: If you are about to talk about this somewhere, let me clarify that the above equation is incomplete to an extent that it is wrong. For statistics, this may be good enough, not for deep learning. Do read the next part to get the mathematics to a conclusion. The split here is for a quick coffee break.\nIn the next post we complete the equation we started working on.\n","date":"2017-08-16T00:00:00+00:00","description":"Deep learning is a complex name to a much simpler set of mathematical equations. Here we start with defining what the problem is.","image":"/blog/2017/08/16/deep-learning-part-1/cover_hu668e34e81b4703e79cff25c8fd41ae14_51370_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/08/16/deep-learning-part-1/","readingTime":9,"series":["Deep Learning"],"tags":["deep learning"],"title":"Easy Deep Learning Part I"},{"category":"Toastmasters","contents":"Long Long ago there was a princess\u0026hellip;that\u0026rsquo;s the only way Disney taught us to start a story. Anyways, this princess became a queen\u0026hellip;and what a queen\u0026hellip; the queen that the modern feminists would be jealous of\u0026hellip; The day she sneezed the world stock market fell 100 points. Her laughter was a boost of a hundred and when she got angry\u0026hellip;. Lets not talk about that\u0026hellip;. I know what {audience member} is thinking. I too wish my ancestors took biology seriously. Tracking her health and making some bucks. I won\u0026rsquo;t be standing here like this. Her name was Victoria and she also happen to be the biggest known business tycoon.\nShe was quick to realize that Englishmen are expensive and to get better value for money she took the more modern approach\u0026hellip; outsourcing. She set up some factories in India to produce\u0026hellip; conveyor belt workers and army men. With a lack of word, we happen to call them schools. They barely qualify as schools, just barely. They have rooms that resemble classrooms. When her reign ended, she forgot to unplug and they are still producing hordes of workers every day. The workers have transformed. Just when {audience member} is about to propose to a date.\nHey Lisa, I want to tell to you something?\nHis iPhone would ring, ding ding dring.\nLisa ding ding ding, just a minute\nHello Mr. \u0026lt;\u0026gt;, you can save a thousand dollars by changing your car insurance.\nWhat the ..\nLisa has already moved on.\nSo, lets talk about how they train children. Schools have a wide array of intricate torture techniques. They slowly break you down as a child. The first thing is called morning assembly. Morning assembly is a phenomenon where you put kids in the Sun. Roast them to light medium brown. Make sure, they turn brown. And, they make the guys stand in ascending order of insecurities. Shortest, least self-confident guy goes in the first. Genetically gifted tall guy who\u0026rsquo;s good looking will do well in life can enjoy basking in glory at \\ the back. They make sure that everyone does not have a sense of individualism. By making sure everybody wears the same uniform. And there is, there\u0026rsquo;s the wicked death eater of the morning assembly, the person who checks if you\u0026rsquo;re wearing your uniform correctly. No kid should be given so much power.\nOh but I am not wearing the belt.\nDon\u0026rsquo;t worry, just pull your shirt like this. He\u0026rsquo;ll never check.\nYa, I know. I\u0026rsquo;ll just pull it like this and he won\u0026rsquo;t check. I will slant my nails like this.\nAnd suddenly he goes past. {sigh of relief} then he will stop.\nI love the pledge. Hands straight. Is this a punishment? \u0026ldquo;All things bright and beautiful.\u0026rdquo; \u0026ldquo;Ya, da da da da da. I will be screwed if I bunk the class, so bunk the entire school.\nAnd then there are torture techniques. That teachers use. There was this teacher, Pundit sir. Right way to find new name. I should call myself Doctor. Dr. Jain. No need for a PhD. Back to Pundit sir. He was a cold blooded killer. Want to go to the washroom.\nMay I go to the washroom sir\nYou just did in the last class\n(As if you were spying on me)\nSir Pleeeeze.\nSit down.\n(Pees in the pants)\nOk. Sir. Done.\nThere\u0026rsquo;s a proper hail Hitler thing in school, which is. Good morning Teacher. After a point, it wasn\u0026rsquo;t about respect anymore it was a \u0026ldquo;Don\u0026rsquo;t hit me teacher.\u0026rdquo; So what we used to do, in between the class, we have like, five minutes of freedom, right? It\u0026rsquo;s just.. Na nana nan a nana nana. We\u0026rsquo;re just chilling. And all of us were smart, like, we used to keep one leg distance from our desk. We used to chill like this, teacher comes in, \u0026ldquo;Good morning Sir.\u0026rdquo; So we prepared. Where there\u0026rsquo;ll be one or two idiots who\u0026rsquo;re like in the back and like,.. And suddenly Pundit sir comes in.\nYou know why India sucks at sports. Because we learn different games. You should hold your ears while running. Instead of catching the ball, have a game where you need to avoid one.\nWhen Queen Victoria started schools in India, she was looking at instilling the following traits  Discipline, loyalty and obedience. She never realized that these traits are as essential to success as are perseverance and intuition. Those factories havent stopped running but instead over the age have picked up new and efficient techniques. The classic management case of innovation from the bottom. India is now the leading exporter of engineers on this planet. Give it a few decades and there will be scientists, entrepreneurs and many more.\n","date":"2017-04-23T00:00:00+00:00","description":"When Queen Victoria set up schools in India she didn't realize what a chain reaction she triggered.","image":"/blog/2017/04/23/indian-schooling/cover_hu8dcac9242037ab02a2cefee8e32bd263_150104_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/04/23/indian-schooling/","readingTime":4,"series":null,"tags":["toastmasters","life"],"title":"Indian Schooling"},{"category":"Toastmasters","contents":"Imagine a huge beautiful lake with crystal clear water you could drink. Add an island in the middle that can be accessed via a passage made of ice. No motorboats, no sailboats, not even a wooden plank. To all that add a huge swath of land with lush green grass that extends to as long as the eyes can see. Mountains colored red and yellow with flowers sitting at the horizon. Light rustling of distant flowing water interrupted occasionally with the heavy bustling of the mountain wind. Cool breeze flows through your hair reminding you that it is reality and no dream. Not even a walking trail in sight, no signboards and no proof of the existence of animal life, forget humanity. Wild edible strawberries growing near your feet. Eat as much as you like.\nYou cannot camp in paradise - it is an exotic travel destination which god loves too much to allow mere humans to stay. There are very few tour books that mention this place. The maps cheat, distorting reality by dislocating important areas and blurring out a lot of detail. Fellow toastmasters and honored guests, today I will describe a journey through destiny and hope that you are able to guess this unique destination before my talk runs out.\nThe first step of getting there is to pray to god - \u0026ldquo;O great Lord!! Please bless me. Please allow visits to your homeland this year.\u0026rdquo; A mere 0.000002% of the world population gets to visit this place in the lucky year when this is open. Next you pray to your family - \u0026ldquo;O great family!! Please bless me. Allow me to go. I will come back.\u0026rdquo; Lying to god and bribing him doesn\u0026rsquo;t work, but it works with your family. They would be praying that your visit gets canceled for one of the millions of reasons that are out there. Then you sign a death disclaimer for the that case you don\u0026rsquo;t make it.\nYou fly, you drive and then you walk, proving your identity to the prying hawk like eyes that track every action, ready pounce upon the slightest of your mistakes. Then begins your seven days visit in the heavens, always with a chance that something might cut them or cut you short. It takes hours climbing through conifers, through heavy rains where any missteps can be your end. But then if you peek outside of your trail you see the mesmerizing view of two rainbows. Rainbows stretch over snow clad mountains and twinkle in the clouds that you are standing on. You can\u0026rsquo;t carry the clouds back home in a bag. The cameras fail. It is a view to breathe in and fill your hearts with.\nThere will be times when you would give up. Climbs would be tougher than yesterday. The bag-packs would feel like iron claws. But then just open your eyes. Sit back and look where you are. You are probably the only thing that the artist would like to remove from the picture. Or maybe let you to live to leave a glimmer of hope to the mortals that men can visit this place in their lifetimes.\nThe place is magical - plain water is better than wine. The air is clean and pure and thinned by the altitude with an intoxication akin to a few shots of tequila. You can sit anywhere to amaze at god\u0026rsquo;s creations - meandering river nourishing the mountains; parched valleys as if sucked dry; or grasslands with winds that can make you fly stretching across to infinity. Plates don\u0026rsquo;t get dirty. Strangers become buddies. Grass feels softer than a feathered bed. Then there is the pass, a 4 hour continuous climb into a point of no return. The rains sweep everything every time to an abyss 500 feet deep. The lucky get to see, the home of the gods - the most challenging piece of rock that mankind has found, smiling from above the clouds, away to glory. On your way down, you can witness everything that you missed, a sea of flowers going right to a lake. The lake which bends into a waterfall. The waterfall that falls into another lake whose other end is beyond the horizon. Forget humans, no fish, no animals inhabit this place. There is only a piece of rock at the corner, worshiped every three years by the rare few who come to the place from the other side skipping the pass.\nLet me help you more in guessing this place. There is also a frozen lake for a week long trek. There is a gigantic region of huge volcanic rocks that you can drive over, right to the mountain of magnet. There is a city build over a lake. This place has been untouched for centuries and mankind is making sure that it remains like that. We have shoot at sight orders by three nuclear powers. All vie for a piece of it. Who can blame them. There is magic in Kashmir.\n","date":"2017-02-19T00:00:00+00:00","description":"I have had my share of travels and places around the world that I have seen. Never before I had and never again will I find a more exotic destination.","image":"/blog/2017/02/19/a-journey-through-heaven/cover_hu004daa3127ccd1dfee91142900af0e14_196707_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/02/19/a-journey-through-heaven/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"A journey through heaven"},{"category":"Toastmasters","contents":"I have a question to start with - Anyone here prefers 5 million dollars 5 years from now over a million right now? What about 10 million in ten years? How about 20 in 20? 100 million in 100 years. Yes. That is what I want to say - there is a time value of money but it is not as huge as is the life value of money. Now is more important than 10 years from now.\nLet me go through what the life of a normal individual say {person 1} looks like - Office is at 10, he wakes up at 9:10, slowly as he puts the alarm clock to sleep. Then the race begins. He switches on the shower while brushing his teeth, drives to office with a sandwich in his right hand. Luckily with automatic transmission there is no gear box to keep the hand busy. Sits in front of a machine all day, even having his lunch at desk. Tired he drives back home, finishes some household chores and again gets late for bed. Then after months of hard work, he finds a vacation and guess what he does going to the exotic location, shuts down his alarm clock and goes back to sleep.\nThis is the now that many of us are living. We work so hard waiting for a glorious future. We sacrifice now for tomorrow but the tomorrow never comes. Young await being independent. Adults yearn to save enough for a retirement, the enough that is never defined. The best days are the ones that we are letting go. God gave a present, the present time in out lives that keeps slipping right from under our nose.\nI am not saying to stop planning or working for a better future. With my burgeoning ambition, I am also trapped in this present sacrificing, future looking ride of life myself. By speaking out loud I am trying to remind myself more than I am trying to remind you - you do need to work for a better future but not at the cost of the present. I know it is a clich but it is a fact that no one on his deathbed wishes that he had worked a tad bit harder. There is an opportunity cost to everything. Sweet memories are too huge a cost for any future. Coming to US, I miss so many small family meet ups and events that would have created a great set of memories. I am very likely missing a cousin\u0026rsquo;s wedding this March. Therefore, I should be building a better set of memories that would justify my decision, rather than just a plan of a better future.\nI do love my job and maybe, even when I earn the financial independence I would continue to do something very similar. But there was so much more to me that got lost while growing up. That is another point that we should remember. Say we had no job to do tomorrow. Do we have something to do in the retirement we are spending our lives working towards. Now is the time to develop that additional hobby that is enjoyable. The aspirational writer needs the hours of practice before he learns enough to go full time. Now is when that time has to come. Not everyone can be Bill Gates or Sergey Brin to have enough time after retirement to work on things that he desired. We need to slice time from the present so that we don\u0026rsquo;t regret in the future. That future planning is what we are missing in this race for wealth.\nThere is one more thing that you need to do now. That is meet {person 1} and make friends with him. Same with {person 2}, {person 3} or any other interesting person you need to be friends with. The top of the success pyramid is very boring. So will be the time when all life goals are reached. Many old men await death just because they have nothing to do and no people to do stuff with. Now is the time to figure out the interesting people you will need life long. Remember that you get this life only once. Now will never return.\nBuild memories as they will be the only ones that last. Build hobbies as they need time to grow. Make friends you will desperately need at all times good or bad. I leave you with a question very different from the one I started with. If you were to be forced onto the mission to colonize Mars, think about the one photo you would like to take with you. Mine would have my parents and my wife. I don\u0026rsquo;t spend enough time with the people that matter most to me. Do you?\n","date":"2017-01-29T00:00:00+00:00","description":"We should never sacrifice the current time in our lives for a better tomorrow because now is the most important part of our lives.","image":"/blog/2017/01/29/now/cover_hufca353cac007171fa6c73c46feccb096_54116_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/01/29/now/","readingTime":4,"series":null,"tags":["toastmasters","thoughts"],"title":"Now"},{"category":"Thoughts","contents":"What was life like a hundred years back? Lets go back to 1917. Lets start with the luxurious you need to forgo - Phones, Laptops, Internet and anything smart or connected. I know you figured that out. Lets continue - lights, lamps, motors, air conditioners, heaters, fans and everything that runs with electricity. That should\u0026rsquo;ve hurt. Electricity was only in cities and for the rich. I can\u0026rsquo;t imagine life without electricity. There are so many things tied to it. Forget taps. We can\u0026rsquo;t have tanks on the roofs that supply water to them. Forget anything that you do at night. Apart from candle light dinners. Lets add more to the pain - forget cars and scooters. Learn to ride a horse. Ramp up your walking stamina. Horses are not for everybody and every-time.\nLets revise some history. The World War I was in progress. The Britishers ruled half of the planet. A conquerer could sell you for money. Slavery was rampant in a major part of the world. Malaria could wipe out a city. Medicine was less successful than a coin toss. The average man never saw old age. A rupee was worth more than ten thousand today (at least in terms of salary if not purchasing power). Common men only traveled across continents for one sole reason - to die in war.\n Happy Birthday Babaji   You were born in 1917 in the cold winters of the first world war. You were in your twenties when the second one broke through. Not many able men in their twenties survived the apocalypse. Yet you carried on in a small village that was not even in any of the maps (luckily nowadays Google maps puts up everything. I can mark your house in it) - without much of the health care innovations seeping in, not even notice from any of the corrupt government officers that were busy filling their own coffers.\nI congratulate you my grandfather to have lived through some of the toughest times to live through. You really need a of lot to survive - good health, peaceful times and a huge lot of luck. I know you didn\u0026rsquo;t get all that, but somehow struggled through the tumults to live the day that very few live up to. I am blessed to have grown up under your blessings and hope to stay blessed for the rest of my life.\n","date":"2017-01-07T00:00:00+00:00","description":"A century is a lot of time. Happy 100th birthday to my grandfather. It is a feat.","image":"/blog/2017/01/07/100-years-happy-birthday/cover_hu4183ab2089b8e19166b7ece7d1fb7196_82163_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2017/01/07/100-years-happy-birthday/","readingTime":2,"series":null,"tags":["life"],"title":"100 years - Happy birthday"},{"category":"Toastmasters","contents":"Here is another speech for toastmasters, CC#02. I vouch for games - Computer Games that have been cursed by parents for little apparent reason.\nMom\u0026rsquo;s always like to complain.\nStone age moms - Why do you always go out to play? You\u0026rsquo;ll get yourself killed.\nNineteenth century moms - Go out and play. What\u0026rsquo;s there in these stupid books.\nTwentieth century moms - You\u0026rsquo;re turning into idiots in front of the idiot box. Read some books.\nTwenty first century moms - Stop with these video games and mobile phones. Spend time with your family. Watch some TV.\nEven the news is against games - \u0026ldquo;8 year old Louisiana boy shoots his elderly caretaker because of playing games.\u0026rdquo;. Fellow toastmasters and honored guests. Today I discuss the other side of the story. Games are good. They are the most immersive form of entertainment and there are reasons we shouldn\u0026rsquo;t be so pessimistic about them. I will talk about how they have been revolutionizing learning, sports, engineering, acumen and team building.\nI\u0026rsquo;ll start with learning. How many here know how the renaissance progressed through Europe, how Genghis Khan marched through central Asia or how the lessons learned from the battle of troy. Gamers spent hours in Assassin\u0026rsquo;s creed living in the renaissance, marched Genghis khan\u0026rsquo;s army in the age of empires and built the Trojan horse in the age of mythology. I witnessed the Boston massacre first hand and happily set the east Indian ships with tea bags on fire in assassin\u0026rsquo;s creed 3. Those twenty hours of game-play will never drop from my memory while the countless hours learning history have vanished. The tactics of strategy games like StarCraft and Dota are a lot more advanced than the generations old chess. The rule of good writing is \u0026lsquo;Show not tell\u0026rsquo;. The rule of a great movie is \u0026lsquo;Show not tell\u0026rsquo;. The rule of a great game is \u0026lsquo;Experience not show\u0026rsquo;. There are games in all disciplines. You manage a city in SimCity and fly a plane in jet simulator. You learn keyboard shortcuts for the age of empires. Aren\u0026rsquo;t these skills in front of a machine that you need in your professional life?\nGames are great at breaking cultural barriers and at bonding people. Gamers go through so many good and bad times together that they begin to feel the interpersonal tensions of life easier. You play in teams being fighting to defend your partner or sacrificing yourself for the common good. Which other form of entertainment can instill this attitude? None. There are leaders and there are followers, bullies and the bullied. But you have a choice. You can practice to be better than the bullies, try out swapping leadership in teams and switch games in case you are not happy with the community. You can retain anonymity online and be safe that your actions won\u0026rsquo;t hurt you for life. Many of these options are not present in the real world. The opportunities of personal development in games is much better than most forms of entertainment.\nGames have been taking the world forward. They are the pioneers that brought GPUs to the masses and are the forerunners for artificial intelligence. They were the first to venture into mobile phones and are the leaders in exploring the AR/VR future. Games keep you one step ahead of the rest technology and you are free to bring the learning to real life. Games simulate a subset of real world social order and behavior and are experiments with various social conditions. There was an epidemic in the World of WarCraft where researchers saw how the world would behave if something came out for real. Some went to a corner to cry. Others ventured in anger to infect the unaffected. The simulation tell us what we need to be ready for. They are the cheapest means to study mass psychology.\nGames do have side effects. After a certain rate of exposure, the virtual world starts to feel real and the real world virtual. There are only 24 hours in the day and there are other tasks that need time allocation. Very few earn money via games. We have failed as a society to channel our entertainment to create something valuable. We need to move more of our learning to be done via playing. We need to realize that just like bad books and bad movies there are bad games. That doesn\u0026rsquo;t mean the medium is bad. The next time you find your little one asking to play a game, influence him in playing something that is useful and fun rather than restricting access. Games are the phenomenon that we can\u0026rsquo;t prevent. Better to channel them.\n","date":"2016-11-20T00:00:00+00:00","description":"I vouch for games - Computer Games that have been cursed by parents for little apparent reason.","image":"/blog/2016/11/20/games-are-good/cover_hu1b7737603f0a858fe896e67800bdbe7a_40814_100x100_fill_q75_box_bottom.jpg","meta":null,"permalink":"https://atishay.me/blog/2016/11/20/games-are-good/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Games are good"},{"category":"Toastmasters","contents":"Here are the contents from my first speech at toastmasters. This one is for the CC Manual (CC#01). I did get the ice breaker and the best speech of the day ribbon for this. I know if you read this, your first speech is coming up. Don\u0026rsquo;t worry. I have a tip for you. Bind your story in a theme, like I have done with Dj Vu. This gives something for the audience to remember and also gives you pointers to remember what to say next. Practice, till you are comfortable. Don\u0026rsquo;t worry. It will all be good.\nHow many here have experienced Dj Vu? A feeling that what we are seeing/doing has happened before? Dj Vu - French for already seen. Psychologists say 2/3rd of the healthy population experiences Dj Vu as a part of their life.\nFellow Toastmasters and honored guests. My name is Atishay, pronounced as - A as in up, ti doesn\u0026rsquo;t have a sound in English, you can equate it with the tea you drink and shay as in the month of may. I will be discussing how my life\u0026rsquo;s journey has been in cycles and why Dj Vu\u0026rsquo;s are frequent in my life - or what makes you to get the feeling.\nThis is my first speech but not the first time I am in such a situation so many new faces around me - De\u0026mdash;Ja\u0026mdash;-Vu. I was born in New Delhi and when I was very young, my family shifted to Dehradun, a small city in a beautiful valley back then. Now its a freaking metropolis! Imagine so many people to introduce yourself to, the psychological anxiety was similar as it is now. The huge city of Delhi faded quickly into distant memory. And now I live in the Silicon Valley in a serene and quiet neighborhood lush with vegetation (pause) - Dj Vu.\nI don\u0026rsquo;t believe in life after death. That\u0026rsquo;s not a source of Dj Vu. I am born to a pious family that believes in Jainism; a 2600 yr. old religion built around non-violence. Though the religion has firm roots in life after death, I find the tenants of agnosticism more fathomable. That\u0026rsquo;s the set of beliefs both Darwin and Einstein associated with them. The concept is simple - we can neither prove nor dis-approve the existence of God. Apart from the psychological effect of having this belief, there is no evidence that such an entity if exists has an impact on our lives. I do believe in humanity and non-violence and I remain vegetarian. I dont have strict political preferences and do feel that politics is like fashion, with the same trends repeating after a certain interval of time. What was old is new again. This gives us a sense of (pause) Dj Vu.\nI am a geek like so many others you find in the Silicon Valley and am very ambitious. I wish to be a part of making something that has a profound positive impact on humanity. Adobe, my employer has given me the opportunity to come here to learn. I firmly believe in technology as the being the best way to solve a lot of the worlds problems. I am a perfectionist and disciplinarian and many a times irk my wife with being obstinate on certain things. If something is amiss, I have this strong urge of fixing it, and that I have seen and fixed things like this before. Urghhh, why do they happen over and over again (pause) Dj Vu.\nI am glad to be here at toastmasters and thank you all for inviting me to this stage. I would like to say that Dj vu is caused by our memories, our thoughts and our dreams. Life moves in circles and each turn leaves an imprint on the memory. All we can hope is that each turn s for the better. With that I begin my journey here at toastmasters and hope that it will only get better.\n","date":"2016-11-12T00:00:00+00:00","description":"My first toastmaster's speech, the icebreaker. Here I introduce myself via a short but interesting story.","image":"/blog/2016/11/12/d%C3%A9j%C3%A0-vu/cover_huc271aa7a49734bc9beb76fbe1c457dc6_109993_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2016/11/12/d%C3%A9j%C3%A0-vu/","readingTime":4,"series":null,"tags":["toastmasters"],"title":"Dj vu"},{"category":"Thoughts","contents":"The first output of every computer program has traditionally been hello world. That feels like the right way to restart a blog. I have had a website and blogs at multiple times in the past. While resurrecting a website and a blog for myself, I have had some questions that you non-blogger should ask yourself:\n Why blog? Why now? What has changed?\n Blogging is one of the corner stones of the wild west of the Internet. The brave would venture out and publish pieces of their writing online. Free for anyone to read, criticize, to copy and redistribute (You would never have resources to pull down via the DMCA in case of a theft even after it was enacted). Blog were sources of Internet fame that would inspire the new online entrants to continue to deal with all the troubles for blogging. There were many troubles. Troves of hackers looked at ways to get into your servers, to make a name for themselves by defacing your website or use it as a part of their botnet. The Internet has always been relentless with the weak and maintenance of the blog has always been trouble. The fashion keeps changing as do the requirements of the browsers from higher resolutions to mobile screens, from skeumorphic to flat designs and from plain HTML to server side generation and then to client side rendering. The old theme you picked up from your blog from a gratuitous designer who was looking for a name for himself dies pretty often leaving a defaced website for you to clean up. The platforms change, so do the people but the blog still requires constant effort. It is easier to delete the blog with no entries for more than a year than to maintain it. And now you have places like Facebook to eat out most of the content you wanted to post.\nThen why blog now? Because the world has changed. Gone are the peak days of blogging. Personal blogs are personal again. There is no more peer pressure to update everything. That pressure moved from blogs to Facebook and then died when Facebook became creepy. You can now blog with your own will and at your own pace making sure that the writing makes you feel good. The troves of hackers are still there though their focus is now on greener pastures. You don\u0026rsquo;t get credits for taking down atishay.me and the one server is now not very useful in the botnet where a single script can give you thousands of light bulbs that glow on your command. Blog platforms have matured to be almost hacker proof. I host this static website generated by a static generator at Github and can be assured that security is being taken care of by Github. Hosting has become cheaper. Cheap enough for me to host the static assets with the blog and be safe from the mercy of the host for the images that my design requires. I am still at the mercy of fashion but unfashionable is not as bad as not working.\nThere is more need for blogging now than ever before. The distribution platforms that challenged blogging are too focused on money. They sell your posts for ads and earn by ruining the experience of your readers. Any website that was hosted 10 years ago and has remained unchanged would be many times faster than the best news website that is more modern. The performance bar for entry has fallen. Blogging is easier, faster and more fun than ever before. There is no gatekeeper pushing you to post more. The blogs today are more private than the most private conversation on the spied upon messaging apps.\nWith the breath of freedom, I am happy to be back. Hope to continue posting.\n","date":"2016-11-01T00:00:00+00:00","description":"Welcome to my blog. Its great to be blogging again. In my first post I discuss my motivations to blog.","image":"/blog/2016/11/01/hello-world/cover_hu92ebb433b32b4582e92b25f663f551b0_105090_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/blog/2016/11/01/hello-world/","readingTime":3,"series":null,"tags":["thoughts","hello","blogging"],"title":"Hello World"},{"category":"","contents":"","date":"0001-01-01T00:00:00+00:00","description":"","image":"/contact/cover_hu49c03114a9ce8ad2bc0bd62c0ddb3f2a_881086_100x100_fill_q75_box_center.jpg","meta":null,"permalink":"https://atishay.me/contact/","readingTime":0,"series":null,"tags":null,"title":"Contact Me"},{"category":"","contents":"You should try to find some internet connection to browse here.\n","date":"0001-01-01T00:00:00+00:00","description":"","image":"/image/favicon.min.svg","meta":null,"permalink":"https://atishay.me/off/","readingTime":1,"series":null,"tags":null,"title":"Offline"},{"category":"","contents":" Effective date: August 18, 2018\nAtishay Jain Website (\u0026ldquo;us\u0026rdquo;, \u0026ldquo;we\u0026rdquo;, or \u0026ldquo;our\u0026rdquo;) operates the https://atishay.me website (hereinafter referred to as the \u0026ldquo;Service\u0026rdquo;).\nThis page informs you of our policies regarding the collection, use, and disclosure of personal data when you use our Service and the choices you have associated with that data. This Privacy Policy for Atishay Jain Website is powered by PrivacyPolicies.com.\nWe use your data to provide and improve the Service. By using the Service, you agree to the collection and use of information in accordance with this policy. Unless otherwise defined in this Privacy Policy, the terms used in this Privacy Policy have the same meanings as in our Terms and Conditions, accessible from https://atishay.me\nInformation Collection And Use We collect several different types of information for various purposes to provide and improve our Service to you.\nTypes of Data Collected Personal Data While using our Service, we may ask you to provide us with certain personally identifiable information that can be used to contact or identify you (\u0026ldquo;Personal Data\u0026rdquo;). Personally identifiable information may include, but is not limited to cookies and usage data.\nUsage Data We may also collect information on how the Service is accessed and used (\u0026ldquo;Usage Data\u0026rdquo;). This Usage Data may include information such as your computer\u0026rsquo;s Internet Protocol address (e.g. IP address), browser type, browser version, the pages of our Service that you visit, the time and date of your visit, the time spent on those pages, unique device identifiers and other diagnostic data.\nTracking \u0026amp; Cookies Data We use cookies and similar tracking technologies to track the activity on our Service and hold certain information.\nCookies are files with small amount of data which may include an anonymous unique identifier. Cookies are sent to your browser from a website and stored on your device. Tracking technologies also used are beacons, tags, and scripts to collect and track information and to improve and analyze our Service.\nYou can instruct your browser to refuse all cookies or to indicate when a cookie is being sent. However, if you do not accept cookies, you may not be able to use some portions of our Service.\nExamples of Cookies we use:\n Session Cookies: We use Session Cookies to operate our Service.\n Preference Cookies: We use Preference Cookies to remember your preferences and various settings.\n Security Cookies: We use Security Cookies for security purposes.\n  Use of Data Atishay Jain Website uses the collected data for various purposes:\n To provide and maintain the Service\n To notify you about changes to our Service\n To allow you to participate in interactive features of our Service when you choose to do so\n To provide customer care and support\n To provide analysis or valuable information so that we can improve the Service\n To monitor the usage of the Service\n To detect, prevent and address technical issues\n  Transfer Of Data Your information, including Personal Data, may be transferred to  and maintained on  computers located outside of your state, province, country or other governmental jurisdiction where the data protection laws may differ than those from your jurisdiction.\nIf you are located outside United States and choose to provide information to us, please note that we transfer the data, including Personal Data, to United States and process it there.\nYour consent to this Privacy Policy followed by your submission of such information represents your agreement to that transfer.\nAtishay Jain Website will take all steps reasonably necessary to ensure that your data is treated securely and in accordance with this Privacy Policy and no transfer of your Personal Data will take place to an organization or a country unless there are adequate controls in place including the security of your data and other personal information.\nDisclosure Of Data Legal Requirements Atishay Jain Website may disclose your Personal Data in the good faith belief that such action is necessary to:\n To comply with a legal obligation\n To protect and defend the rights or property of Atishay Jain Website\n To prevent or investigate possible wrongdoing in connection with the Service\n To protect the personal safety of users of the Service or the public\n To protect against legal liability\n  Security Of Data The security of your data is important to us, but remember that no method of transmission over the Internet, or method of electronic storage is 100% secure. While we strive to use commercially acceptable means to protect your Personal Data, we cannot guarantee its absolute security.\nService Providers We may employ third party companies and individuals to facilitate our Service (\u0026ldquo;Service Providers\u0026rdquo;), to provide the Service on our behalf, to perform Service-related services or to assist us in analyzing how our Service is used.\nThese third parties have access to your Personal Data only to perform these tasks on our behalf and are obligated not to disclose or use it for any other purpose.\nAnalytics We may use third-party Service Providers to monitor and analyze the use of our Service.\n Google Analytics Google Analytics is a web analytics service offered by Google that tracks and reports website traffic. Google uses the data collected to track and monitor the use of our Service. This data is shared with other Google services. Google may use the collected data to contextualize and personalize the ads of its own advertising network.\nYou can opt-out of having made your activity on the Service available to Google Analytics by installing the Google Analytics opt-out browser add-on. The add-on prevents the Google Analytics JavaScript (ga.js, analytics.js, and dc.js) from sharing information with Google Analytics about visits activity.\nFor more information on the privacy practices of Google, please visit the Google Privacy \u0026amp; Terms web page: https://policies.google.com/privacy?hl=en\n  Links To Other Sites Our Service may contain links to other sites that are not operated by us. If you click on a third party link, you will be directed to that third party\u0026rsquo;s site. We strongly advise you to review the Privacy Policy of every site you visit.\nWe have no control over and assume no responsibility for the content, privacy policies or practices of any third party sites or services.\nChildren\u0026rsquo;s Privacy Our Service does not address anyone under the age of 18 (\u0026ldquo;Children\u0026rdquo;).\nWe do not knowingly collect personally identifiable information from anyone under the age of 18. If you are a parent or guardian and you are aware that your Children has provided us with Personal Data, please contact us. If we become aware that we have collected Personal Data from children without verification of parental consent, we take steps to remove that information from our servers.\nChanges To This Privacy Policy We may update our Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on this page.\nWe will let you know via email and/or a prominent notice on our Service, prior to the change becoming effective and update the \u0026ldquo;effective date\u0026rdquo; at the top of this Privacy Policy.\nYou are advised to review this Privacy Policy periodically for any changes. Changes to this Privacy Policy are effective when they are posted on this page.\nContact Us If you have any questions about this Privacy Policy, please contact us:\n By email: contact@atishay.me\n By visiting this page on our website: https://atishay.me/contact\n  ","date":"0001-01-01T00:00:00+00:00","description":"","image":"/image/favicon.min.svg","meta":null,"permalink":"https://atishay.me/privacy/","readingTime":6,"series":null,"tags":null,"title":"Privacy Policy"},{"category":"","contents":" Terms By accessing the website at http://atishay.me, you are agreeing to be bound by these terms of service, all applicable laws and regulations, and agree that you are responsible for compliance with any applicable local laws. If you do not agree with any of these terms, you are prohibited from using or accessing this site. The materials contained in this website are protected by applicable copyright and trademark law.\nUse License  Permission is granted to temporarily download one copy of the materials (information or software) on Atishay Jain\u0026rsquo;s website for personal, non-commercial transitory viewing only. This is the grant of a license, not a transfer of title, and under this license you may not:\n modify or copy the materials;\n use the materials for any commercial purpose, or for any public display (commercial or non-commercial);\n attempt to decompile or reverse engineer any software contained on Atishay Jain\u0026rsquo;s website;\n remove any copyright or other proprietary notations from the materials; or\n transfer the materials to another person or \u0026ldquo;mirror\u0026rdquo; the materials on any other server.\n  This license shall automatically terminate if you violate any of these restrictions and may be terminated by Atishay Jain at any time. Upon terminating your viewing of these materials or upon the termination of this license, you must destroy any downloaded materials in your possession whether in electronic or printed format.\n  Disclaimer  The materials on Atishay Jain\u0026rsquo;s website are provided on an \u0026lsquo;as is\u0026rsquo; basis. Atishay Jain makes no warranties, expressed or implied, and hereby disclaims and negates all other warranties including, without limitation, implied warranties or conditions of merchantability, fitness for a particular purpose, or non-infringement of intellectual property or other violation of rights.\n Further, Atishay Jain does not warrant or make any representations concerning the accuracy, likely results, or reliability of the use of the materials on its website or otherwise relating to such materials or on any sites linked to this site.\n  Limitations In no event shall Atishay Jain or its suppliers be liable for any damages (including, without limitation, damages for loss of data or profit, or due to business interruption) arising out of the use or inability to use the materials on Atishay Jain\u0026rsquo;s website, even if Atishay Jain or a Atishay Jain authorized representative has been notified orally or in writing of the possibility of such damage. Because some jurisdictions do not allow limitations on implied warranties, or limitations of liability for consequential or incidental damages, these limitations may not apply to you.\nAccuracy of materials The materials appearing on Atishay Jain website could include technical, typographical, or photographic errors. Atishay Jain does not warrant that any of the materials on its website are accurate, complete or current. Atishay Jain may make changes to the materials contained on its website at any time without notice. However Atishay Jain does not make any commitment to update the materials.\nLinks Atishay Jain has not reviewed all of the sites linked to its website and is not responsible for the contents of any such linked site. The inclusion of any link does not imply endorsement by Atishay Jain of the site. Use of any such linked website is at the user\u0026rsquo;s own risk.\nModifications Atishay Jain may revise these terms of service for its website at any time without notice. By using this website you are agreeing to be bound by the then current version of these terms of service.\nGoverning Law These terms and conditions are governed by and construed in accordance with the laws of California and you irrevocably submit to the exclusive jurisdiction of the courts in that State or location.\n","date":"0001-01-01T00:00:00+00:00","description":"","image":"/image/favicon.min.svg","meta":null,"permalink":"https://atishay.me/terms/","readingTime":3,"series":null,"tags":null,"title":"Terms of Use"}]