<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>handwriting recognition on Atishay Jain</title><link>https://atishay.me/tags/handwriting-recognition/</link><description>Recent content in handwriting recognition on Atishay Jain</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>contact@atishay.me (Atishay Jain)</managingEditor><webMaster>contact@atishay.me (Atishay Jain)</webMaster><lastBuildDate>Tue, 22 Aug 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://atishay.me/tags/handwriting-recognition/index.xml" rel="self" type="application/rss+xml"/><item><title>Easy Deep Learning Part IV</title><link>https://atishay.me/blog/2017/08/22/deep-learning-part-4/</link><pubDate>Tue, 22 Aug 2017 00:00:00 +0000</pubDate><author>contact@atishay.me (Atishay Jain)</author><guid>https://atishay.me/blog/2017/08/22/deep-learning-part-4/</guid><description>Working code This is the fourth part of an intended multi-part series on deep learning. You should start with Part 1.
Recap In the previous sections we defined our deep learning task of identifying the contents of an image:
g(AX + b) = Probability of being a content type where X is the huge matrix that makes up the image and A are the weights, b the biases and g is the function that converts scores into probabilities like softmax.</description></item></channel></rss>